```python
import os
import re
import hashlib
import json
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timezone

import gspread
from google.auth.transport.requests import Request
from google.oauth2.service_account import Credentials


SPREADSHEET_ENV_KEY = "GOOGLE_SHEETS_SPREADSHEET_ID"
SERVICE_ACCOUNT_FILE_ENV_KEY = "GOOGLE_SERVICE_ACCOUNT_FILE"


REQUIRED_SHEETS: Dict[str, List[str]] = {
    # 1) Courses - êµìœ¡ ê³¼ì • ë¦¬ìŠ¤íŠ¸
    "Courses": [
        "course_id",
        "program_name",
        "session_no",
        "theme",
        "event_type",  # NCT / Forum / Workshop / Webinar / Internal Talk
        "event_date",
        "location",
        "host_org",
        "speakers",
        "survey_form_version",
        "response_source_file",
        "status",  # planned / active / completed / archived
        "created_at",
        "updated_at",
    ],
    # 2) Survey_Items - ì„¤ë¬¸ í•­ëª© ì¹´íƒˆë¡œê·¸ (í‘œì¤€í™”ëœ ë¬¸í•­ ê´€ë¦¬)
    "Survey_Items": [
        "item_id",
        "item_code",  # ì¬ì‚¬ìš© í‘œì¤€ ì½”ë“œ (ì˜ˆ: SAT_OVERALL, DIFF_OVERALL, NPS)
        "item_group",  # ì„¸ì…˜/ìŠ¤í”¼ì¹˜/ëŒ€ë‹´ ê·¸ë£¹ëª…
        "item_text",  # ë¬¸í•­ ë³¸ë¬¸
        "metric_type",  # likert / nps / single_choice / multi_choice / text
        "dimension",  # satisfaction / difficulty / understanding / insight / recommend / operations / content / nps
        "scale_min",
        "scale_max",
        "scale_label_min",
        "scale_label_max",
        "options",  # ì„ íƒì§€ ëª©ë¡ (JSON ë˜ëŠ” CSV)
        "applies_to_speaker",  # ìŠ¤í”¼ì»¤ë³„ í‰ê°€ ë¬¸í•­ì¸ ê²½ìš°
        "applies_to_session",  # ì„¸ì…˜ë³„ í‰ê°€ ë¬¸í•­ì¸ ê²½ìš°
        "default_order",
        "is_active",
        "created_at",
        "updated_at",
    ],
    # 3) Course_Item_Map - ê³¼ì •â†”ë¬¸í•­ ë§¤í•‘ (ë¬¸í•­ ì¬ì‚¬ìš©)
    "Course_Item_Map": [
        "map_id",
        "course_id",
        "item_id",
        "order_in_course",
        "is_required",
        "custom_item_text",  # ê³¼ì •ë³„ ë¬¸í•­ ì»¤ìŠ¤í„°ë§ˆì´ì§• ì‹œ ì‚¬ìš©
        "created_at",
    ],
    # 4) Responses - ë¬¸í•­ ë‹¨ìœ„ ì‘ë‹µ (ì •ê·œí™”)
    "Responses": [
        "response_id",
        "course_id",
        "respondent_id",
        "timestamp",
        "item_id",
        "response_value",  # ì›ë³¸ í…ìŠ¤íŠ¸
        "response_value_num",  # ì •ê·œí™” ìˆ˜ì¹˜ (ë¦¬ì»¤íŠ¸/NPS â†’ ìˆ«ì)
        "choice_value",  # ë‹¤ì¤‘ì„ íƒ ë¶„í•´ ì‹œ ë‹¨ì¼ ì„ íƒê°’
        "comment_text",  # ì„œìˆ í˜•
        "source_row_index",  # ì›ë³¸ íŒŒì¼ì˜ í–‰ ë²ˆí˜¸
        "ingest_batch_id",  # ì ì¬ ë°°ì¹˜/ë²„ì „
    ],
    # 5) Respondents - ì‘ë‹µì ì •ë³´ (PII ë¶„ë¦¬)
    "Respondents": [
        "respondent_id",
        "course_id",
        "pii_consent",
        "company",
        "department",
        "job_role",
        "tenure_years",
        "name",
        "phone",
        "email",
        "hashed_contact",  # ì‹ë³„ìš© í•´ì‹œ
        "extra_meta",  # ì¶”ê°€ ë©”íƒ€ë°ì´í„° (JSON)
        "created_at",
    ],
    # 6) Insights - ì¸ì‚¬ì´íŠ¸ ê²°ê³¼ ì €ì¥ (ëŒ€ì‹œë³´ë“œìš©)
    "Insights": [
        "insight_id",
        "course_id",  # ë‹¨ì¼ ê³¼ì • ë˜ëŠ” cross-courseìš©ì€ Null í—ˆìš©
        "insight_scope",  # per_course / cross_course
        "insight_type",  # KPI / Trend / Finding / Quote
        "title",
        "description",
        "metric_name",
        "metric_value",
        "metric_unit",
        "breakdown_dim",  # ì„¸ë¶„í™” ì°¨ì› (ì˜ˆ: job_role)
        "breakdown_value",  # ì„¸ë¶„í™” ê°’ (ì˜ˆ: ì—”ì§€ë‹ˆì–´)
        "period_start",
        "period_end",
        "method",  # ì§‘ê³„ ê³µì‹/ì •ì˜
        "chart_spec_json",  # ì‹œê°í™” ìŠ¤í™ (Vega-Lite ë“±)
        "source_query",  # ì›ì²œ ì¿¼ë¦¬/ê³µì‹
        "last_updated",
    ],
    # 7) Lookups - í‘œì¤€ê°’ ì‚¬ì „
    "Lookups": [
        "key",
        "value",
        "description",
    ],
    # í•˜ìœ„ í˜¸í™˜ì„ ìœ„í•œ ë ˆê±°ì‹œ ì‹œíŠ¸ (ì„ íƒì‚¬í•­)
    "SurveySettings": [
        "courseId",
        "isActive",
        "startDate",
        "endDate",
        "maxResponses",
    ],
}


def _get_credentials(service_account_file: Optional[str] = None) -> Credentials:
    """ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (Streamlit Cloud & ë¡œì»¬ ì§€ì›)"""
    try:
        import streamlit as st
        
        # 1. Streamlit Secretsì—ì„œ JSON ë¬¸ìì—´ë¡œ ì½ê¸° (Streamlit Cloud)
        if "GOOGLE_CREDENTIALS" in st.secrets:
            creds_dict = json.loads(st.secrets["GOOGLE_CREDENTIALS"])
            scopes = [
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/drive",
            ]
            creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)
            return creds
    except Exception:
        pass  # Secrets ì‹¤íŒ¨ ì‹œ ë¡œì»¬ íŒŒì¼ë¡œ fallback
    
    # 2. ë¡œì»¬ íŒŒì¼ ì‚¬ìš© (ê°œë°œ í™˜ê²½)
    file_path = service_account_file or os.getenv(
        SERVICE_ACCOUNT_FILE_ENV_KEY, "huhsame-service-account-key.json"
    )
    
    scopes = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive",
    ]
    
    if os.path.exists(file_path):
        creds = Credentials.from_service_account_file(file_path, scopes=scopes)
        
        # Refresh token if needed
        if creds.expired and creds.refresh_token:
            creds.refresh(Request())
        
        return creds
    
    # 3. ë‘˜ ë‹¤ ì‹¤íŒ¨
    raise FileNotFoundError(
        "ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
        "Streamlit Cloud: Secretsì— 'GOOGLE_CREDENTIALS' ì„¤ì • í•„ìš”.\n"
        "ë¡œì»¬: JSON íŒŒì¼ ê²½ë¡œ í™•ì¸ í•„ìš”."
    )


def get_client(service_account_file: Optional[str] = None) -> gspread.Client:
    creds = _get_credentials(service_account_file)
    return gspread.authorize(creds)


def open_or_create_spreadsheet(
    client: gspread.Client,
    title: str = "êµìœ¡ì„¤ë¬¸_ì‹œìŠ¤í…œ",
    spreadsheet_id: str | None = None,
) -> gspread.Spreadsheet:
    """Open an existing spreadsheet by ID or title, or create if permitted.

    Note: If no ID is supplied and Drive quota prevents creation, a RuntimeError is raised
    with guidance to set GOOGLE_SHEETS_SPREADSHEET_ID.
    """
    # Prefer explicit ID (param) then env var
    spreadsheet_id = spreadsheet_id or os.getenv(SPREADSHEET_ENV_KEY)
    if spreadsheet_id:
        return client.open_by_key(spreadsheet_id)
    # Try open by title if exists
    try:
        return client.open(title)
    except gspread.SpreadsheetNotFound:
        # As a last resort, attempt creation but handle quota/permission errors clearly
        try:
            ss = client.create(title)
            return ss
        except Exception as e:
            raise RuntimeError(
                "Cannot create spreadsheet (likely Drive quota/permission). "
                "Please set GOOGLE_SHEETS_SPREADSHEET_ID to an existing Sheet ID."
            ) from e


def ensure_schema(spreadsheet: gspread.Spreadsheet) -> Dict[str, gspread.Worksheet]:
    """Ensure all required worksheets exist with headers.

    Returns a mapping of sheet name to worksheet.
    """
    worksheets: Dict[str, gspread.Worksheet] = {}
    existing = {ws.title: ws for ws in spreadsheet.worksheets()}

    for sheet_name, headers in REQUIRED_SHEETS.items():
        if sheet_name in existing:
            ws = existing[sheet_name]
        else:
            ws = spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=max(10, len(headers)))
        worksheets[sheet_name] = ws
        # Set headers if first row is empty or different length
        current = ws.row_values(1)
        if not current or len(current) < len(headers):
            ws.resize(rows=1000, cols=max(10, len(headers)))
            ws.update("1:1", [headers])
    # Remove default empty sheet if not in REQUIRED_SHEETS
    if "Sheet1" in existing and "Sheet1" not in REQUIRED_SHEETS:
        try:
            spreadsheet.del_worksheet(existing["Sheet1"])
        except Exception:
            pass
    return worksheets


def upsert_course(
    spreadsheet: gspread.Spreadsheet,
    course: Dict[str, str],
) -> None:
    ws = spreadsheet.worksheet("Courses")
    headers = REQUIRED_SHEETS["Courses"]
    all_rows = ws.get_all_records()
    # Update by courseId if exists, else append
    target_index = None
    for idx, row in enumerate(all_rows, start=2):  # header is row 1
        if str(row.get("courseId")) == str(course.get("courseId")):
            target_index = idx
            break
    values = [course.get(col, "") for col in headers]
    if target_index is None:
        ws.append_row(values, value_input_option="USER_ENTERED")
    else:
        cell_range = f"{target_index}:{target_index}"
        ws.update(cell_range, [values])


def list_courses(spreadsheet: gspread.Spreadsheet) -> List[Dict[str, str]]:
    ws = spreadsheet.worksheet("Courses")
    return ws.get_all_records()


def get_survey_settings(spreadsheet: gspread.Spreadsheet, course_id: str) -> Dict[str, str]:
    ws = spreadsheet.worksheet("SurveySettings")
    records = ws.get_all_records()
    for idx, row in enumerate(records, start=2):
        if str(row.get("courseId")) == str(course_id):
            row["_row"] = idx
            return row
    return {"courseId": course_id, "isActive": "FALSE", "startDate": "", "endDate": "", "maxResponses": ""}


def set_survey_active(spreadsheet: gspread.Spreadsheet, course_id: str, is_active: bool) -> None:
    ws = spreadsheet.worksheet("SurveySettings")
    headers = REQUIRED_SHEETS["SurveySettings"]
    records = ws.get_all_records()
    target_index = None
    for idx, row in enumerate(records, start=2):
        if str(row.get("courseId")) == str(course_id):
            target_index = idx
            break
    values = [
        course_id,
        "TRUE" if is_active else "FALSE",
        "",
        "",
        "",
    ]
    if target_index is None:
        ws.append_row(values, value_input_option="USER_ENTERED")
    else:
        ws.update(f"{target_index}:{target_index}", [values])


def list_questions(spreadsheet: gspread.Spreadsheet, course_id: str) -> List[Dict[str, str]]:
    ws = spreadsheet.worksheet("Questions")
    records = ws.get_all_records()
    filtered = [r for r in records if str(r.get("courseId")) == str(course_id)]
    # sort by order numeric if present
    try:
        filtered.sort(key=lambda r: int(str(r.get("order", "0") or 0)))
    except Exception:
        pass
    return filtered


def upsert_question(spreadsheet: gspread.Spreadsheet, question: Dict[str, str]) -> None:
    ws = spreadsheet.worksheet("Questions")
    headers = REQUIRED_SHEETS["Questions"]
    records = ws.get_all_records()
    target_index = None
    for idx, row in enumerate(records, start=2):
        if str(row.get("questionId")) == str(question.get("questionId")):
            target_index = idx
            break
    values = [question.get(col, "") for col in headers]
    if target_index is None:
        ws.append_row(values, value_input_option="USER_ENTERED")
    else:
        ws.update(f"{target_index}:{target_index}", [values])


def save_response(spreadsheet: gspread.Spreadsheet, course_id: str, question_id: str, answer: str, respondent_hash: str, session_id: str, ip_masked: str) -> None:
    """Save a single response to the Responses sheet"""
    ws = spreadsheet.worksheet("Responses")
    headers = REQUIRED_SHEETS["Responses"]
    response_id = str(int(datetime.now(timezone.utc).timestamp() * 1000))
    values = [
        response_id,
        course_id,
        question_id,
        answer,
        datetime.now(timezone.utc).isoformat(),
        respondent_hash,
        session_id,
        ip_masked,
    ]
    ws.append_row(values, value_input_option="USER_ENTERED")


def update_response_stats(spreadsheet: gspread.Spreadsheet, course_id: str) -> None:
    """Update ResponseStats for a course (v2 compatible)"""
    try:
        ws_responses = spreadsheet.worksheet("Responses")
        
        # v2 ìŠ¤í‚¤ë§ˆ: Survey_Itemsì™€ Course_Survey_Items ì‹œíŠ¸ ì‚¬ìš©
        try:
            ws_items = spreadsheet.worksheet("Survey_Items")
            ws_course_items = spreadsheet.worksheet("Course_Survey_Items")
            use_v2 = True
        except Exception:
            # ë ˆê±°ì‹œ: Questions ì‹œíŠ¸ ì‚¬ìš©
            ws_questions = spreadsheet.worksheet("Questions")
            use_v2 = False
        
        # ResponseStats ì‹œíŠ¸ í™•ì¸
        try:
            ws_stats = spreadsheet.worksheet("ResponseStats")
        except Exception:
            # ResponseStats ì‹œíŠ¸ê°€ ì—†ìœ¼ë©´ ìƒì„±í•˜ì§€ ì•Šê³  ì¢…ë£Œ
            return
        
        # Count unique respondents for this course
        responses = ws_responses.get_all_records()
        course_responses = [r for r in responses if str(r.get("course_id", r.get("courseId"))) == str(course_id)]
        unique_respondents = len(set(r.get("respondent_id", r.get("respondentHash")) for r in course_responses))
        
        # Count total questions/items for this course
        if use_v2:
            # v2: Course_Survey_Itemsì—ì„œ ì´ courseì— ë§¤í•‘ëœ item ìˆ˜ ì„¸ê¸°
            course_items = ws_course_items.get_all_records()
            total_questions = len([ci for ci in course_items if str(ci.get("course_id")) == str(course_id)])
        else:
            # ë ˆê±°ì‹œ: Questionsì—ì„œ courseIdë¡œ í•„í„°ë§
            questions = ws_questions.get_all_records()
            course_questions = [q for q in questions if str(q.get("courseId")) == str(course_id)]
            total_questions = len(course_questions)
        
        # Calculate response rate
        response_rate = (unique_respondents / max(1, total_questions)) * 100 if total_questions > 0 else 0
        
        # Update or create stats record
        stats_records = ws_stats.get_all_records()
        target_index = None
        for idx, row in enumerate(stats_records, start=2):
            if str(row.get("courseId", row.get("course_id"))) == str(course_id):
                target_index = idx
                break
        
        values = [
            course_id,
            str(total_questions),
            str(unique_respondents),
            f"{response_rate:.1f}",
            datetime.now(timezone.utc).isoformat(),
        ]
        
        if target_index is None:
            ws_stats.append_row(values, value_input_option="USER_ENTERED")
        else:
            ws_stats.update(f"{target_index}:{target_index}", [values])
    except Exception as e:
        # í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ (ë©”ì¸ ì—…ë¡œë“œì— ì˜í–¥ ì—†ìŒ)
        pass


def delete_question(spreadsheet: gspread.Spreadsheet, question_id: str) -> bool:
    ws = spreadsheet.worksheet("Questions")
    records = ws.get_all_records()
    for idx, row in enumerate(records, start=2):
        if str(row.get("questionId")) == str(question_id):
            ws.delete_rows(idx)
            return True
    return False


def get_course_by_id(spreadsheet: gspread.Spreadsheet, course_id: str) -> Dict[str, str]:
    """Get a specific course by ID (LEGACY)"""
    courses = list_courses(spreadsheet)
    for course in courses:
        if str(course.get("courseId")) == str(course_id):
            return course
    return {}


def get_course_by_id_v2(spreadsheet: gspread.Spreadsheet, course_id: str) -> Dict[str, str]:
    """v2 ìŠ¤í‚¤ë§ˆ: course_idë¡œ ê³¼ì • ì¡°íšŒ"""
    try:
        ws = spreadsheet.worksheet("Courses")
        all_rows = ws.get_all_records()
        
        for row in all_rows:
            if str(row.get("course_id", "")).strip() == str(course_id).strip():
                return row
        return {}
    except Exception as e:
        print(f"Error loading course {course_id}: {e}")
        return {}


def get_responses_for_course(spreadsheet: gspread.Spreadsheet, course_id: str) -> List[Dict[str, str]]:
    """Get all responses for a specific course"""
    ws = spreadsheet.worksheet("Responses")
    responses = ws.get_all_records()
    return [r for r in responses if str(r.get("courseId")) == str(course_id)]


def get_responses_by_question(spreadsheet: gspread.Spreadsheet, course_id: str, question_id: str) -> List[Dict[str, str]]:
    """Get all responses for a specific question"""
    ws = spreadsheet.worksheet("Responses")
    responses = ws.get_all_records()
    return [r for r in responses if str(r.get("courseId")) == str(course_id) and str(r.get("questionId")) == str(question_id)]


def save_analysis(spreadsheet: gspread.Spreadsheet, course_id: str, analysis_data: Dict[str, str]) -> None:
    """Save AI analysis results to Analysis sheet (LEGACY - use save_insight for new schema)"""
    # Legacy function kept for backward compatibility
    pass


# ============================================================================
# NEW SCHEMA FUNCTIONS (ê°œì„ ëœ ìŠ¤í‚¤ë§ˆ ì „ìš© í•¨ìˆ˜ë“¤)
# ============================================================================

def upsert_course_v2(spreadsheet: gspread.Spreadsheet, course: Dict[str, str]) -> None:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: ê³¼ì • ì •ë³´ ì €ì¥/ì—…ë°ì´íŠ¸"""
    ws = spreadsheet.worksheet("Courses")
    headers = REQUIRED_SHEETS["Courses"]
    all_rows = ws.get_all_records()
    
    # course_id ë¬¸ìì—´ ê°•ì œ ë³€í™˜ (ì ˆëŒ€ ë‚ ì§œ/ì‹œê°„ìœ¼ë¡œ ë³€í™˜í•˜ì§€ ì•ŠìŒ)
    course["course_id"] = str(course.get("course_id", "")).strip()
    
    if not course["course_id"]:
        raise ValueError("course_idëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤. ë¹ˆ ê°’ì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # course_idë¡œ ê¸°ì¡´ í–‰ ì°¾ê¸°
    target_index = None
    for idx, row in enumerate(all_rows, start=2):
        if str(row.get("course_id")).strip() == course["course_id"]:
            target_index = idx
            break
    
    # ê°’ ì¤€ë¹„ (ëª¨ë“  ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜)
    values = [str(course.get(col, "")) for col in headers]
    
    if target_index is None:
        # ìƒˆ í–‰ ì¶”ê°€
        ws.append_row(values, value_input_option="USER_ENTERED")
    else:
        # ê¸°ì¡´ í–‰ ì—…ë°ì´íŠ¸ (course_idëŠ” ì ˆëŒ€ ë³€ê²½ë˜ì§€ ì•ŠìŒ)
        ws.update(f"{target_index}:{target_index}", [values])


def list_courses_v2(spreadsheet: gspread.Spreadsheet, status: str = None) -> List[Dict[str, str]]:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: ê³¼ì • ëª©ë¡ ì¡°íšŒ (status í•„í„° ì˜µì…˜)"""
    ws = spreadsheet.worksheet("Courses")
    records = ws.get_all_records()
    if status:
        return [r for r in records if str(r.get("status")) == str(status)]
    return records


def upsert_survey_item(spreadsheet: gspread.Spreadsheet, item: Dict[str, str]) -> None:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: ì„¤ë¬¸ í•­ëª© ì €ì¥/ì—…ë°ì´íŠ¸ (í‘œì¤€ ë¬¸í•­ ì¹´íƒˆë¡œê·¸)"""
    ws = spreadsheet.worksheet("Survey_Items")
    headers = REQUIRED_SHEETS["Survey_Items"]
    all_rows = ws.get_all_records()
    
    # item_idë¡œ ê¸°ì¡´ í–‰ ì°¾ê¸°
    target_index = None
    for idx, row in enumerate(all_rows, start=2):
        if str(row.get("item_id")) == str(item.get("item_id")):
            target_index = idx
            break
    
    values = [item.get(col, "") for col in headers]
    
    if target_index is None:
        ws.append_row(values, value_input_option="USER_ENTERED")
    else:
        ws.update(f"{target_index}:{target_index}", [values])


def list_survey_items(spreadsheet: gspread.Spreadsheet, is_active: bool = True) -> List[Dict[str, str]]:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: ì„¤ë¬¸ í•­ëª© ëª©ë¡ ì¡°íšŒ"""
    ws = spreadsheet.worksheet("Survey_Items")
    records = ws.get_all_records()
    if is_active:
        return [r for r in records if str(r.get("is_active")).upper() in ["TRUE", "1", "Y"]]
    return records


def get_survey_item_by_code(spreadsheet: gspread.Spreadsheet, item_code: str) -> Dict[str, str]:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: item_codeë¡œ í‘œì¤€ ë¬¸í•­ ì¡°íšŒ"""
    ws = spreadsheet.worksheet("Survey_Items")
    records = ws.get_all_records()
    for r in records:
        if str(r.get("item_code")) == str(item_code):
            return r
    return {}


def map_item_to_course(spreadsheet: gspread.Spreadsheet, course_id: str, item_id: str, 
                       order: int = 0, is_required: bool = False, custom_text: str = "") -> None:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: ê³¼ì •ì— ë¬¸í•­ ë§¤í•‘ (ì¬ì‚¬ìš© ê°€ëŠ¥)"""
    ws = spreadsheet.worksheet("Course_Item_Map")
    headers = REQUIRED_SHEETS["Course_Item_Map"]
    
    map_id = f"{course_id}_{item_id}"
    values = [
        map_id,
        course_id,
        item_id,
        str(order),
        "TRUE" if is_required else "FALSE",
        custom_text,
        datetime.now(timezone.utc).isoformat(),
    ]
    ws.append_row(values, value_input_option="USER_ENTERED")


def get_course_items(spreadsheet: gspread.Spreadsheet, course_id: str) -> List[Dict[str, str]]:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: íŠ¹ì • ê³¼ì •ì˜ ë¬¸í•­ ëª©ë¡ ì¡°íšŒ (ë§¤í•‘ + ë¬¸í•­ ì •ë³´)"""
    ws_map = spreadsheet.worksheet("Course_Item_Map")
    ws_items = spreadsheet.worksheet("Survey_Items")
    
    mappings = ws_map.get_all_records()
    items = ws_items.get_all_records()
    
    # course_idì— í•´ë‹¹í•˜ëŠ” ë§¤í•‘ë§Œ í•„í„°
    course_mappings = [m for m in mappings if str(m.get("course_id")) == str(course_id)]
    
    # item_idë¡œ ë¬¸í•­ ì •ë³´ ë³‘í•©
    result = []
    for mapping in course_mappings:
        item_id = str(mapping.get("item_id"))
        item_info = next((i for i in items if str(i.get("item_id")) == item_id), {})
        
        # ë§¤í•‘ ì •ë³´ + ë¬¸í•­ ì •ë³´ í•©ì¹˜ê¸°
        combined = {**item_info, **mapping}
        result.append(combined)
    
    # order_in_courseë¡œ ì •ë ¬
    try:
        result.sort(key=lambda x: int(str(x.get("order_in_course", "0") or 0)))
    except Exception:
        pass
    
    return result


def save_response_v2(spreadsheet: gspread.Spreadsheet, response: Dict[str, str]) -> None:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: ì‘ë‹µ ì €ì¥ (ì •ê·œí™”ëœ í˜•ì‹)
    
    ğŸš¨ í•µì‹¬: Responses ì‹œíŠ¸ì˜ í—¤ë” ìˆœì„œì— ë§ì¶° ë°ì´í„°ë¥¼ ì €ì¥í•˜ì—¬ ë°ì´í„° ë°€ë¦¼ ë°©ì§€
    
    ë¬¼ë¦¬ì  ì—´ ìˆœì„œ (REQUIRED_SHEETS["Responses"]):
      1. response_id     - ì‘ë‹µ ê³ ìœ  ID
      2. course_id       - ê³¼ì • ID
      3. respondent_id   - ì‘ë‹µì ID
      4. timestamp       - ì‘ë‹µ ì‹œê° (ISO 8601)
      5. item_id         - ë¬¸í•­ ID (I-xxxxxxxx) âš ï¸ ì¤‘ìš”: ì´ ê°’ì´ íƒ€ì„ìŠ¤íƒ¬í”„ì™€ ë°”ë€Œë©´ ì•ˆ ë¨!
      6. response_value  - ì‘ë‹µ ê°’ (í…ìŠ¤íŠ¸)
      7. response_value_num - ì‘ë‹µ ê°’ (ìˆ«ì)
      8. choice_value    - ì„ íƒì§€ ê°’
      9. comment_text    - ì½”ë©˜íŠ¸/ì£¼ê´€ì‹
     10. source_row_index - ì›ë³¸ íŒŒì¼ í–‰ ë²ˆí˜¸
     11. ingest_batch_id  - ë°°ì¹˜ ID
    """
    ws = spreadsheet.worksheet("Responses")
    headers = REQUIRED_SHEETS["Responses"]
    
    # response_idê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±
    if not response.get("response_id"):
        response["response_id"] = str(int(datetime.now(timezone.utc).timestamp() * 1000000))
    
    # ğŸ”‘ ëª…ì‹œì  ìˆœì„œ ë³´ì¥: headers ë¦¬ìŠ¤íŠ¸ ìˆœì„œëŒ€ë¡œ ê°’ì„ ì¶”ì¶œ
    # headers = ["response_id", "course_id", "respondent_id", "timestamp", "item_id", ...]
    ordered_values = [response.get(col, "") for col in headers]
    
    # âš ï¸ ë°ì´í„° ì •í•©ì„± ê²€ì¦ (ë””ë²„ê·¸ìš©)
    if len(ordered_values) != len(headers):
        raise ValueError(f"ë°ì´í„° ê¸¸ì´ ë¶ˆì¼ì¹˜: expected {len(headers)}, got {len(ordered_values)}")
    
    ws.append_row(ordered_values, value_input_option="USER_ENTERED")


def save_respondent(spreadsheet: gspread.Spreadsheet, respondent: Dict[str, str]) -> None:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: ì‘ë‹µì ì •ë³´ ì €ì¥ (PII ë¶„ë¦¬)"""
    ws = spreadsheet.worksheet("Respondents")
    headers = REQUIRED_SHEETS["Respondents"]
    all_rows = ws.get_all_records()
    
    # respondent_idë¡œ ê¸°ì¡´ í–‰ ì°¾ê¸° (ì¤‘ë³µ ë°©ì§€)
    target_index = None
    for idx, row in enumerate(all_rows, start=2):
        if str(row.get("respondent_id")) == str(respondent.get("respondent_id")):
            target_index = idx
            break
    
    values = [respondent.get(col, "") for col in headers]
    
    if target_index is None:
        ws.append_row(values, value_input_option="USER_ENTERED")
    else:
        ws.update(f"{target_index}:{target_index}", [values])


def get_responses_v2(spreadsheet: gspread.Spreadsheet, course_id: str = None, 
                     item_id: str = None, respondent_id: str = None) -> List[Dict[str, str]]:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: ì‘ë‹µ ì¡°íšŒ (ë‹¤ì–‘í•œ í•„í„° ì˜µì…˜)"""
    ws = spreadsheet.worksheet("Responses")
    responses = ws.get_all_records()
    
    # í•„í„° ì ìš©
    if course_id:
        responses = [r for r in responses if str(r.get("course_id")) == str(course_id)]
    if item_id:
        responses = [r for r in responses if str(r.get("item_id")) == str(item_id)]
    if respondent_id:
        responses = [r for r in responses if str(r.get("respondent_id")) == str(respondent_id)]
    
    return responses


def save
def save_insight(spreadsheet: gspread.Spreadsheet, insight: Dict[str, str]) -> None:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: ì¸ì‚¬ì´íŠ¸ ì €ì¥ (ëŒ€ì‹œë³´ë“œìš©)"""
    ws = spreadsheet.worksheet("Insights")
    headers = REQUIRED_SHEETS["Insights"]
    
    # insight_idê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±
    if not insight.get("insight_id"):
        insight["insight_id"] = str(int(datetime.now(timezone.utc).timestamp() * 1000))
    
    values = [insight.get(col, "") for col in headers]
    ws.append_row(values, value_input_option="USER_ENTERED")


def get_insights(spreadsheet: gspread.Spreadsheet, course_id: str = None, 
                 insight_scope: str = None, insight_type: str = None) -> List[Dict[str, str]]:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ (í•„í„° ì˜µì…˜)"""
    ws = spreadsheet.worksheet("Insights")
    insights = ws.get_all_records()
    
    # í•„í„° ì ìš©
    if course_id:
        insights = [i for i in insights if str(i.get("course_id")) == str(course_id)]
    if insight_scope:
        insights = [i for i in insights if str(i.get("insight_scope")) == str(insight_scope)]
    if insight_type:
        insights = [i for i in insights if str(i.get("insight_type")) == str(insight_type)]
    
    return insights


def upsert_lookup(spreadsheet: gspread.Spreadsheet, key: str, value: str, description: str = "") -> None:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: í‘œì¤€ê°’ ì‚¬ì „ ì €ì¥/ì—…ë°ì´íŠ¸"""
    ws = spreadsheet.worksheet("Lookups")
    all_rows = ws.get_all_records()
    
    # keyë¡œ ê¸°ì¡´ í–‰ ì°¾ê¸°
    target_index = None
    for idx, row in enumerate(all_rows, start=2):
        if str(row.get("key")) == str(key):
            target_index = idx
            break
    
    values = [key, value, description]
    
    if target_index is None:
        ws.append_row(values, value_input_option="USER_ENTERED")
    else:
        ws.update(f"{target_index}:{target_index}", [values])


def get_lookups(spreadsheet: gspread.Spreadsheet) -> Dict[str, str]:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: í‘œì¤€ê°’ ì‚¬ì „ ì¡°íšŒ (key-value ë”•ì…”ë„ˆë¦¬ ë°˜í™˜)"""
    ws = spreadsheet.worksheet("Lookups")
    records = ws.get_all_records()
    return {str(r.get("key")): str(r.get("value")) for r in records}


def initialize_standard_lookups(spreadsheet: gspread.Spreadsheet) -> None:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: í‘œì¤€ê°’ ì‚¬ì „ ì´ˆê¸°í™” (event_type, metric_type, dimension ë“±)"""
    standard_values = [
        # event_type
        ("event_type.nct", "NCT", "Next Chip Talk ì„¸ë¯¸ë‚˜"),
        ("event_type.forum", "Forum", "ë¯¸ë˜ë°˜ë„ì²´ í¬ëŸ¼"),
        ("event_type.workshop", "Workshop", "ì›Œí¬ìƒµ"),
        ("event_type.webinar", "Webinar", "ì›¨ë¹„ë‚˜"),
        ("event_type.internal_talk", "Internal Talk", "ì‚¬ë‚´ ê°•ì—°"),
        
        # metric_type
        ("metric_type.likert", "likert", "ë¦¬ì»¤íŠ¸ ì²™ë„ (1-5, 1-7 ë“±)"),
        ("metric_type.nps", "nps", "Net Promoter Score"),
        ("metric_type.single_choice", "single_choice", "ë‹¨ì¼ ì„ íƒ"),
        ("metric_type.multi_choice", "multi_choice", "ë³µìˆ˜ ì„ íƒ"),
        ("metric_type.text", "text", "ì£¼ê´€ì‹ í…ìŠ¤íŠ¸"),
        
        # dimension
        ("dimension.satisfaction", "satisfaction", "ë§Œì¡±ë„"),
        ("dimension.difficulty", "difficulty", "ë‚œì´ë„"),
        ("dimension.understanding", "understanding", "ì´í•´ë„"),
        ("dimension.insight", "insight", "ì¸ì‚¬ì´íŠ¸"),
        ("dimension.recommend", "recommend", "ì¶”ì²œë„"),
        ("dimension.operations", "operations", "ìš´ì˜/ì§„í–‰"),
        ("dimension.content", "content", "ì½˜í…ì¸ /ë‚´ìš©"),
        ("dimension.nps", "nps", "ìˆœì¶”ì²œì§€ìˆ˜"),
        
        # status
        ("status.planned", "planned", "ê³„íšë¨"),
        ("status.active", "active", "ì§„í–‰ì¤‘"),
        ("status.completed", "completed", "ì™„ë£Œ"),
        ("status.archived", "archived", "ë³´ê´€"),
        
        # insight_type
        ("insight_type.kpi", "KPI", "ì£¼ìš” ì§€í‘œ"),
        ("insight_type.trend", "Trend", "ì¶”ì„¸ ë¶„ì„"),
        ("insight_type.finding", "Finding", "ì£¼ìš” ë°œê²¬ì‚¬í•­"),
        ("insight_type.quote", "Quote", "ì¸ìš©/í”¼ë“œë°±"),
        
        # insight_scope
        ("insight_scope.per_course", "per_course", "ë‹¨ì¼ ê³¼ì •"),
        ("insight_scope.cross_course", "cross_course", "ê³¼ì •ê°„ ë¹„êµ"),
    ]
    
    for key, value, description in standard_values:
        upsert_lookup(spreadsheet, key, value, description)


def initialize_standard_items(spreadsheet: gspread.Spreadsheet) -> None:
    """ìƒˆ ìŠ¤í‚¤ë§ˆ: í‘œì¤€ ì„¤ë¬¸ í•­ëª© ì´ˆê¸°í™” (ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿ ë¬¸í•­)"""
    standard_items = [
        {
            "item_id": "ITEM_SAT_OVERALL",
            "item_code": "SAT_OVERALL",
            "item_group": "ì „ì²´í‰ê°€",
            "item_text": "ì „ë°˜ì ìœ¼ë¡œ ì´ë²ˆ êµìœ¡ì— ë§Œì¡±í•˜ì…¨ë‚˜ìš”?",
            "metric_type": "likert",
            "dimension": "satisfaction",
            "scale_min": "1",
            "scale_max": "5",
            "scale_label_min": "ë§¤ìš° ë¶ˆë§Œì¡±",
            "scale_label_max": "ë§¤ìš° ë§Œì¡±",
            "options": "",
            "applies_to_speaker": "",
            "applies_to_session": "",
            "default_order": "100",
            "is_active": "TRUE",
            "created_at": datetime.now(timezone.utc).isoformat(),
            "updated_at": datetime.now(timezone.utc).isoformat(),
        },
        {
            "item_id": "ITEM_DIFF_OVERALL",
            "item_code": "DIFF_OVERALL",
            "item_group": "ì „ì²´í‰ê°€",
            "item_text": "êµìœ¡ ë‚´ìš©ì˜ ë‚œì´ë„ëŠ” ì–´ë– ì…¨ë‚˜ìš”?",
            "metric_type": "likert",
            "dimension": "difficulty",
            "scale_min": "1",
            "scale_max": "5",
            "scale_label_min": "ë§¤ìš° ì‰¬ì›€",
            "scale_label_max": "ë§¤ìš° ì–´ë ¤ì›€",
            "options": "",
            "applies_to_speaker": "",
            "applies_to_session": "",
            "default_order": "200",
            "is_active": "TRUE",
            "created_at": datetime.now(timezone.utc).isoformat(),
            "updated_at": datetime.now(timezone.utc).isoformat(),
        },
        {
            "item_id": "ITEM_UNDERSTAND_OVERALL",
            "item_code": "UNDERSTAND_OVERALL",
            "item_group": "ì „ì²´í‰ê°€",
            "item_text": "êµìœ¡ ë‚´ìš©ì„ ì–¼ë§ˆë‚˜ ì´í•´í•˜ì…¨ë‚˜ìš”?",
            "metric_type": "likert",
            "dimension": "understanding",
            "scale_min": "1",
            "scale_max": "5",
            "scale_label_min": "ì „í˜€ ì´í•´ ëª»í•¨",
            "scale_label_max": "ì™„ì „íˆ ì´í•´í•¨",
            "options": "",
            "applies_to_speaker": "",
            "applies_to_session": "",
            "default_order": "300",
            "is_active": "TRUE",
            "created_at": datetime.now(timezone.utc).isoformat(),
            "updated_at": datetime.now(timezone.utc).isoformat(),
        },
        {
            "item_id": "ITEM_NPS",
            "item_code": "NPS",
            "item_group": "ì¶”ì²œë„",
            "item_text": "ì´ êµìœ¡ì„ ë™ë£Œì—ê²Œ ì¶”ì²œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (0-10ì )",
            "metric_type": "nps",
            "dimension": "nps",
            "scale_min": "0",
            "scale_max": "10",
            "scale_label_min": "ì „í˜€ ì¶”ì²œì•ˆí•¨",
            "scale_label_max": "ë§¤ìš° ì¶”ì²œí•¨",
            "options": "",
            "applies_to_speaker": "",
            "applies_to_session": "",
            "default_order": "900",
            "is_active": "TRUE",
            "created_at": datetime.now(timezone.utc).isoformat(),
            "updated_at": datetime.now(timezone.utc).isoformat(),
        },
        {
            "item_id": "ITEM_FEEDBACK_TEXT",
            "item_code": "FEEDBACK_TEXT",
            "item_group": "ì£¼ê´€ì‹",
            "item_text": "ê°œì„ ì‚¬í•­ì´ë‚˜ ì˜ê²¬ì„ ììœ ë¡­ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.",
            "metric_type": "text",
            "dimension": "content",
            "scale_min": "",
            "scale_max": "",
            "scale_label_min": "",
            "scale_label_max": "",
            "options": "",
            "applies_to_speaker": "",
            "applies_to_session": "",
            "default_order": "1000",
            "is_active": "TRUE",
            "created_at": datetime.now(timezone.utc).isoformat(),
            "updated_at": datetime.now(timezone.utc).isoformat(),
        },
    ]
    
    for item in standard_items:
        upsert_survey_item(spreadsheet, item)


# ============================================================================
# í—¤ë” ê¸°ë°˜ ë¬¸í•­ ìë™ ë“±ë¡ (Auto Item Registration from Headers)
# ============================================================================

def slugify(text: str) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ slugë¡œ ë³€í™˜ (í•œê¸€/ì˜ë¬¸ ëª¨ë‘ ì§€ì›)"""
    text = str(text).strip().lower()
    # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    text = re.sub(r'[^\w\sê°€-í£-]', '', text)
    # ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ
    text = re.sub(r'[\s]+', '_', text)
    return text[:30]  # ìµœëŒ€ 30ì


def generate_item_code(item_text: str, dimension: Optional[str], metric_type: str) -> str:
    """í•­ëª© ì½”ë“œ ìƒì„± (ì¤‘ë³µ ë°©ì§€ìš© ê³ ìœ  ì½”ë“œ)"""
    base = dimension or metric_type or "item"
    slug = slugify(item_text)
    hash_str = hashlib.md5(item_text.encode('utf-8')).hexdigest()[:6]
    return f"{slugify(base)}_{slug}_{hash_str}".upper()


def generate_item_id() -> str:
    """ìƒˆ í•­ëª© ID ìƒì„±"""
    import uuid
    return f"I-{uuid.uuid4().hex[:8].upper()}"


def generate_map_id() -> str:
    """ìƒˆ ë§¤í•‘ ID ìƒì„±"""
    import uuid
    return f"M-{uuid.uuid4().hex[:8].upper()}"


def is_survey_question(header: str) -> bool:
    """í—¤ë”ê°€ ì„¤ë¬¸ ë¬¸í•­ì¸ì§€ íŒë‹¨ (ë©”íƒ€ë°ì´í„° ì œì™¸)"""
    header_lower = str(header).strip().lower()
    
    # ğŸš¨ í•µì‹¬ ìˆ˜ì •: íšŒì‚¬/ì†Œì†/ì§êµ°/ì—°ì°¨ ë“±ì€ ì„¤ë¬¸ ë¬¸í•­ìœ¼ë¡œ í¬í•¨
    # ë©”íƒ€ë°ì´í„°ì´ì§€ë§Œ ë¶„ì„ ê°€ì¹˜ê°€ ìˆëŠ” í•­ëª©ë“¤
    include_metadata_keywords = ["íšŒì‚¬", "ì†Œì†", "ë¶€ì„œ", "ì§ë¬´", "ì§êµ°", "ì§ì±…", "ì—°ì°¨", "company", "department", "job"]
    for keyword in include_metadata_keywords:
        if keyword in header_lower:
            return True  # ì„¤ë¬¸ ë¬¸í•­ìœ¼ë¡œ í¬í•¨
    
    # PII í•­ëª©ë§Œ ì œì™¸ (ê°œì¸ì‹ë³„ì •ë³´)
    exclude_pii_keywords = [
        'timestamp', 'íƒ€ì„ìŠ¤íƒ¬í”„', 'ì‹œê°„', 'ë‚ ì§œ', 'date',
        'email', 'ì´ë©”ì¼', 'ë©”ì¼',
        'name', 'ì´ë¦„', 'ì„±ëª…',
        'phone', 'ì „í™”', 'ì—°ë½ì²˜',
        'id', 'user_id', 'respondent_id',
    ]
    
    for keyword in exclude_pii_keywords:
        if keyword in header_lower:
            return False
    
    # ë„ˆë¬´ ì§§ì€ í—¤ë”ëŠ” ì œì™¸
    if len(header.strip()) < 3:
        return False
    
    return True


def guess_metric_type_and_dimension(header: str) -> Tuple[str, Optional[str], int, int]:
    """
    í—¤ë”ì—ì„œ metric_type, dimension, scale_min, scale_max ì¶”ë¡ 
    
    Returns:
        (metric_type, dimension, scale_min, scale_max)
    """
    header_lower = str(header).strip().lower()
    
    # ğŸš¨ í•µì‹¬ ìˆ˜ì •: ë©”íƒ€ë°ì´í„°ì„± í•­ëª©ì„ 'text' íƒ€ì…ìœ¼ë¡œ ê°•ì œ ì¸ì‹
    # "ì†Œì† íšŒì‚¬", "ì§êµ°", "ì—°ì°¨", "íšŒì‚¬ëª…" ê°™ì€ í•­ëª©ì€ ì£¼ê´€ì‹ í…ìŠ¤íŠ¸ë¡œ ìˆ˜ì§‘
    metadata_text_keywords = ["ì§êµ°", "ì—°ì°¨", "íšŒì‚¬ëª…", "íšŒì‚¬", "ì†Œì†", "ë¶€ì„œ", "ì§ë¬´", "ì§ì±…"]
    for keyword in metadata_text_keywords:
        if keyword in header_lower:
            return ('text', None, 0, 0)
    
    # NPS íŒ¨í„´
    if any(keyword in header_lower for keyword in ['ì¶”ì²œ', 'nps', 'recommend', '0~10', '0-10']):
        return ('nps', 'recommend', 0, 10)
    
    # Likert scale íŒ¨í„´
    likert_patterns = [
        (r'[1-5]ì ', (1, 5)),
        (r'5ì \s*ë§Œì ', (1, 5)),
        (r'[1-7]ì ', (1, 7)),
        (r'7ì \s*ë§Œì ', (1, 7)),
    ]
    for pattern, (min_val, max_val) in likert_patterns:
        if re.search(pattern, header):
            dimension = infer_dimension_from_text(header)
            return ('likert', dimension, min_val, max_val)
    
    # Dimension í‚¤ì›Œë“œë¡œ Likert ì¶”ë¡ 
    dimension_keywords = {
        'satisfaction': ['ë§Œì¡±', 'ë§Œì¡±ë„'],
        'difficulty': ['ë‚œì´', 'ë‚œì´ë„', 'ì–´ë ¤ì›€'],
        'understanding': ['ì´í•´', 'ì´í•´ë„'],
        'insight': ['ì¸ì‚¬ì´íŠ¸', 'ë„ì›€', 'ìœ ìµ'],
        'operations': ['ìš´ì˜', 'ì§„í–‰', 'ì¥ì†Œ', 'ì‹œì„¤'],
        'content': ['ë‚´ìš©', 'êµ¬ì„±', 'ì£¼ì œ'],
    }
    
    for dim, keywords in dimension_keywords.items():
        if any(kw in header_lower for kw in keywords):
            return ('likert', dim, 1, 5)
    
    # Yes/No íŒ¨í„´
    if any(keyword in header_lower for keyword in ['ì˜ˆ/ì•„ë‹ˆì˜¤', 'yes/no', 'ë™ì˜', 'ì°¸ì„']):
        return ('single_choice', None, 0, 0)
    
    # ë³µìˆ˜ ì„ íƒ íŒ¨í„´
    if any(keyword in header_lower for keyword in ['ë³µìˆ˜', 'ëª¨ë‘', 'í•´ë‹¹ë˜ëŠ”', 'multiple']):
        return ('multi_choice', None, 0, 0)
    
    # ê¸°ë³¸: text (ì„œìˆ í˜•)
    return ('text', None, 0, 0)


def infer_dimension_from_text(text: str) -> Optional[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ dimension ì¶”ë¡ """
    text_lower = str(text).strip().lower()
    
    dimension_keywords = {
        'satisfaction': ['ë§Œì¡±', 'ë§Œì¡±ë„'],
        'difficulty': ['ë‚œì´', 'ë‚œì´ë„', 'ì–´ë ¤ì›€'],
        'understanding': ['ì´í•´', 'ì´í•´ë„'],
        'insight': ['ì¸ì‚¬ì´íŠ¸', 'ë„ì›€', 'ìœ ìµ', 'ë„ì›€'],
        'recommend': ['ì¶”ì²œ', 'nps', 'recommend'],
        'operations': ['ìš´ì˜', 'ì§„í–‰', 'ì¥ì†Œ', 'ì‹œì„¤', 'ì•ˆë‚´'],
        'content': ['ë‚´ìš©', 'êµ¬ì„±', 'ì£¼ì œ', 'ê°•ì˜'],
    }
    
    for dim, keywords in dimension_keywords.items():
        if any(kw in text_lower for kw in keywords):
            return dim
    
    return None


def extract_session_number(text: str) -> Optional[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ì„¸ì…˜ ë²ˆí˜¸ ì¶”ì¶œ"""
    # íŒ¨í„´: Session 1, ì„¸ì…˜1, ì„¸ì…˜ 2
    patterns = [
        r'\bSession\s*(\d+)\b',
        r'ì„¸ì…˜\s*(\d+)',
        r'\[ì„¸ì…˜\s*(\d+)\]',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            return match.group(1)
    
    return None


def extract_speaker_name(text: str) -> Optional[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ë°œí‘œì ì´ë¦„ ì¶”ì¶œ"""
    # íŒ¨í„´: [ê³ ì˜ë¯¼], ê¹€í˜„ì¬, (ë°•ì¢…ê²½)
    patterns = [
        r'[\[\(]([ê°€-í£]{2,4})[\]\)]',  # ê´„í˜¸ ì•ˆì˜ í•œê¸€ ì´ë¦„
        r'\b([ê°€-í£]{2,4})\s*(?:ë°•ì‚¬|êµìˆ˜|ë‹˜|ì—°êµ¬ì›|ëŒ€í‘œ)',  # ì§í•¨ ì•ì˜ ì´ë¦„
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            return match.group(1)
    
    return None


def infer_item_from_header(header: str, order: int) -> Dict:
    """
    í—¤ë”ë¡œë¶€í„° Survey_Items í•­ëª© ì •ë³´ ì¶”ë¡ 
    
    Args:
        header: ì»¬ëŸ¼ í—¤ë”ëª…
        order: ìˆœì„œ (0ë¶€í„° ì‹œì‘)
    
    Returns:
        í•­ëª© ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    metric_type, dimension, scale_min, scale_max = guess_metric_type_and_dimension(header)
    session_no = extract_session_number(header)
    speaker = extract_speaker_name(header)
    
    # ì˜µì…˜ ì„¤ì • (single_choice, multi_choice)
    options = None
    if metric_type in ['single_choice', 'multi_choice']:
        # ê¸°ë³¸ ì˜µì…˜ (ì‹¤ì œ ë°ì´í„°ì—ì„œ ì¶”ì¶œí•˜ëŠ” ê²ƒì´ ë” ì •í™•)
        if 'ì˜ˆ/ì•„ë‹ˆì˜¤' in header.lower() or 'yes/no' in header.lower():
            options = 'ì˜ˆ,ì•„ë‹ˆì˜¤'
        else:
            options = None  # ì‹¤ì œ ë°ì´í„°ì—ì„œ ì¶”ì¶œ í•„ìš”
    
    # Scale label ì„¤ì •
    scale_label_min = None
    scale_label_max = None
    if metric_type == 'likert':
        scale_label_min = 'ë§¤ìš° ë‚®ìŒ'
        scale_label_max = 'ë§¤ìš° ë†’ìŒ'
    elif metric_type == 'nps':
        scale_label_min = 'ì „í˜€ ì¶”ì²œí•˜ì§€ ì•ŠìŒ'
        scale_label_max = 'ì ê·¹ ì¶”ì²œ'
    
    return {
        "item_text": header.strip(),
        "metric_type": metric_type,
        "dimension": dimension,
        "scale_min": scale_min if scale_min > 0 else None,
        "scale_max": scale_max if scale_max > 0 else None,
        "scale_label_min": scale_label_min,
        "scale_label_max": scale_label_max,
        "options": options,
        "applies_to_speaker": speaker,
        "applies_to_session": session_no,
        "default_order": order,
        "item_group": f"Session {session_no}" if session_no else None,
    }


def ensure_survey_items_from_headers(
    spreadsheet: gspread.Spreadsheet,
    headers: List[str]
) -> List[Dict]:
    """
    í—¤ë” ëª©ë¡ìœ¼ë¡œë¶€í„° Survey_Items ìë™ ë“±ë¡ (ì¤‘ë³µ ë°©ì§€)
    
    Args:
        spreadsheet: Google Spreadsheet ê°ì²´
        headers: ì»¬ëŸ¼ í—¤ë” ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ë“±ë¡ëœ í•­ëª© ì •ë³´ ë¦¬ìŠ¤íŠ¸ (item_id í¬í•¨)
    """
    ws = spreadsheet.worksheet("Survey_Items")
    all_items = ws.get_all_records()
    
    # ê¸°ì¡´ item_code ëª©ë¡
    existing_codes = {str(row.get("item_code", "")) for row in all_items}
    
    result_items = []
    
    for idx, header in enumerate(headers):
        # ì„¤ë¬¸ ë¬¸í•­ì¸ì§€ í™•ì¸
        if not is_survey_question(header):
            continue
        
        # í•­ëª© ì •ë³´ ì¶”ë¡ 
        item_info = infer_item_from_header(header, idx)
        
        # item_code ìƒì„±
        item_code = generate_item_code(
            item_info["item_text"],
            item_info.get("dimension"),
            item_info["metric_type"]
        )
        
        # ì¤‘ë³µ í™•ì¸
        if item_code in existing_codes:
            # ê¸°ì¡´ í•­ëª© ì°¾ê¸°
            for row in all_items:
                if str(row.get("item_code", "")) == item_code:
                    result_items.append(row)
                    break
            continue
        
        # ìƒˆ í•­ëª© ìƒì„±
        item_id = generate_item_id()
        new_item = {
            "item_id": item_id,
            "item_code": item_code,
            "item_group": item_info.get("item_group") or "",
            "item_text": item_info["item_text"],
            "metric_type": item_info["metric_type"],
            "dimension": item_info.get("dimension") or "",
            "scale_min": item_info.get("scale_min") or "",
            "scale_max": item_info.get("scale_max") or "",
            "scale_label_min": item_info.get("scale_label_min") or "",
            "scale_label_max": item_info.get("scale_label_max") or "",
            "options": item_info.get("options") or "",
            "applies_to_speaker": item_info.get("applies_to_speaker") or "",
            "applies_to_session": item_info.get("applies_to_session") or "",
            "default_order": item_info["default_order"],
            "is_active": "TRUE",
            "created_at": datetime.now(timezone.utc).isoformat(),
            "updated_at": datetime.now(timezone.utc).isoformat(),
        }
        
        # ì €ì¥
        headers_list = REQUIRED_SHEETS["Survey_Items"]
        values = [str(new_item.get(col, "")) for col in headers_list]
        ws.append_row(values, value_input_option="USER_ENTERED")
        
        result_items.append(new_item)
        existing_codes.add(item_code)
    
    return result_items


def ensure_course_item_mapping(
    spreadsheet: gspread.Spreadsheet,
    course_id: str,
    item_list: List[Dict]
) -> None:
    """
    Courseì™€ Survey_Items ìë™ ë§¤í•‘
    
    Args:
        spreadsheet: Google Spreadsheet ê°ì²´
        course_id: ê³¼ì • ID
        item_list: í•­ëª© ë¦¬ìŠ¤íŠ¸ (item_id í¬í•¨)
    """
    ws = spreadsheet.worksheet("Course_Item_Map")
    all_maps = ws.get_all_records()
    
    # ê¸°ì¡´ ë§¤í•‘ í™•ì¸
    existing_pairs = {
        (str(row.get("course_id", "")), str(row.get("item_id", "")))
        for row in all_maps
    }
    
    for item in item_list:
        item_id = str(item.get("item_id", ""))
        if not item_id:
            continue
        
        # ì¤‘ë³µ í™•ì¸
        if (course_id, item_id) in existing_pairs:
            continue
        
        # ìƒˆ ë§¤í•‘ ìƒì„±
        map_id = generate_map_id()
        new_mapping = {
            "map_id": map_id,
            "course_id": course_id,
            "item_id": item_id,
            "order_in_course": item.get("default_order", ""),
            "is_required": "TRUE",
            "custom_item_text": "",
            "created_at": datetime.now(timezone.utc).isoformat(),
        }
        
        headers_list = REQUIRED_SHEETS["Course_Item_Map"]
        values = [str(new_mapping.get(col, "")) for col in headers_list]
        ws.append_row(values, value_input_option="USER_ENTERED")


def delete_course_item_mappings(
    spreadsheet: gspread.Spreadsheet,
    course_id: str,
) -> int:
    """íŠ¹ì • course_idì™€ ë§¤í•‘ëœ Course_Item_Map í–‰ ì‚­ì œ"""

    ws = spreadsheet.worksheet("Course_Item_Map")
    all_values = ws.get_all_values()

    if not all_values:
        return 0

    header = all_values[0]
    try:
        course_idx = header.index("course_id")
    except ValueError:
        return 0

    rows_to_delete = []
    for idx, row in enumerate(all_values[1:], start=2):
        if len(row) <= course_idx:
            continue
        if str(row[course_idx]).strip() == str(course_id):
            rows_to_delete.append(idx)

    for row_num in reversed(rows_to_delete):
        ws.delete_rows(row_num)

    return len(rows_to_delete)
    
