import os
import hashlib
import json
from datetime import datetime, date as datetime_date, timedelta, timezone
from typing import Dict, List
from collections import Counter, defaultdict
import io

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import time

from gsheets_utils import (
    get_client,
    open_or_create_spreadsheet,
    ensure_schema,
    upsert_course,
    list_courses,
    list_questions,
    upsert_question,
    delete_question,
    get_survey_settings,
    set_survey_active,
    save_response,
    update_response_stats,
    get_course_by_id,
    get_responses_for_course,
    get_responses_by_question,
    save_analysis,
    # ìƒˆ v2 ìŠ¤í‚¤ë§ˆ í•¨ìˆ˜ë“¤
    upsert_course_v2,
    list_courses_v2,
    get_course_by_id_v2,
    get_course_items,
    upsert_survey_item,
    map_item_to_course,
    save_response_v2,
    save_respondent,
    get_responses_v2,
    save_insight,
    get_insights,
    list_survey_items,
    get_survey_item_by_code,
    initialize_standard_lookups,
    initialize_standard_items,
    # í—¤ë” ê¸°ë°˜ ìë™ ë“±ë¡ í•¨ìˆ˜ë“¤
    ensure_survey_items_from_headers,
    ensure_course_item_mapping,
    delete_course_item_mappings,
)


APP_TITLE = "êµìœ¡ ì„¤ë¬¸ í”Œë«í¼"
ADMIN_BADGE = "ê´€ë¦¬ì ëª¨ë“œ"


# ============================================================================
# í—¬í¼ í•¨ìˆ˜: ID ë°œê¸‰, íƒ€ì… ì¶”ë¡  ë“±
# ============================================================================

def generate_course_id() -> str:
    """course_id ìë™ ìƒì„±: C-YYYY-nnn í˜•ì‹"""
    from datetime import datetime
    year = datetime.now().year
    random_suffix = str(int(datetime.utcnow().timestamp()))[-3:]
    return f"C-{year}-{random_suffix}"


def generate_item_id() -> str:
    """item_id ìë™ ìƒì„±"""
    return f"I-{int(datetime.utcnow().timestamp() * 1000)}"


def generate_respondent_id() -> str:
    """respondent_id ìë™ ìƒì„±"""
    import uuid
    return f"U-{str(uuid.uuid4())[:8]}"


def generate_response_id() -> str:
    """response_id ìë™ ìƒì„±"""
    return f"R-{int(datetime.utcnow().timestamp() * 1000000)}"


def generate_batch_id() -> str:
    """ingest_batch_id ìƒì„±"""
    return f"B-{int(datetime.utcnow().timestamp())}"


def normalize_company_name(company_name: str) -> str:
    """ì†Œì† íšŒì‚¬ëª…ì„ ì •ê·œí™”í•˜ì—¬ ëŒ€ì†Œë¬¸ì ë° ì¼ë¶€ í‚¤ì›Œë“œ ë¶ˆì¼ì¹˜ë¥¼ í•´ê²°
    
    Examples:
        "SKí•˜ì´ë‹‰ìŠ¤" â†’ "SKhynix"
        "ì£¼ì‹íšŒì‚¬ SKì´ë…¸ë² ì´ì…˜" â†’ "SKinnovation"
        "sk telecom" â†’ "SKtelecom"
        "ì—ìŠ¤ì¼€ì´í…”ë ˆì½¤" â†’ "SKtelecom"
    """
    if not company_name or not str(company_name).strip():
        return ""
    
    # 1. ì•ë’¤ ê³µë°± ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
    name = str(company_name).strip().lower()
    
    # 2. ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œ/íŠ¹ìˆ˜ë¬¸ì ì œê±°
    replacements = {
        "ì£¼ì‹íšŒì‚¬": "", 
        "ì£¼)": "", 
        "(ì£¼)": "", 
        "ãˆœ": "",
        " ": "",
        ".": "",
        ",": "",
        "í•˜ì´ë‹‰ìŠ¤": "hynix", 
        "ì—ìŠ¤ì¼€ì´": "sk", 
        "ì´ë…¸ë² ì´ì…˜": "innovation",
        "í…”ë ˆì½¤": "telecom"
    }
    for old, new in replacements.items():
        name = name.replace(old, new)
    
    # 3. í•µì‹¬ í‚¤ì›Œë“œ ë§¤í•‘ (ê°€ì¥ ì¼ë°˜ì ì¸ SK ê³„ì—´ì‚¬)
    if "hynix" in name or "í•˜ì´ë‹‰ìŠ¤" in name:
        return "SKhynix"
    if "innovation" in name or "ì´ë…¸ë² ì´ì…˜" in name:
        return "SKinnovation"
    if "telecom" in name or "í…”ë ˆì½¤" in name:
        return "SKtelecom"
    if name in ["skt", "tsk"]:
        return "SKtelecom"
    
    # 4. ê¸°íƒ€ SK ê³„ì—´ì‚¬ ì²˜ë¦¬
    if name.startswith("sk") and len(name) > 2:
        # SKë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° ì²« ê¸€ìë¥¼ ëŒ€ë¬¸ìë¡œ
        return "SK" + name[2:].capitalize()
    
    # 5. ì •ê·œí™” ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë¬¸ìì—´ì„ íƒ€ì´í‹€ ì¼€ì´ìŠ¤ë¡œ ë°˜í™˜
    return company_name.strip().title()


def infer_metric_type_from_text(text: str) -> str:
    """ë¬¸í•­ í…ìŠ¤íŠ¸ì—ì„œ metric_type ì¶”ë¡ """
    text_lower = text.lower()

    # ğŸš¨ í•µì‹¬ ìˆ˜ì •: ë©”íƒ€ë°ì´í„°ì„± í•­ëª©ì„ 'text' íƒ€ì…ìœ¼ë¡œ ê°•ì œ ì¸ì‹
    # "ì†Œì† íšŒì‚¬", "ì§êµ°", "ì—°ì°¨", "íšŒì‚¬ëª…" ê°™ì€ í•­ëª©ì€ ì£¼ê´€ì‹ í…ìŠ¤íŠ¸ë¡œ ìˆ˜ì§‘
    metadata_text_keywords = ["ì§êµ°", "ì—°ì°¨", "íšŒì‚¬ëª…", "íšŒì‚¬", "ì†Œì†", "ë¶€ì„œ", "ì§ë¬´", "ì§ì±…"]
    for keyword in metadata_text_keywords:
        if keyword in text_lower:
            return "text"

    if "ë§Œì¡±" in text_lower or "í‰ê°€" in text_lower or "ì ìˆ˜" in text_lower:
        return "likert"
    elif "ì¶”ì²œ" in text_lower and ("10" in text or "0~10" in text):
        return "nps"
    elif "ì„ íƒ" in text_lower and ("í•˜ë‚˜" in text_lower or "ë‹¨ì¼" in text_lower):
        return "single_choice"
    elif "ì„ íƒ" in text_lower and ("ì—¬ëŸ¬" in text_lower or "ë³µìˆ˜" in text_lower or "ë‹¤ì¤‘" in text_lower):
        return "multi_choice"
    else:
        return "text"


def infer_dimension_from_text(text: str) -> str:
    """ë¬¸í•­ í…ìŠ¤íŠ¸ì—ì„œ dimension ì¶”ë¡ """
    text_lower = text.lower()

    if "ë§Œì¡±" in text_lower:
        return "satisfaction"
    elif "ë‚œì´ë„" in text_lower or "ì–´ë ¤" in text_lower:
        return "difficulty"
    elif "ì´í•´" in text_lower:
        return "understanding"
    elif "ì¶”ì²œ" in text_lower:
        return "recommend"
    elif "ìš´ì˜" in text_lower or "ì§„í–‰" in text_lower:
        return "operations"
    else:
        return "content"


def convert_answer_to_numeric(
    answer: str,
    metric_type: str,
     scale_max: int = 5) -> str:
    """ì‘ë‹µì„ ìˆ«ìë¡œ ë³€í™˜"""
    try:
        return str(float(answer))
    except (ValueError, TypeError):
        # í…ìŠ¤íŠ¸ ë§¤í•‘
        if metric_type in ["likert", "nps"]:
            if "ë§¤ìš°" in str(answer) and (
    "ë§Œì¡±" in str(answer) or "ê·¸ë ‡ë‹¤" in str(answer)):
                return str(scale_max)
            elif "ë§Œì¡±" in str(answer) or "ê·¸ë ‡ë‹¤" in str(answer):
                return str(scale_max - 1)
            elif "ë³´í†µ" in str(answer):
                return str(scale_max // 2)
        return ""


def safe_str(val) -> str:
    """None/ê³µë°±/íŠ¹ìˆ˜ë¬¸ìë¥¼ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if val is None:
        return ""

    # ë¬¸ìì—´ë¡œ ë³€í™˜
    s = str(val)

    # Zero-width space ì œê±°
    ZWSP = "\u200b"
    s = s.replace(ZWSP, "")

    # ì•ë’¤ ê³µë°± ì œê±°
    s = s.strip()

    # ì—°ì†ëœ ê³µë°±/ê°œí–‰ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ
    import re
    s = re.sub(r'\s+', ' ', s)

    return s


def safe_date(val) -> str:
    """ë‚ ì§œë¥¼ ì•ˆì „í•˜ê²Œ ISO í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not val:
        return ""

    # ì´ë¯¸ date/datetime ê°ì²´ì¸ ê²½ìš°
    if isinstance(val, (datetime_date, datetime)):
        return val.strftime("%Y-%m-%d") if hasattr(val,
                            'strftime') else str(val)

    # ë¬¸ìì—´ì¸ ê²½ìš°
    s = safe_str(val).replace("/", "-")
    if not s:
        return ""

    try:
        # YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ íŒŒì‹± ì‹œë„
        parsed = datetime.strptime(s, "%Y-%m-%d")
        return parsed.date().isoformat()
    except Exception:
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
        return s


def read_uploaded_any(uploaded_file):
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œ (ëª¨ë“  ì‹œíŠ¸ ë˜ëŠ” CSV)
    
    Returns:
        (sheets_dict, meta) - sheets_dictëŠ” Dict[str, DataFrame] ë˜ëŠ” None
    """
    if not uploaded_file:
        st.warning("ğŸ“ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return None, None

    filename = uploaded_file.name.lower()
    
    # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ
    uploaded_file.seek(0)
    raw = uploaded_file.read()
    
    if not raw:
        st.error("âŒ ì—…ë¡œë“œëœ íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return None, None

    buf = io.BytesIO(raw)
    meta = {"filename": filename, "size": len(raw)}

    try:
        if filename.endswith((".xlsx", ".xlsm")):
            # ì—‘ì…€ êµ¬ì¡° ê±´ê°•ê²€ì§„ (Zip ìœ íš¨ì„±)
            import zipfile
            try:
                buf.seek(0)
                with zipfile.ZipFile(buf) as zf:
                    _ = zf.namelist()  # ì ‘ê·¼ë§Œ
            except zipfile.BadZipFile:
                st.error("âŒ ì—‘ì…€ íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ì••ì¶• êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                st.info("ğŸ’¡ í•´ê²°ë°©ë²•: ì—‘ì…€/êµ¬ê¸€ì‹œíŠ¸ì—ì„œ 'ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì €ì¥' í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
                return None, meta

            buf.seek(0)
            # ëª¨ë“  ì‹œíŠ¸ ë¡œë“œ: sheet_name=None â†’ dict[str, DataFrame]
            try:
                xl = pd.read_excel(buf, sheet_name=None, engine="openpyxl", dtype=str)
                
                # íŒŒì¼ í¬ì¸í„°ë¥¼ ë‹¤ì‹œ ì²˜ìŒìœ¼ë¡œ
                uploaded_file.seek(0)
                
                return xl, meta
            except Exception as e:
                st.error(f"âŒ Excel íŒŒì¼ íŒŒì‹± ìµœì¢… ì‹¤íŒ¨: {uploaded_file.name}")
                st.warning("âš ï¸ íŒŒì¼ ë‚´ë¶€ XMLì´ ì†ìƒë˜ì—ˆê±°ë‚˜ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” í˜•ì‹ì…ë‹ˆë‹¤.")
                st.info(
                    "ğŸ’¡ **í•´ê²°ë°©ë²• (ìš°ì„ ìˆœìœ„ ìˆœì„œ)**:\n\n"
                    "1. **CSV í˜•ì‹ìœ¼ë¡œ ë³€í™˜** (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)\n"
                    "   - ì—‘ì…€ì—ì„œ íŒŒì¼ ì—´ê¸° â†’ 'ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì €ì¥' â†’ 'CSV UTF-8(ì‰¼í‘œë¡œ ë¶„ë¦¬)' ì„ íƒ\n\n"
                    "2. **ìƒˆ ì—‘ì…€ íŒŒì¼ë¡œ ì¬ìƒì„±**\n"
                    "   - íŒŒì¼ ë‚´ìš© ì „ì²´ ë³µì‚¬ â†’ ìƒˆ Excel íŒŒì¼ì— ë¶™ì—¬ë„£ê¸° â†’ ì €ì¥\n\n"
                    "3. **Google Sheets ê²½ìœ **\n"
                    "   - Google Sheetsì— ì—…ë¡œë“œ â†’ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ (xlsx ë˜ëŠ” csv)"
                )
                with st.expander("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ë©”ì‹œì§€ (ê°œë°œì ì°¸ê³ )"):
                    st.code(str(e))
                    st.caption("ì´ ì˜¤ë¥˜ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì†ìƒëœ XML êµ¬ì¡°, ì§€ì›ë˜ì§€ ì•ŠëŠ” Excel ê¸°ëŠ¥ ì‚¬ìš©, ë˜ëŠ” íŒŒì¼ ì¸ì½”ë”© ë¬¸ì œë¡œ ë°œìƒí•©ë‹ˆë‹¤.")
                return None, meta

        elif filename.endswith(".xls"):
            buf.seek(0)
            try:
                # xlrdëŠ” xlsë§Œ ì§€ì› (ì„¤ì¹˜ í•„ìš”)
                xl = pd.read_excel(buf, sheet_name=None, engine="xlrd", dtype=str)
                uploaded_file.seek(0)
                return xl, meta
            except ImportError:
                st.error("âŒ .xls íŒŒì¼ ì½ê¸°ë¥¼ ìœ„í•´ xlrd íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                st.info("ğŸ’¡ ì„¤ì¹˜: pip install xlrd")
                return None, meta
            except Exception as e:
                st.error(f"âŒ .xls íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                return None, meta

        elif filename.endswith(".xlsb"):
            buf.seek(0)
            try:
                # pyxlsb ì—”ì§„ (ì„¤ì¹˜ í•„ìš”)
                xl = pd.read_excel(buf, sheet_name=None, engine="pyxlsb", dtype=str)
                uploaded_file.seek(0)
                return xl, meta
            except ImportError:
                st.error("âŒ .xlsb íŒŒì¼ ì½ê¸°ë¥¼ ìœ„í•´ pyxlsb íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                st.info("ğŸ’¡ ì„¤ì¹˜: pip install pyxlsb")
                return None, meta
            except Exception as e:
                st.error(f"âŒ .xlsb íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                return None, meta

        elif filename.endswith(".csv"):
            # CSVëŠ” ë‹¨ì¼ DFë¡œ ë°˜í™˜, í‘œì¤€ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ„í•´ dictë¡œ ê°ìŒˆ
            df = None
            for encoding in ["utf-8-sig", "cp949", "euc-kr", "utf-8"]:
                try:
                    buf.seek(0)
                    df = pd.read_csv(buf, encoding=encoding, dtype=str)
                    break
                except UnicodeDecodeError:
                    continue
                except Exception:
                    continue
            
            if df is None:
                st.error("âŒ CSV ì¸ì½”ë”© íŒŒì‹± ì‹¤íŒ¨")
                st.info("ğŸ’¡ UTF-8 â†’ CP949 â†’ EUC-KR ìˆœìœ¼ë¡œ ì‹œë„í–ˆìœ¼ë‚˜ ëª¨ë‘ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. CSV ì¸ì½”ë”©ì„ í™•ì¸í•˜ì„¸ìš”.")
                return None, meta
            
            uploaded_file.seek(0)
            return {"Questions": df}, meta

        else:
            st.error("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
            st.info("ğŸ’¡ .xlsx / .xls / .xlsb / .csv íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            return None, meta

    except Exception as e:
        st.error(f"âŒ íŒŒì¼ íŒŒì‹± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.info("ğŸ’¡ íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        import traceback
        with st.expander("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
            st.code(traceback.format_exc())
        return None, meta


def pick_questions_sheet(sheets_dict):
    """Questions ì‹œíŠ¸ ì„ íƒ/ëŒ€ì²´ ë¡œì§
    
    Returns:
        DataFrame ë˜ëŠ” None
    """
    if sheets_dict is None or not sheets_dict:
        st.error("âŒ ì‹œíŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # ì‹œíŠ¸ëª… ì •ê·œí™”
    keys = {k: k for k in sheets_dict.keys()}
    lower = {k.lower(): k for k in sheets_dict.keys()}
    
    # ë””ë²„ê¹…: ì‹œíŠ¸ ëª©ë¡ í‘œì‹œ
    with st.expander("ğŸ“‹ íŒŒì¼ ë‚´ ì‹œíŠ¸ ëª©ë¡"):
        for idx, (name, df) in enumerate(sheets_dict.items(), 1):
            st.write(f"{idx}. **{name}** - {len(df)}í–‰ Ã— {len(df.columns)}ì—´")

    # 1) ìš°ì„ ìˆœìœ„ ë§¤ì¹­
    for candidate in ["questions", "ë¬¸í•­", "ì§ˆë¬¸", "survey_items", "ì„¤ë¬¸ë¬¸í•­", "sheet1"]:
        if candidate in lower:
            matched_key = lower[candidate]
            st.success(f"âœ… '{matched_key}' ì‹œíŠ¸ë¥¼ Questionsë¡œ ìë™ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
            return sheets_dict[matched_key]

    # 2) ìë™ ì¶”ì •: ì»¬ëŸ¼ íŒ¨í„´ í¬í•¨ DF ì°¾ê¸°
    def looks_like_questions(df):
        if df is None or df.empty:
            return False
        cols = [str(c).strip().lower() for c in df.columns]
        keywords = ["question", "ë¬¸í•­", "ì§ˆë¬¸", "ì˜µì…˜", "option", "scale", "ì‘ë‹µ", "answer", "choice"]
        hit = sum(any(k in c for k in keywords) for c in cols)
        return hit >= 1 and len(cols) >= 1 and len(df) >= 1

    candidates = [(name, df) for name, df in sheets_dict.items() 
                  if isinstance(df, pd.DataFrame) and looks_like_questions(df)]
    
    if len(candidates) == 1:
        name, df = candidates[0]
        st.success(f"âœ… '{name}' ì‹œíŠ¸ê°€ Questions íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ì—¬ ìë™ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
        return df

    # 3) ì‚¬ìš©ìê°€ ì„ íƒí•˜ë„ë¡ ë“œë¡­ë‹¤ìš´
    st.warning("âš ï¸ 'Questions' ì‹œíŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.info("ğŸ’¡ ì•„ë˜ì—ì„œ Questions ì—­í• ì„ í•  ì‹œíŠ¸ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    
    choice = st.selectbox(
        "ì‹œíŠ¸ ì„ íƒ",
        list(keys.keys()),
        format_func=lambda x: f"{x} ({len(sheets_dict[x])}í–‰)"
    )
    
    if choice:
        return sheets_dict[keys[choice]]
    
    return None


def normalize_questions_wide(df):
    """wide í¬ë§· ìœ íš¨ì„± ê²€ì‚¬ & ì •ë¦¬
    
    Returns:
        ì •ë¦¬ëœ DataFrame
    """
    if df is None or df.empty:
        st.error("âŒ Questions ì‹œíŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    # ê³µë°±/ë¹ˆì—´ ì œê±°, ì¤‘ë³µì»¬ëŸ¼ ì²˜ë¦¬
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    df = df.loc[:, ~df.columns.duplicated(keep="first")]
    
    # ì™„ì „ ê³µë°± í–‰ ì œê±°
    df = df.dropna(how="all")
    
    if df.empty:
        st.error("âŒ Questions ì‹œíŠ¸ì˜ ëª¨ë“  í–‰ì´ ë¹„ì–´ìˆê±°ë‚˜ ê²°ì¸¡ì…ë‹ˆë‹¤.")
        return df
    
    return df


def load_uploaded_file(uploaded_file):
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ìë™ í¬ë§· ê°ì§€ í›„ DataFrameìœ¼ë¡œ ë¡œë“œ (ë ˆê±°ì‹œ í˜¸í™˜)
    
    ë‹¨ì¼ DataFrame ë°˜í™˜ (ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜)
    """
    sheets, meta = read_uploaded_any(uploaded_file)
    if sheets is None:
        return None
    
    # Questions ì‹œíŠ¸ ì„ íƒ
    qdf = pick_questions_sheet(sheets)
    if qdf is None:
        st.error("âŒ Questions ì‹œíŠ¸ë¥¼ ì„ íƒ/ì¶”ì •í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None
    
    # ì •ê·œí™”
    qdf = normalize_questions_wide(qdf)
    if qdf.empty:
        return None
    
    st.success(f"âœ… Questions ì‹œíŠ¸ ë¡œë“œ ì™„ë£Œ: {meta['filename']} | {len(qdf)}í–‰ Ã— {len(qdf.columns)}ì—´")
    
    with st.expander("ğŸ‘€ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
        st.dataframe(qdf.head(10))
    
    return qdf


def set_page_config():
    st.set_page_config(page_title=APP_TITLE, page_icon="ğŸ“Š", layout="wide")


def apply_global_styles():
    """Inject global CSS variables, fonts, and component theming for SK style."""
    # Plotly theme defaults (colors align with SK palette)
    try:
        primary = "#D90B31"
        secondary = "#404040"
        accent1 = "#F26680"
        accent2 = "#020659"
        neutral = "#D9D9D9"
        px.defaults.template = "plotly_white"
        px.defaults.color_discrete_sequence = [
    primary, accent1, accent2, secondary, neutral]
    except Exception:
        pass

    # Fonts: The Jamsil family (Noonnu CDN)
    st.markdown(
        """
        <style>
          @import url('https://cdn.jsdelivr.net/gh/projectnoonnu/noonfonts_2307@1.1.0/fonts/TheJamsil5Bold.woff2');
          @import url('https://cdn.jsdelivr.net/gh/projectnoonnu/noonfonts_2307@1.1.0/fonts/TheJamsil6ExtraBold.woff2');
          @font-face { font-family: 'TheJamsil-6'; src: url('https://cdn.jsdelivr.net/gh/projectnoonnu/noonfonts_2307@1.1.0/fonts/TheJamsil6ExtraBold.woff2') format('woff2'); font-weight: 800; font-style: normal; }
          @font-face { font-family: 'TheJamsil-5'; src: url('https://cdn.jsdelivr.net/gh/projectnoonnu/noonfonts_2307@1.1.0/fonts/TheJamsil5Bold.woff2') format('woff2'); font-weight: 700; font-style: normal; }
          @font-face { font-family: 'TheJamsil-4'; src: url('https://cdn.jsdelivr.net/gh/projectnoonnu/noonfonts_2307@1.1.0/fonts/TheJamsil4Medium.woff2') format('woff2'); font-weight: 500; font-style: normal; }
          @font-face { font-family: 'TheJamsil-3'; src: url('https://cdn.jsdelivr.net/gh/projectnoonnu/noonfonts_2307@1.1.0/fonts/TheJamsil3Regular.woff2') format('woff2'); font-weight: 400; font-style: normal; }

          :root {
            --pastel-blue: #A8D8EA;
            --pastel-purple: #D4A5D8;
            --pastel-pink: #FFB3C1;
            --pastel-mint: #B5EAD7;
            --pastel-lavender: #C7CEEA;
            --pastel-peach: #FFDAB9;
            --dark-text: #2C3E50;
            --light-text: #7F8C8D;
            --bg-soft: #F8F9FA;
          }

          html, body, [class^="main"] { font-family: 'TheJamsil-3', system-ui, -apple-system, Segoe UI, Roboto, 'Noto Sans KR', Arial, sans-serif; }

          /* SVG ì•„ì´ì½˜ ìŠ¤íƒ€ì¼ */
          .icon-svg {
            width: 24px;
            height: 24px;
            display: inline-block;
            vertical-align: middle;
            margin-right: 8px;
          }
          
          .icon-chip { stroke: var(--pastel-blue); fill: none; stroke-width: 2; }
          .icon-chart { stroke: var(--pastel-purple); fill: none; stroke-width: 2; }
          .icon-star { stroke: var(--pastel-peach); fill: none; stroke-width: 2; }
          .icon-message { stroke: var(--pastel-mint); fill: none; stroke-width: 2; }
          .icon-brain { stroke: var(--pastel-lavender); fill: none; stroke-width: 2; }

          /* Headings */
          h1, .sk-h1 { 
            font-family: 'TheJamsil-6', sans-serif; 
            color: var(--dark-text); 
            letter-spacing: -0.2px; 
          }
          h2, .sk-h2 { 
            font-family: 'TheJamsil-5', sans-serif; 
            color: var(--dark-text); 
          }
          h3, .sk-h3 { 
            font-family: 'TheJamsil-5', sans-serif; 
            color: var(--dark-text); 
          }

          /* Sidebar */
          section[data-testid="stSidebar"] { 
            border-right: 2px solid var(--pastel-lavender);
            background: linear-gradient(180deg, #ffffff 0%, var(--bg-soft) 100%);
          }
          section[data-testid="stSidebar"] .css-1d391kg, 
          section[data-testid="stSidebar"] * { 
            font-family: 'TheJamsil-4', sans-serif; 
          }

          /* Buttons */
          .stButton > button {
            background: linear-gradient(135deg, var(--pastel-blue) 0%, var(--pastel-lavender) 100%) !important;
            color: var(--dark-text) !important;
            border: 2px solid var(--pastel-purple) !important;
            border-radius: 12px !important;
            padding: 0.6rem 1.2rem !important;
            font-family: 'TheJamsil-5', sans-serif;
            box-shadow: 0 4px 12px rgba(168, 216, 234, 0.3);
            transition: all 0.3s ease;
          }
          .stButton > button:hover { 
            transform: translateY(-2px);
            box-shadow: 0 6px 16px rgba(168, 216, 234, 0.5);
          }
          .stButton > button:focus { 
            outline: 3px solid var(--pastel-mint);
            outline-offset: 2px;
          }

          /* Selects, inputs */
          .stSelectbox div[data-baseweb="select"] > div,
          .stTextInput > div > div > input,
          .stTextArea textarea,
          .stRadio,
          .stSlider {
            font-family: 'TheJamsil-3', sans-serif !important;
          }

          /* Tabs */
          button[role="tab"] { 
            font-family: 'TheJamsil-4', sans-serif;
            color: var(--light-text);
            transition: all 0.3s ease;
          }
          button[role="tab"][aria-selected="true"] { 
            color: var(--dark-text);
            border-bottom: 3px solid var(--pastel-blue);
            background: linear-gradient(180deg, transparent 0%, rgba(168, 216, 234, 0.1) 100%);
          }
          button[role="tab"]:hover {
            color: var(--dark-text);
            background: rgba(168, 216, 234, 0.05);
          }

          /* íŒŒìŠ¤í…” ë°°ê²½ ì¥ì‹ */
          .ai-bg-decoration {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
            z-index: -1;
            opacity: 0.4;
            background-image: 
              radial-gradient(circle at 20% 30%, rgba(168, 216, 234, 0.3) 0%, transparent 50%),
              radial-gradient(circle at 80% 70%, rgba(212, 165, 216, 0.2) 0%, transparent 50%),
              radial-gradient(circle at 50% 50%, rgba(181, 234, 215, 0.15) 0%, transparent 60%);
          }

          /* Cards - íŒŒìŠ¤í…” ì„ í˜• ìŠ¤íƒ€ì¼ */
          .sk-card {
            border: 2px solid var(--pastel-lavender);
            border-radius: 20px;
            padding: 24px;
            background: linear-gradient(145deg, #ffffff 0%, rgba(168, 216, 234, 0.05) 100%);
            box-shadow: 
              0 8px 24px rgba(168, 216, 234, 0.15),
              0 4px 12px rgba(212, 165, 216, 0.1),
              inset 0 1px 0 rgba(255, 255, 255, 0.9);
            position: relative;
            overflow: hidden;
            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
          }
          
          .sk-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: linear-gradient(90deg, 
              var(--pastel-blue) 0%, 
              var(--pastel-purple) 25%, 
              var(--pastel-pink) 50%, 
              var(--pastel-mint) 75%, 
              var(--pastel-lavender) 100%);
            border-radius: 20px 20px 0 0;
            opacity: 0.7;
            transition: all 0.4s ease;
          }
          
          .sk-card:hover {
            transform: translateY(-6px);
            border-color: var(--pastel-purple);
            box-shadow: 
              0 12px 32px rgba(168, 216, 234, 0.25),
              0 6px 16px rgba(212, 165, 216, 0.2),
              inset 0 1px 0 rgba(255, 255, 255, 1);
          }
          
          .sk-card:hover::before {
            height: 4px;
            opacity: 1;
          }
          
          .sk-card h4 {
            margin: 0 0 12px 0;
            font-family: 'TheJamsil-5';
            color: var(--dark-text);
            font-size: 1.2rem;
            display: flex;
            align-items: center;
          }
          
          .sk-card .sk-desc {
            color: var(--light-text);
            font-family: 'TheJamsil-3';
            line-height: 1.7;
          }
          
          /* ì„ í˜• íŒ¨í„´ ì¥ì‹ */
          .sk-card::after {
            content: '';
            position: absolute;
            bottom: 0;
            right: 0;
            width: 120px;
            height: 120px;
            background-image: 
              repeating-linear-gradient(45deg, transparent, transparent 10px, rgba(168, 216, 234, 0.03) 10px, rgba(168, 216, 234, 0.03) 20px),
              repeating-linear-gradient(-45deg, transparent, transparent 10px, rgba(212, 165, 216, 0.03) 10px, rgba(212, 165, 216, 0.03) 20px);
            opacity: 0.6;
            pointer-events: none;
            border-radius: 0 0 20px 0;
          }

          /* Page header band */
          .sk-page-header {
            padding: 20px 24px;
            border-left: 5px solid var(--pastel-blue);
            background: linear-gradient(135deg, #ffffff 0%, rgba(168, 216, 234, 0.08) 100%);
            border-radius: 16px;
            box-shadow: 
              0 4px 16px rgba(168, 216, 234, 0.15),
              0 2px 8px rgba(212, 165, 216, 0.1);
            position: relative;
            border: 2px solid var(--pastel-lavender);
            border-left: 5px solid var(--pastel-blue);
          }
          
          .sk-page-header .title {
            font-family: 'TheJamsil-6';
            color: var(--dark-text);
            font-size: 1.7rem;
            margin-bottom: 4px;
          }
          
          .sk-page-header .subtitle {
            color: var(--light-text);
            font-size: 1rem;
          }

          /* KPIs */
          [data-testid="stMetricValue"] {
            color: var(--dark-text);
            font-family: 'TheJamsil-6';
            font-size: 1.8rem !important;
          }
          
          [data-testid="stMetric"] {
            background: linear-gradient(135deg, #ffffff 0%, rgba(168, 216, 234, 0.05) 100%);
            border-radius: 16px;
            padding: 16px;
            border: 2px solid var(--pastel-lavender);
            box-shadow: 0 4px 12px rgba(168, 216, 234, 0.1);
            transition: all 0.3s ease;
          }
          
          [data-testid="stMetric"]:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 16px rgba(168, 216, 234, 0.2);
            border-color: var(--pastel-blue);
          }
          
          [data-testid="stMetricLabel"] {
            color: var(--light-text);
            font-family: 'TheJamsil-4';
          }

          /* Mobile adjustments */
          @media (max-width: 480px) {
            .sk-page-header .title { font-size: 1.25rem; }
            .stButton > button { width: 100%; }
            .stRadio label, .stSelectbox { font-size: 0.95rem; }
            .stTextArea textarea { min-height: 120px; }
          }
        </style>
        """,
        unsafe_allow_html=True,
    )


def get_admin_password() -> str:
    # Priority: env -> st.secrets
    pwd = os.getenv("SURVEY_ADMIN_PASSWORD")
    if not pwd and hasattr(
    st,
     "secrets") and "SURVEY_ADMIN_PASSWORD" in st.secrets:
        pwd = st.secrets["SURVEY_ADMIN_PASSWORD"]
    return pwd or "skms2024"  # fallback for local dev


@st.cache_resource(ttl=600)  # Cache for 10 minutes to reduce API calls
def require_spreadsheet():
    """Get spreadsheet with caching to avoid quota issues"""
    import time

    client = get_client()
    # Use fixed spreadsheet ID from env/secrets or fallback to provided ID
    sheet_id = os.getenv("GOOGLE_SHEETS_SPREADSHEET_ID")
    if not sheet_id and hasattr(
    st, "secrets") and "GOOGLE_SHEETS_SPREADSHEET_ID" in st.secrets:
        sheet_id = st.secrets["GOOGLE_SHEETS_SPREADSHEET_ID"]
    if not sheet_id:
        # Fallback to the provided Sheet ID
        sheet_id = "1sxwBgqSqxHw1mqfxAHskspO-SCpEDWTAioII_pp7hHs"

    # Retry logic for quota errors with exponential backoff
    max_retries = 5
    for attempt in range(max_retries):
        try:
            spreadsheet = open_or_create_spreadsheet(
                client, spreadsheet_id=sheet_id)
            ensure_schema(spreadsheet)
            return spreadsheet
        except Exception as e:
            if "429" in str(e) or "Quota exceeded" in str(
                e) or "quota" in str(e).lower():
                if attempt < max_retries - 1:
                    # 2, 4, 8, 16, 32 seconds (exponential)
                    wait_time = (2 ** attempt) * 2
                    st.warning(
    f"â³ Google Sheets API ì¿¼í„° ì œí•œ ê°ì§€. {wait_time}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤... (ì‹œë„ {
        attempt + 1}/{max_retries})")
                    time.sleep(wait_time)
                    continue
                else:
                    st.error("âš ï¸ Google Sheets API ì¿¼í„°ê°€ ê³„ì† ì´ˆê³¼ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
                    st.info(
                        "ğŸ’¡ í•´ê²° ë°©ë²•:\n- í˜ì´ì§€ë¥¼ 2-3ë¶„ í›„ì— ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.\n- ì—¬ëŸ¬ ì‚¬ìš©ìê°€ ë™ì‹œì— ì ‘ê·¼ ì¤‘ì´ë¼ë©´ ì ì‹œ ëŒ€ê¸°í•˜ì„¸ìš”.\n- API ì¿¼í„°ê°€ ë¶€ì¡±í•˜ë©´ Google Cloud Consoleì—ì„œ ì¿¼í„° ì¦ê°€ë¥¼ ìš”ì²­í•˜ì„¸ìš”.")
                    st.stop()
            else:
                st.error(f"ì˜¤ë¥˜: {str(e)}")
                st.stop()


def sidebar_mode_selector():
    """ì‚¬ì´ë“œë°”ì— ëª¨ë“œ ì„ íƒê¸° í‘œì‹œ"""
    st.sidebar.markdown(
        """
        <div class="sk-page-header" style="margin-bottom:8px;">
          <div class="title" style="font-size:1.1rem;">ğŸ”§ ëª¨ë“œ ì„ íƒ</div>
          <div class="subtitle" style="font-size:0.9rem;">ì‚¬ìš©ì / ê´€ë¦¬ì</div>
        </div>
        """,
        unsafe_allow_html=True,
    )
    mode = st.sidebar.selectbox(
        "ì ‘ê·¼ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        ["ì¼ë°˜ ì‚¬ìš©ì", "ê´€ë¦¬ì"],
        index=0
    )
    return mode == "ê´€ë¦¬ì"


def authenticate_if_needed(is_admin_mode: bool):
    if is_admin_mode and not st.session_state.get("admin_authenticated"):
        with st.sidebar:
            st.markdown("### ê´€ë¦¬ì ì¸ì¦")
            pwd = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
            if st.button("ì¸ì¦"):
                if pwd == get_admin_password():
                    st.session_state["admin_authenticated"] = True
                    st.session_state["admin_expire_at"] = (
                        datetime.now(timezone.utc) + timedelta(minutes=30)
                    ).isoformat()
                    st.success("ì¸ì¦ ì„±ê³µ")
                else:
                    st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤")

    # Expire admin session
    expire_at = st.session_state.get("admin_expire_at")
    if expire_at and datetime.now(
    timezone.utc) > datetime.fromisoformat(expire_at):
        st.session_state["admin_authenticated"] = False
        st.session_state["admin_expire_at"] = None


def page_setup_db(spreadsheet):
    st.subheader("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### ğŸ“‹ ìŠ¤í‚¤ë§ˆ ìƒì„±")
        st.write("í•„ìš”í•œ ì‹œíŠ¸ë¥¼ ìƒì„±í•˜ê³  í—¤ë”ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.")
        if st.button("ìŠ¤í‚¤ë§ˆ ë³´ì¦ ì‹¤í–‰"):
            with st.spinner("ìŠ¤í‚¤ë§ˆ ìƒì„± ì¤‘..."):
                ensure_schema(spreadsheet)
                st.success("âœ… ì‹œíŠ¸ ìŠ¤í‚¤ë§ˆê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

    with col2:
        st.markdown("#### âœ¨ v2 ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™”")
        st.write("í‘œì¤€ê°’ ë° í‘œì¤€ ë¬¸í•­ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
        if st.button("v2 ì´ˆê¸°í™” ì‹¤í–‰"):
            with st.spinner("v2 ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™” ì¤‘..."):
                try:
                    # 1. í‘œì¤€ê°’ ì‚¬ì „ ì´ˆê¸°í™”
                    initialize_standard_lookups(spreadsheet)
                    st.success("âœ… Lookups ì‹œíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

                    # 2. í‘œì¤€ ë¬¸í•­ ì´ˆê¸°í™”
                    initialize_standard_items(spreadsheet)
                    st.success("âœ… Survey_Items ì‹œíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

                    st.balloons()
                    st.info("ğŸ’¡ ì´ì œ í‘œì¤€ ë¬¸í•­ì„ ì¬ì‚¬ìš©í•˜ì—¬ ìƒˆ ê³¼ì •ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
                except Exception as e:
                    st.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

    # ì‹œíŠ¸ ëª©ë¡ í‘œì‹œ
    st.divider()
    st.markdown("#### ğŸ“Š í˜„ì¬ ì‹œíŠ¸ ëª©ë¡")

    try:
        worksheets = spreadsheet.worksheets()

        # ìƒˆ ìŠ¤í‚¤ë§ˆ ì‹œíŠ¸
        v2_sheets = [
    "Survey_Items",
    "Course_Item_Map",
    "Respondents",
    "Insights",
     "Lookups"]
        # ë ˆê±°ì‹œ ì‹œíŠ¸
        legacy_sheets = ["Questions", "ResponseStats", "Analysis"]

        cols = st.columns(3)
        for idx, ws in enumerate(worksheets):
            with cols[idx % 3]:
                if ws.title in v2_sheets:
                    st.success(f"âœ¨ {ws.title} (v2)")
                elif ws.title in legacy_sheets:
                    st.warning(f"âš ï¸ {ws.title} (ë ˆê±°ì‹œ)")
                else:
                    st.info(f"ğŸ“„ {ws.title}")

        # ë ˆê±°ì‹œ ì‹œíŠ¸ ì •ë¦¬ ì•ˆë‚´
        if any(ws.title in legacy_sheets for ws in worksheets):
            st.divider()
            st.warning("âš ï¸ ë ˆê±°ì‹œ ì‹œíŠ¸ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.caption("í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
            st.code(
    "python cleanup_legacy_sheets.py --dry-run",
     language="bash")

    except Exception as e:
        st.error(f"ì‹œíŠ¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


def _detect_uploaded_frames(uploaded_file) -> Dict[str, pd.DataFrame]:
    """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ Course/Questions/Responsesë¥¼ ìë™ ê°ì§€í•´ DataFrameìœ¼ë¡œ ë°˜í™˜"""
    dfs: Dict[str, pd.DataFrame] = {}
    try:
        if uploaded_file.name.lower().endswith(".xlsx"):
            xls = pd.ExcelFile(uploaded_file, engine='openpyxl')
            sheet_names_lower = {s.lower(): s for s in xls.sheet_names}
            # í‘œì¤€ ì‹œíŠ¸ëª… ìš°ì„ 
            if "course" in sheet_names_lower:
                dfs["course"] = pd.read_excel(
    xls, sheet_name=sheet_names_lower["course"], engine='openpyxl')  # type: ignore
            if "questions" in sheet_names_lower:
                dfs["questions"] = pd.read_excel(
    xls, sheet_name=sheet_names_lower["questions"], engine='openpyxl')  # type: ignore
            if "responses" in sheet_names_lower:
                dfs["responses"] = pd.read_excel(
    xls, sheet_name=sheet_names_lower["responses"], engine='openpyxl')  # type: ignore
            # ë³´ì¡°: ì²« 1~3 ì‹œíŠ¸ë¥¼ heuristicìœ¼ë¡œ ë§¤í•‘
            if not dfs:
                sheets = xls.sheet_names[:3]
                for s in sheets:
                    df = pd.read_excel(xls, sheet_name=s, engine='openpyxl')
                    cols = {c.strip().lower() for c in df.columns.astype(str)}
                    if {"courseid", "title"}.issubset(cols):
                        dfs["course"] = df
                    elif {"questionid", "text", "type"}.issubset(cols):
                        dfs["questions"] = df
                    elif {"courseid", "questionid", "answer"}.issubset(cols):
                        dfs["responses"] = df
        else:
            # CSV: í—¤ë” ê¸°ë°˜ìœ¼ë¡œ ìœ í˜• ê°ì§€ (ë‹¤ì¤‘ ì¸ì½”ë”© ì‹œë„)
            data = uploaded_file.read()
            buf = io.BytesIO(data)
            df = None
            for enc in (
    None,
    "utf-8",
    "utf-8-sig",
    "cp949",
    "euc-kr",
     "latin1"):
                try:
                    buf.seek(0)
                    if enc is None:
                        df = pd.read_csv(buf)
                    else:
                        df = pd.read_csv(buf, encoding=enc)
                    break
                except Exception:
                    continue
            if df is None:
                raise ValueError("CSV ì¸ì½”ë”©ì„ íŒë³„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            try:
                uploaded_file.seek(0)
            except Exception:
                pass
            cols = {c.strip().lower() for c in df.columns.astype(str)}
            if {"courseid", "title"}.issubset(cols):
                dfs["course"] = df
            if {"questionid", "text", "type"}.issubset(cols):
                dfs["questions"] = df
            if {"courseid", "questionid", "answer"}.issubset(cols):
                dfs["responses"] = df
    except Exception as e:
        st.error(f"íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
    return dfs


def _normalize_question_row(row: Dict) -> Dict:
    """ì—…ë¡œë“œ ì§ˆë¬¸ í–‰ì„ ë‚´ë¶€ ìŠ¤í‚¤ë§ˆë¡œ ì •ê·œí™”"""
    def get_str(key: str, default: str = ""):
        v = row.get(key)
        return "" if v is None else str(v).strip()

    q: Dict[str, str] = {}
    q["questionId"] = get_str("questionId") or get_str(
        "id") or str(int(datetime.utcnow().timestamp() * 1000))
    q["courseId"] = get_str("courseId")
    q["order"] = get_str("order") or get_str("displayOrder") or ""
    q["text"] = get_str("text") or get_str("question")
    q_type = (get_str("type") or "subjective").lower()
    if q_type not in {"objective", "subjective", "rating"}:
        q_type = "subjective"
    q["type"] = q_type

    # choices
    choices_json = get_str("choicesJson")
    if not choices_json and get_str("choices"):
        raw = [c.strip() for c in get_str("choices").split(",") if c.strip()]
        choices_json = "[" + \
            ",".join([f'\"{c}\"' for c in raw]) + "]" if raw else "[]"
    q["choicesJson"] = choices_json or "[]"

    # rating
    q["ratingMax"] = get_str("ratingMax") or (get_str("maxRating") or "")

    # required
    is_required = get_str("isRequired") or get_str("required")
    q["isRequired"] = "TRUE" if is_required.lower() in {
    "true", "1", "yes", "y"} else (
        "TRUE" if is_required == "TRUE" else "FALSE")

    # max chars
    q["maxChars"] = get_str("maxChars") or get_str("maxLength") or "0"
    return q


def _normalize_course_row(row: Dict) -> Dict:
    def gs(key: str, default: str = ""):
        v = row.get(key)
        return default if v is None else str(v).strip() or default

    return {
        "courseId": gs("courseId") or gs("id", ""),
        "title": gs("title", "(ì œëª©ì—†ìŒ)"),
        "description": gs("description", ""),
        "category": gs("category", "ê¸°ë³¸"),
        "createdAt": gs("createdAt", datetime.utcnow().isoformat()),
        "status": (gs("status", "active").lower() if gs("status", "active") else "active"),
        "ownerId": gs("ownerId", "admin"),
    }


def _normalize_response_row(row: Dict) -> Dict:
    def gs(key: str, default: str = ""):
        v = row.get(key)
        return default if v is None else str(v)

    return {
        "courseId": gs("courseId"),
        "questionId": gs("questionId"),
        "answer": gs("answer"),
        "respondentHash": gs("respondentHash", "import" + hashlib.md5(json.dumps(row, ensure_ascii=False).encode()).hexdigest()[:8]),
        "sessionId": gs("sessionId", "import_session"),
        "ipMasked": gs("ipMasked", "***.***.***.***"),
        "timestamp": gs("timestamp", datetime.utcnow().isoformat()),
    }


def _is_metadata_column(column_text: str) -> bool:
    """ë©”íƒ€ë°ì´í„°/PII ì—´ì¸ì§€ íŒë‹¨ (ì„¤ë¬¸ ë¬¸í•­ì´ ì•„ë‹Œ ì‘ë‹µì ì •ë³´)"""
    column_lower = column_text.lower()
    
    # ğŸš¨ í•µì‹¬ ìˆ˜ì •: íšŒì‚¬/ì†Œì†/ë¶€ì„œ/ì§êµ° ë“±ì€ ì„¤ë¬¸ ë¬¸í•­ìœ¼ë¡œ í¬í•¨
    # ë©”íƒ€ë°ì´í„°ì´ì§€ë§Œ ë¶„ì„ ê°€ì¹˜ê°€ ìˆìœ¼ë¯€ë¡œ ë¬¸í•­ìœ¼ë¡œ ë“±ë¡
    # PII(ê°œì¸ì‹ë³„ì •ë³´)ë§Œ ì œì™¸
    pii_keywords = [
        "ì´ë¦„", "ì„±í•¨", "ì„±ëª…", "name",
        "ì—°ë½ì²˜", "ì „í™”", "íœ´ëŒ€í°", "í•¸ë“œí°", "phone", "mobile", "tel",
        "ì´ë©”ì¼", "ë©”ì¼", "email", "e-mail",
        "ê²½í’ˆ", "ë™ì˜", "ê°œì¸ì •ë³´", "prize", "consent", "privacy",
        "ì£¼ì†Œ", "address",
        "ìƒë…„ì›”ì¼", "birthday", "birth",
    ]
    
    # í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ PIIë¡œ ê°„ì£¼
    for keyword in pii_keywords:
        if keyword in column_lower:
            return True
    
    return False


def _parse_wide_excel_first_sheet(uploaded_file) -> Dict[str, List[Dict]]:
    """Parse an Excel where row1 columns are questions and row2+ are responses.
    
    ğŸ”§ ì•ˆì •ì„± ê°•í™”: ê°œë³„ ì…€ ì˜¤ë¥˜ë¥¼ ê±´ë„ˆë›°ê³  ìµœëŒ€í•œ ë§ì€ ë°ì´í„°ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.

    Returns dict with keys:
      - questions: List[Dict]
      - responses: List[Dict] each has questionId, answer, respondentIndex
      - skipped_columns: List[str] (ë©”íƒ€ë°ì´í„°ë¡œ ê±´ë„ˆë›´ ì—´ ëª©ë¡)
    """
    result: Dict[str, List[Dict]] = {"questions": [], "responses": [], "skipped_columns": []}
    try:
        # Read into buffer to avoid consuming original pointer irreversibly
        data = uploaded_file.read()
        buf = io.BytesIO(data)
        xls = pd.ExcelFile(buf, engine='openpyxl')
        sheet_name = xls.sheet_names[0]
        
        # ğŸ”§ dtype=strë¡œ ëª¨ë“  ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ì½ì–´ í˜•ì‹ ì˜¤ë¥˜ ë°©ì§€
        df = pd.read_excel(xls, sheet_name=sheet_name, header=None, engine='openpyxl', dtype=str)
        if df.empty:
            return result

        # First row -> question texts (skip first column: timestamp)
        header_row = []
        try:
            header_row = df.iloc[0].fillna("").astype(str).tolist()
        except Exception as e:
            st.warning(f"âš ï¸ í—¤ë” í–‰ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return result
        
        # Data rows -> responses
        data_df = df.iloc[1:].reset_index(drop=True)

        # Build questions (ë©”íƒ€ë°ì´í„° ì—´ ì œì™¸)
        questions: List[Dict] = []
        col_to_qid: Dict[int, str] = {}
        skipped_columns: List[str] = []
        
        for idx, q_text in enumerate(header_row):
            try:
                # ì²« ë²ˆì§¸ ì—´(íƒ€ì„ìŠ¤íƒ¬í”„) ê±´ë„ˆë›°ê¸°
                if idx == 0:
                    continue
                
                # ë¹ˆ ì—´ ê±´ë„ˆë›°ê¸°
                if not str(q_text).strip():
                    continue
                
                # ğŸš¨ ë©”íƒ€ë°ì´í„°/PII ì—´ ê°ì§€ ë° ê±´ë„ˆë›°ê¸°
                if _is_metadata_column(str(q_text)):
                    skipped_columns.append(f"[ì—´ {idx+1}] {str(q_text)[:50]}")
                    continue
                
                # ë¬¸í•­ìœ¼ë¡œ ë“±ë¡
                qid = str(int(datetime.utcnow().timestamp() * 1000)) + f"{idx:02d}"
                col_to_qid[idx] = qid
                questions.append({
                    "questionId": qid,
                    "order": str(len(questions) + 1),
                    "text": str(q_text).strip(),
                    "type": "subjective",
                    "choicesJson": "[]",
                    "ratingMax": "",
                    "isRequired": "FALSE",
                    "maxChars": "0",
                })
            except Exception as e:
                # ê°œë³„ ì—´ íŒŒì‹± ì˜¤ë¥˜ëŠ” ê±´ë„ˆë›°ê³  ê³„ì† ì§„í–‰
                st.warning(f"âš ï¸ ì—´ {idx+1} íŒŒì‹± ì˜¤ë¥˜ (ê±´ë„ˆëœ€): {str(e)}")
                continue

        # Build responses (ê°œë³„ ì…€ ì˜¤ë¥˜ ì²˜ë¦¬)
        responses: List[Dict] = []
        for ridx in range(len(data_df)):
            try:
                row_series = data_df.iloc[ridx]
                for cidx, val in enumerate(row_series.tolist()):
                    try:
                        if cidx not in col_to_qid:
                            continue
                        # ğŸ”§ ì•ˆì „í•œ ë¬¸ìì—´ ë³€í™˜
                        ans = "" if pd.isna(val) or val is None else str(val).strip()
                        responses.append({
                            "questionId": col_to_qid[cidx],
                            "answer": ans,
                            "respondentIndex": ridx,
                        })
                    except Exception as cell_err:
                        # ê°œë³„ ì…€ ì˜¤ë¥˜ëŠ” ê±´ë„ˆë›°ê³  ê³„ì†
                        continue
            except Exception as row_err:
                # í–‰ ì „ì²´ ì˜¤ë¥˜ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì†
                st.warning(f"âš ï¸ í–‰ {ridx+2} íŒŒì‹± ì˜¤ë¥˜ (ê±´ë„ˆëœ€): {str(row_err)}")
                continue

        result["questions"] = questions
        result["responses"] = responses
        result["skipped_columns"] = skipped_columns
        
        # íŒŒì‹± ê²°ê³¼ ìš”ì•½
        if len(questions) > 0:
            st.success(f"âœ… ì—‘ì…€ íŒŒì‹± ì„±ê³µ: {len(questions)}ê°œ ë¬¸í•­, {len(responses)}ê°œ ì‘ë‹µ")
        
    except Exception as e:
        error_msg = str(e)
        
        # XML ê´€ë ¨ ì˜¤ë¥˜ íŠ¹ë³„ ì²˜ë¦¬
        if "XML" in error_msg or "manifest" in error_msg or "openpyxl" in error_msg:
            st.error("âŒ ì—‘ì…€ íŒŒì¼ XML êµ¬ì¡° ì˜¤ë¥˜: íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹ì…ë‹ˆë‹¤.")
            st.warning("âš ï¸ ì´ ì˜¤ë¥˜ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš° ë°œìƒí•©ë‹ˆë‹¤:")
            st.write("   1. Google Formsì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œí•œ XLSX íŒŒì¼")
            st.write("   2. ì˜¨ë¼ì¸ ë„êµ¬ë¡œ ë³€í™˜ëœ XLSX íŒŒì¼")
            st.write("   3. ì†ìƒëœ ì—‘ì…€ íŒŒì¼")
            st.error("ğŸš¨ **í•„ìˆ˜**: Excelì—ì„œ íŒŒì¼ì„ ì—´ê³  CSV UTF-8ë¡œ ë‹¤ì‹œ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤!")
            with st.expander("ğŸ“ CSV ë³€í™˜ ë°©ë²• (ìƒì„¸)"):
                st.markdown("""
                ### Excelì—ì„œ CSVë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•:
                
                1. **ì—‘ì…€ì—ì„œ íŒŒì¼ ì—´ê¸°** (.xlsx íŒŒì¼)
                2. `íŒŒì¼` â†’ `ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì €ì¥` í´ë¦­
                3. `íŒŒì¼ í˜•ì‹` ë“œë¡­ë‹¤ìš´ì—ì„œ ì„ íƒ:
                   - **"CSV UTF-8 (ì‰¼í‘œë¡œ ë¶„ë¦¬)(*.csv)"** â† ì´ê²ƒ ì„ íƒ!
                4. íŒŒì¼ëª… í™•ì¸ í›„ `ì €ì¥` í´ë¦­
                5. ê²½ê³  ë©”ì‹œì§€ ë‚˜ì˜¤ë©´ `ì˜ˆ` í´ë¦­
                6. ì €ì¥ëœ .csv íŒŒì¼ì„ ì—…ë¡œë“œ
                
                âš ï¸ ì£¼ì˜: "CSV (ì‰¼í‘œë¡œ ë¶„ë¦¬)" ê°€ ì•„ë‹ˆë¼ **"CSV UTF-8"** ì„ ì„ íƒí•˜ì„¸ìš”!
                """)
        else:
            st.error(f"âŒ wide í¬ë§· íŒŒì‹± ì‹¤íŒ¨: {error_msg}")
            st.info("ğŸ’¡ íŒŒì¼ì„ **CSV í˜•ì‹**ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¬ì—…ë¡œë“œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
    finally:
        try:
            uploaded_file.seek(0)
        except Exception:
            pass
    return result


def _parse_wide_csv(uploaded_file) -> Dict[str, List[Dict]]:
    """Parse a CSV where col1 is timestamp, row1 columns are questions (from col2), and row2+ are responses.
    
    ğŸ”§ ì•ˆì •ì„± ê°•í™”: ê°œë³„ ì…€ ì˜¤ë¥˜ë¥¼ ê±´ë„ˆë›°ê³  ìµœëŒ€í•œ ë§ì€ ë°ì´í„°ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.

    Returns dict with keys:
      - questions: List[Dict]
      - responses: List[Dict] each has questionId, answer, respondentIndex
      - skipped_columns: List[str] (ë©”íƒ€ë°ì´í„°ë¡œ ê±´ë„ˆë›´ ì—´ ëª©ë¡)
    """
    result: Dict[str, List[Dict]] = {"questions": [], "responses": [], "skipped_columns": []}
    try:
        data = uploaded_file.read()
        buf = io.BytesIO(data)
        
        # ğŸš¨ í•µì‹¬ ìˆ˜ì •: ì¸ì½”ë”© ìë™ ê°ì§€ ë¡œì§ ê°•í™” ë° ìƒì„¸ ì˜¤ë¥˜ ë©”ì‹œì§€
        df = None
        encoding_used = None
        encoding_errors = []
        
        # utf-8-sigë¥¼ ë¨¼ì € ì‹œë„í•´ì•¼ BOM(Byte Order Mark) ë¬¸ì œ í•´ê²°
        for encoding in ['utf-8-sig', 'cp949', 'euc-kr', 'utf-8', 'latin-1']:
            try:
                buf.seek(0)
                # ğŸ”§ dtype=strë¡œ ëª¨ë“  ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ì½ì–´ í˜•ì‹ ì˜¤ë¥˜ ë°©ì§€
                df = pd.read_csv(buf, header=None, encoding=encoding, dtype=str, on_bad_lines='skip')
                encoding_used = encoding
                st.success(f"âœ… CSV ì¸ì½”ë”© ê°ì§€ ì„±ê³µ: {encoding_used}")
                break
            except Exception as e:
                encoding_errors.append(f"{encoding}: {str(e)[:50]}")
                continue
        
        if df is None or df.empty:
            st.error("âŒ CSV ì¸ì½”ë”© íŒŒì‹± ì‹¤íŒ¨: íŒŒì¼ ì¸ì½”ë”©ì„ (UTF-8 with BOM ë˜ëŠ” CP949)ë¡œ ì €ì¥ í›„ ì¬ì—…ë¡œë“œí•˜ì‹­ì‹œì˜¤.")
            with st.expander("ğŸ” ì¸ì½”ë”© ì‹œë„ ë‚´ì—­"):
                for err in encoding_errors:
                    st.write(f"  - {err}")
            st.info("ğŸ’¡ Excelì—ì„œ CSV ì €ì¥ ì‹œ: 'ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì €ì¥' â†’ 'CSV UTF-8 (ì‰¼í‘œë¡œ ë¶„ë¦¬)(*.csv)' ì„ íƒ")
            return result

        # First row -> question texts (skip first column: timestamp)
        header_row = []
        try:
            header_row = df.iloc[0].fillna("").astype(str).tolist()
        except Exception as e:
            st.warning(f"âš ï¸ CSV í—¤ë” í–‰ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return result
        
        # Data rows -> responses
        data_df = df.iloc[1:].reset_index(drop=True)

        questions: List[Dict] = []
        col_to_qid: Dict[int, str] = {}
        skipped_columns: List[str] = []
        
        for idx in range(1, len(header_row)):
            try:
                q_text = header_row[idx]
                
                # ë¹ˆ ì—´ ê±´ë„ˆë›°ê¸°
                if not str(q_text).strip():
                    continue
                
                # ğŸš¨ ë©”íƒ€ë°ì´í„°/PII ì—´ ê°ì§€ ë° ê±´ë„ˆë›°ê¸°
                if _is_metadata_column(str(q_text)):
                    skipped_columns.append(f"[ì—´ {idx+1}] {str(q_text)[:50]}")
                    continue
                
                # ë¬¸í•­ìœ¼ë¡œ ë“±ë¡
                qid = str(int(datetime.utcnow().timestamp() * 1000)) + f"{idx:02d}"
                col_to_qid[idx] = qid
                questions.append({
                    "questionId": qid,
                    "order": str(len(questions) + 1),
                    "text": str(q_text).strip(),
                    "type": "subjective",
                    "choicesJson": "[]",
                    "ratingMax": "",
                    "isRequired": "FALSE",
                    "maxChars": "0",
                })
            except Exception as e:
                # ê°œë³„ ì—´ íŒŒì‹± ì˜¤ë¥˜ëŠ” ê±´ë„ˆë›°ê³  ê³„ì†
                st.warning(f"âš ï¸ CSV ì—´ {idx+1} íŒŒì‹± ì˜¤ë¥˜ (ê±´ë„ˆëœ€): {str(e)}")
                continue

        # Build responses (ê°œë³„ ì…€ ì˜¤ë¥˜ ì²˜ë¦¬)
        responses: List[Dict] = []
        for ridx in range(len(data_df)):
            try:
                row_series = data_df.iloc[ridx]
                for cidx in range(1, len(row_series)):
                    try:
                        if cidx not in col_to_qid:
                            continue
                        val = row_series.iloc[cidx]
                        # ğŸ”§ ì•ˆì „í•œ ë¬¸ìì—´ ë³€í™˜
                        ans = "" if pd.isna(val) or val is None else str(val).strip()
                        responses.append({
                            "questionId": col_to_qid[cidx],
                            "answer": ans,
                            "respondentIndex": ridx,
                        })
                    except Exception as cell_err:
                        # ê°œë³„ ì…€ ì˜¤ë¥˜ëŠ” ê±´ë„ˆë›°ê³  ê³„ì†
                        continue
            except Exception as row_err:
                # í–‰ ì „ì²´ ì˜¤ë¥˜ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì†
                st.warning(f"âš ï¸ CSV í–‰ {ridx+2} íŒŒì‹± ì˜¤ë¥˜ (ê±´ë„ˆëœ€): {str(row_err)}")
                continue

        result["questions"] = questions
        result["responses"] = responses
        result["skipped_columns"] = skipped_columns
        
        # íŒŒì‹± ê²°ê³¼ ìš”ì•½
        if len(questions) > 0:
            st.success(f"âœ… CSV íŒŒì‹± ì„±ê³µ ({encoding_used}): {len(questions)}ê°œ ë¬¸í•­, {len(responses)}ê°œ ì‘ë‹µ")
        
    except Exception as e:
        st.error(f"âŒ CSV wide í¬ë§· íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        st.info("ğŸ’¡ íŒŒì¼ì„ ë‹¤ì‹œ ì €ì¥í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì¸ì½”ë”©(UTF-8)ìœ¼ë¡œ ì €ì¥í•´ë³´ì„¸ìš”.")
    finally:
        try:
            uploaded_file.seek(0)
        except Exception:
            pass
    return result


def page_upload_files(spreadsheet):
    """ê´€ë¦¬ì: ì„¤ë¬¸ íŒŒì¼ ì—…ë¡œë“œ (ë¬¸í•­ë§Œ ë˜ëŠ” ì‘ë‹µ í¬í•¨)"""
    st.subheader("ì„¤ë¬¸ íŒŒì¼ ì—…ë¡œë“œ (CSV/XLSX)")
    st.caption(
        "- XLSXëŠ” 'Course', 'Questions', 'Responses' ì‹œíŠ¸ëª…ì„ ì§€ì›í•©ë‹ˆë‹¤.\n- CSVëŠ” í—¤ë”ë¡œ ìœ í˜•ì„ ìë™ ê°ì§€í•©ë‹ˆë‹¤.")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (course_id ë®ì–´ì“°ê¸° ë°©ì§€)
    if 'upload_course_id' not in st.session_state:
        st.session_state.upload_course_id = ""
    if 'course_id_user_edited' not in st.session_state:
        st.session_state.course_id_user_edited = False

    uploaded = st.file_uploader(
    "íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
    type=[
        "xlsx",
        "csv"],
         accept_multiple_files=False)

    if not uploaded:
        # íŒŒì¼ ì—†ìœ¼ë©´ ì„¸ì…˜ ì´ˆê¸°í™”
        st.session_state.upload_course_id = ""
        st.session_state.course_id_user_edited = False
        return

    # íŒŒì¼ì´ ì—…ë¡œë“œë˜ê³ , ê¸°ë³¸ê°’ì´ ì—†ê³ , ì‚¬ìš©ìê°€ í¸ì§‘í•˜ì§€ ì•Šì•˜ìœ¼ë©´ ì´ˆê¸°ê°’ ìƒì„± (1íšŒë§Œ)
    if not st.session_state.upload_course_id and not st.session_state.course_id_user_edited:
        st.session_state.upload_course_id = generate_course_id()

    # Wide-matrix option (row1=questions, row2+=responses)
    use_wide_format = st.checkbox("1í–‰=ì„¤ë¬¸ ë¬¸í•­, 2í–‰ë¶€í„°=ì‘ë‹µ (ì™€ì´ë“œ í¬ë§·)")
    
    # CSV ìš°ì„  ê¶Œì¥ ë©”ì‹œì§€
    if uploaded and uploaded.name.lower().endswith(".xlsx"):
        st.warning("âš ï¸ XLSX íŒŒì¼ì€ XML ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. CSV UTF-8 í˜•ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤!")
        with st.expander("ğŸ’¡ ë¹ ë¥¸ í•´ê²° ë°©ë²•"):
            st.markdown("""
            **Excelì—ì„œ CSVë¡œ ë³€í™˜:**
            1. í˜„ì¬ íŒŒì¼ì„ Excelì—ì„œ ì—´ê¸°
            2. `íŒŒì¼` â†’ `ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì €ì¥`
            3. `CSV UTF-8 (ì‰¼í‘œë¡œ ë¶„ë¦¬)(*.csv)` ì„ íƒ
            4. ì €ì¥ í›„ CSV íŒŒì¼ ì—…ë¡œë“œ
            """)

    # ì™€ì´ë“œ í¬ë§·(CSV/XLSX) ì„ íƒ ì‹œ, ì‚¬ì „ ê°ì§€ë¥¼ ê±´ë„ˆë›°ì–´ ì¸ì½”ë”©/í¬ì¸í„° ì´ìŠˆ íšŒí”¼
    if use_wide_format and (uploaded.name.lower().endswith(
        ".csv") or uploaded.name.lower().endswith(".xlsx")):
        dfs = {}
    else:
        dfs = _detect_uploaded_frames(uploaded)
    has_course = "course" in dfs and not dfs["course"].empty
    has_questions = "questions" in dfs and not dfs["questions"].empty
    has_responses = "responses" in dfs and not dfs["responses"].empty

    with st.expander("ë¯¸ë¦¬ë³´ê¸°"):
        if use_wide_format and (uploaded.name.lower().endswith(
            ".csv") or uploaded.name.lower().endswith(".xlsx")):
            st.markdown("**ì™€ì´ë“œ í¬ë§· ê°ì§€**: 1í–‰ ë¬¸í•­, 2í–‰ë¶€í„° ì‘ë‹µ")
            try:
                if uploaded.name.lower().endswith(".csv"):
                    preview = _parse_wide_csv(uploaded)
                else:
                    preview = _parse_wide_excel_first_sheet(uploaded)
                q_texts = [q.get("text", "")
                                 for q in preview.get("questions", [])]
                st.markdown(f"**ë¬¸í•­ ìˆ˜: {len(q_texts)}ê°œ**")
                if q_texts:
                    # ëª¨ë“  ë¬¸í•­ì„ ë²ˆí˜¸ì™€ í•¨ê»˜ í‘œì‹œ
                    st.markdown("##### ì „ì²´ ë¬¸í•­ ëª©ë¡:")
                    for idx, q_text in enumerate(q_texts, 1):
                        st.markdown(f"{idx}. {q_text}")
                else:
                    st.info("ë¬¸í•­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 1í–‰ì— ë¬¸í•­ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            except Exception as e:
                st.warning(f"ì™€ì´ë“œ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {str(e)}")
        else:
            if has_course:
                st.markdown("**Course** ë¯¸ë¦¬ë³´ê¸°")
                st.dataframe(dfs["course"].head(10))
            if has_questions:
                st.markdown("**Questions** ë¯¸ë¦¬ë³´ê¸°")
                st.dataframe(dfs["questions"].head(10))
            if has_responses:
                st.markdown("**Responses** ë¯¸ë¦¬ë³´ê¸°")
                st.dataframe(dfs["responses"].head(10))
            if not (has_course or has_questions or has_responses):
                st.warning("ìœ íš¨í•œ ì‹œíŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í—¤ë”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

    # í•„ìˆ˜: ì½”ìŠ¤ ë©”íƒ€ë°ì´í„° ì…ë ¥ (í•­ìƒ í‘œì‹œ)
    st.markdown("### ğŸ“‹ í•„ìˆ˜: ì½”ìŠ¤ ë©”íƒ€ë°ì´í„° ì…ë ¥")
    st.caption("âš ï¸ íŒŒì¼ ì—…ë¡œë“œ ì‹œ ê³¼ì • ì •ë³´ë¥¼ ë°˜ë“œì‹œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")

    # on_change ì½œë°±: ì‚¬ìš©ìê°€ í¸ì§‘í–ˆìŒì„ ë§ˆí‚¹
    def mark_course_id_edited():
        st.session_state.course_id_user_edited = True

    # v2 ìŠ¤í‚¤ë§ˆ ì…ë ¥ í¼ (ëª¨ë‘ ì„¸ì…˜ ìƒíƒœ ê¸°ë°˜)
    col1, col2 = st.columns(2)
    with col1:
        st.text_input(
            "ê³¼ì • ID (í•„ìˆ˜)*",
            value=st.session_state.upload_course_id,
            key="meta_course_id",
            on_change=mark_course_id_edited,
            placeholder="ì˜ˆ: C-2025-001",
            help="ê³ ìœ í•œ ê³¼ì • ì‹ë³„ì (ìë™ ìƒì„±ë˜ì§€ë§Œ ìˆ˜ì • ê°€ëŠ¥)"
        )
        st.text_input(
            "í”„ë¡œê·¸ë¨ëª… (í•„ìˆ˜)*",
            value="",
            key="meta_program_name",
            placeholder="ì˜ˆ: Next Chip Talk",
            help="í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤."
        )
        st.text_input(
            "íšŒì°¨ (í•„ìˆ˜)*",
            value="1",
            key="meta_session_no",
            help="í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤."
        )
        st.text_input(
            "ì£¼ì œ (í•„ìˆ˜)*",
            value="",
            key="meta_theme",
            placeholder="ì˜ˆ: AI ë°˜ë„ì²´ ê¸°ìˆ ",
            help="í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤."
        )

    with col2:
        st.selectbox(
            "ì´ë²¤íŠ¸ ìœ í˜• (í•„ìˆ˜)*",
            ["NCT", "Forum", "Workshop", "Webinar", "Internal Talk"],
            index=0,
            key="meta_event_type"
        )
        st.date_input("í–‰ì‚¬ ë‚ ì§œ", key="meta_event_date")
        st.text_input("ì¥ì†Œ", value="ì˜¨ë¼ì¸", key="meta_location")
        st.text_input("ì£¼ìµœ/ì£¼ê´€", value="SK hynix", key="meta_host_org")

    st.text_input(
        "ì—°ì‚¬ (ì„¸ë¯¸ì½œë¡  êµ¬ë¶„)",
        value="",
        key="meta_speakers",
        placeholder="ì˜ˆ: ê¹€ë°•ì‚¬;ì´êµìˆ˜"
    )
    st.selectbox(
        "ìƒíƒœ",
        ["planned", "active", "completed", "archived"],
        index=1,  # ê¸°ë³¸: active
        key="meta_status"
    )

    # ë²„íŠ¼ì€ í•­ìƒ í™œì„±í™” (ê²€ì¦ì€ í´ë¦­ í›„)
    if st.button("ì—…ë¡œë“œ ì‹¤í–‰", type="primary"):
        # ============================================
        # 1. í•„ìˆ˜ í•„ë“œ ê²€ì¦ (submit í›„ì—ë§Œ ìˆ˜í–‰)
        # ============================================

        # ë””ë²„ê·¸: ì„¸ì…˜ ìƒíƒœ í™•ì¸
        debug_state = {
            "meta_course_id": st.session_state.get("meta_course_id"),
            "meta_program_name": st.session_state.get("meta_program_name"),
            "meta_session_no": st.session_state.get("meta_session_no"),
            "meta_theme": st.session_state.get("meta_theme"),
            "meta_event_type": st.session_state.get("meta_event_type"),
        }

        # ê°œë°œ ì¤‘ì—ë§Œ í‘œì‹œ (í”„ë¡œë•ì…˜ì—ì„œëŠ” ì£¼ì„ ì²˜ë¦¬)
        with st.expander("ğŸ” ë””ë²„ê·¸: ì„¸ì…˜ ìƒíƒœ í™•ì¸"):
            st.json(debug_state)

        # ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜
        required_fields = {
            "course_id": safe_str(st.session_state.get("meta_course_id")),
            "program_name": safe_str(st.session_state.get("meta_program_name")),
            "session_no": safe_str(st.session_state.get("meta_session_no")),
            "theme": safe_str(st.session_state.get("meta_theme")),
            "event_type": safe_str(st.session_state.get("meta_event_type")),
        }

        # ë””ë²„ê·¸: ë³€í™˜ í›„ ê°’ í™•ì¸
        with st.expander("ğŸ” ë””ë²„ê·¸: ë³€í™˜ í›„ í•„ë“œ ê°’"):
            st.json(required_fields)

        missing = [k for k, v in required_fields.items() if not v]

        if missing:
            st.error(f"âŒ í•„ìˆ˜ í•­ëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: {', '.join(missing)}")
            st.warning("âš ï¸ ëª¨ë“  í•„ìˆ˜ í•­ëª©(*)ì„ ì…ë ¥í•œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")

            # ë””ë²„ê·¸: ëˆ„ë½ëœ í•„ë“œì˜ ì›ë³¸ ê°’ í‘œì‹œ
            with st.expander("ğŸ” ë””ë²„ê·¸: ëˆ„ë½ í•„ë“œ ìƒì„¸"):
                for field in missing:
                    raw_val = st.session_state.get(f"meta_{field}")
                    st.write(f"- {field}:")
                    st.write(f"  ì›ë³¸: {repr(raw_val)}")
                    st.write(f"  íƒ€ì…: {type(raw_val)}")
                    st.write(f"  ë³€í™˜ í›„: {repr(required_fields[field])}")

                st.stop()

        # ============================================
        # 2. ì—…ë¡œë“œ ì‹œì‘
        # ============================================
        try:
            log_box = st.expander("ì—…ë¡œë“œ ë¡œê·¸", expanded=False)
            # Helper: exponential backoff wrapper with API quota handling

            def _with_backoff(fn, *args, **kwargs):
                delays = [2, 4, 8, 16, 32]  # Increased delays for quota limits
                last_err = None
                for i, d in enumerate([0] + delays):
                    if d:
                        time.sleep(d)
                        with log_box:
                            st.write(f"â³ API ì¿¼í„° ì œí•œìœ¼ë¡œ {d}ì´ˆ ëŒ€ê¸° ì¤‘...")
                    try:
                        return fn(*args, **kwargs)
                    except Exception as e:
                        msg = str(e)
                        last_err = e
                        if ("429" in msg) or ("Quota exceeded" in msg) or (
                            "quota" in msg.lower()):
                            with log_box:
                                st.write(
                                    f"âš ï¸ API ì¿¼í„° ì´ˆê³¼ ê°ì§€ (ì‹œë„ {i + 1}/{len(delays)})")
                            continue
                        raise
                raise last_err

            # 3) Course ì €ì¥ (v2 ìŠ¤í‚¤ë§ˆ ì‚¬ìš©)
            course_saved_id = None

            # ì„¸ì…˜ ìƒíƒœì—ì„œ ì•ˆì „í•˜ê²Œ ê°’ ê°€ì ¸ì˜¤ê¸°
            course_id_final = required_fields["course_id"]

            # event_date ì²˜ë¦¬ (safe_date ì‚¬ìš©)
            event_date_val = st.session_state.get("meta_event_date")
            event_date_str = safe_date(event_date_val)

            # v2 ìŠ¤í‚¤ë§ˆ ê°ì²´ ìƒì„± (ì„¸ì…˜ ìƒíƒœ ê¸°ë°˜, ì‚¬ìš©ì ì…ë ¥ê°’ ì ˆëŒ€ ë®ì–´ì“°ì§€ ì•ŠìŒ)
            course_obj_v2 = {
                "course_id": course_id_final,  # ë¬¸ìì—´ë¡œ ë³´ì¥
                # ì´ë¯¸ safe_str ì ìš©ë¨
                "program_name": required_fields["program_name"],
                # ì´ë¯¸ safe_str ì ìš©ë¨
                "session_no": required_fields["session_no"],
                # ì´ë¯¸ safe_str ì ìš©ë¨
                "theme": required_fields["theme"],
                # ì´ë¯¸ safe_str ì ìš©ë¨
                "event_type": required_fields["event_type"],
                "event_date": event_date_str,                     # safe_date ì ìš©ë¨
                "location": safe_str(st.session_state.get("meta_location")),
                "host_org": safe_str(st.session_state.get("meta_host_org")),
                "speakers": safe_str(st.session_state.get("meta_speakers")),
                "survey_form_version": "v2.0",
                "response_source_file": uploaded.name if uploaded else "",
                "status": safe_str(st.session_state.get("meta_status", "active")),
                "created_at": datetime.now(timezone.utc).isoformat(),
                "updated_at": datetime.now(timezone.utc).isoformat(),
            }

            # ë””ë²„ê·¸: ìµœì¢… course ê°ì²´ í™•ì¸
            with log_box:
                st.write("ğŸ” ë””ë²„ê·¸: ìµœì¢… course ê°ì²´")
                st.json({k: v for k, v in course_obj_v2.items() if k in [
                        "course_id", "program_name", "theme", "event_type", "event_date"]})

            _with_backoff(upsert_course_v2, spreadsheet, course_obj_v2)
            course_saved_id = course_obj_v2["course_id"]

            # ì„¸ì…˜ ìƒíƒœ ë™ê¸°í™” (ë‹¤ìŒ ë Œë”ë§ ì‹œì—ë„ ìœ ì§€)
            st.session_state.upload_course_id = course_id_final

            with log_box:
                st.write(
    f"âœ… Course ì €ì¥: course_id={course_saved_id}, program_name='{
        course_obj_v2.get(
            'program_name', '')}'")
                st.write(
    f"   ì´ë²¤íŠ¸: {
        course_obj_v2['event_type']} / íšŒì°¨: {
            course_obj_v2['session_no']} / ë‚ ì§œ: {
                course_obj_v2['event_date']}")

            # 4) í—¤ë” ê¸°ë°˜ Survey_Items ìë™ ë“±ë¡ ë° ë§¤í•‘
            with log_box:
                st.write("ğŸ“ íŒŒì¼ í—¤ë” ì¶”ì¶œ ì¤‘...")

            # íŒŒì¼ ë‹¤ì‹œ ì½ê¸° (í—¤ë” ì¶”ì¶œìš©)
            try:
                # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ë˜ëŒë¦¬ê¸°
                uploaded.seek(0)

                # ğŸ”§ íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ í™•ì¸ (ì‹¤ì œ íŒŒì¼ í˜•ì‹ ê°ì§€)
                file_content = uploaded.read()
                uploaded.seek(0)
                
                is_zip_based = file_content[:2] == b'PK'  # ZIP/XLSX ì‹œê·¸ë‹ˆì²˜
                
                if is_zip_based:
                    # ì‹¤ì œë¡œ XLSX íŒŒì¼
                    with log_box:
                        st.info("ğŸ’¡ íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ í™•ì¸: XLSX í˜•ì‹ (ZIP ê¸°ë°˜)")
                    df_headers = pd.read_excel(io.BytesIO(file_content), nrows=0, engine='openpyxl')
                else:
                    # ì‹¤ì œë¡œ CSV íŒŒì¼ - ë‹¤ì¤‘ ì¸ì½”ë”© ì‹œë„
                    with log_box:
                        st.info("ğŸ’¡ íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ í™•ì¸: CSV í˜•ì‹")
                    
                    df_headers = None
                    for encoding in ['utf-8-sig', 'cp949', 'euc-kr', 'utf-8', 'latin-1']:
                        try:
                            df_headers = pd.read_csv(io.BytesIO(file_content), nrows=0, encoding=encoding)
                            with log_box:
                                st.success(f"âœ… í—¤ë” ì½ê¸° ì„±ê³µ: {encoding}")
                            break
                        except Exception:
                            continue
                    
                    if df_headers is None:
                        raise ValueError("CSV í—¤ë”ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ì¸ì½”ë”©ì„ í™•ì¸í•˜ì„¸ìš”.")

                headers = list(df_headers.columns)

                with log_box:
                    st.write(f"ğŸ“‹ ì´ {len(headers)}ê°œ ì»¬ëŸ¼ ë°œê²¬")

                # Survey_Items ìë™ ë“±ë¡
                with log_box:
                    st.write("ğŸ” ì„¤ë¬¸ ë¬¸í•­ ìë™ ë“±ë¡ ì¤‘...")

                registered_items = _with_backoff(
                    ensure_survey_items_from_headers,
                    spreadsheet,
                    headers
                )

                with log_box:
                    st.write(f"âœ… {len(registered_items)}ê°œ ë¬¸í•­ ë“±ë¡ ì™„ë£Œ")
                    for item in registered_items[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
                        st.write(
                            f"   - {item.get('item_text', '')[:50]} ({item.get('metric_type', '')})")
                    if len(registered_items) > 5:
                        st.write(f"   ... ì™¸ {len(registered_items) - 5}ê°œ")

                # Course â†” Items ë§¤í•‘
                if registered_items:
                    with log_box:
                        st.write("ğŸ§¹ ê¸°ì¡´ ê³¼ì •-ë¬¸í•­ ë§¤í•‘ ì •ë¦¬ ì¤‘...")

                    removed_count = _with_backoff(
                        delete_course_item_mappings,
                        spreadsheet,
                        course_saved_id,
                    )

                    with log_box:
                        st.write(f"   - ê¸°ì¡´ ë§¤í•‘ {removed_count}ê°œ ì‚­ì œ")

                    with log_box:
                        st.write("ğŸ”— ìƒˆ ê³¼ì •-ë¬¸í•­ ë§¤í•‘ ìƒì„± ì¤‘...")

                    _with_backoff(
                        ensure_course_item_mapping,
                        spreadsheet,
                        course_saved_id,
                        registered_items
                    )

                    with log_box:
                        st.write(f"âœ… {len(registered_items)}ê°œ ë¬¸í•­ ë§¤í•‘ ì™„ë£Œ")

            except Exception as e:
                with log_box:
                    st.warning(f"âš ï¸ í—¤ë” ê¸°ë°˜ ìë™ ë“±ë¡ ì‹¤íŒ¨: {str(e)}")
                    st.write("ğŸ’¡ ìˆ˜ë™ìœ¼ë¡œ Survey_Itemsë¥¼ ë“±ë¡í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            # 2) Questions ì €ì¥ (í‘œì¤€ ë˜ëŠ” ì™€ì´ë“œ í¬ë§·)
            imported_questions = 0
            wide_result = {"questions": [], "responses": []}
            
            # ğŸ’¡ ì™€ì´ë“œ í¬ë§· íŒŒì‹± ì‹œì‘ - íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ë¡œ ì‹¤ì œ í˜•ì‹ ê°ì§€
            if use_wide_format:
                # ğŸ”§ íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ë¡œ ì‹¤ì œ í˜•ì‹ í™•ì¸
                uploaded.seek(0)
                file_magic = uploaded.read(4)
                uploaded.seek(0)
                
                is_zip_based = file_magic[:2] == b'PK'
                
                if is_zip_based:
                    # ì‹¤ì œë¡œ XLSX íŒŒì¼ (í™•ì¥ìì™€ ë¬´ê´€í•˜ê²Œ)
                    with log_box:
                        st.write("ğŸ“Š ì—‘ì…€ ì™€ì´ë“œ í¬ë§· íŒŒì‹± ì¤‘...")
                        st.info(f"ğŸ’¡ íŒŒì¼ ì‹œê·¸ë‹ˆì²˜: XLSX (ì‹¤ì œ í™•ì¥ì: {uploaded.name.split('.')[-1]})")
                        if not uploaded.name.lower().endswith(".xlsx"):
                            st.warning("âš ï¸ íŒŒì¼ í™•ì¥ìëŠ” .csvì´ì§€ë§Œ ì‹¤ì œë¡œëŠ” XLSX íŒŒì¼ì…ë‹ˆë‹¤!")
                    
                    wide_result = _parse_wide_excel_first_sheet(uploaded)
                    
                    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ (questionsê°€ ì—†ìœ¼ë©´)
                    if not wide_result.get("questions"):
                        st.error("âŒ XLSX íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨!")
                        st.error("ğŸš¨ **í•„ìˆ˜ ì¡°ì¹˜**: Excelì—ì„œ íŒŒì¼ì„ ì—´ê³  CSV UTF-8ë¡œ ì €ì¥ í›„ ì¬ì—…ë¡œë“œí•˜ì„¸ìš”!")
                        return
                    
                    # ğŸš¨ ë©”íƒ€ë°ì´í„° ì—´ ê±´ë„ˆë›°ê¸° ì•Œë¦¼
                    if wide_result.get("skipped_columns"):
                        with log_box:
                            st.info(f"ğŸ“‹ ë©”íƒ€ë°ì´í„°/PII ì—´ ê±´ë„ˆë›°ê¸°: {len(wide_result['skipped_columns'])}ê°œ")
                            with st.expander("ğŸ” ê±´ë„ˆë›´ ì—´ ëª©ë¡ ë³´ê¸°"):
                                for col in wide_result["skipped_columns"]:
                                    st.write(f"   - {col}")
                                st.caption("ğŸ’¡ ì´ ì—´ë“¤ì€ ì‘ë‹µì ê°œì¸ì •ë³´ë¡œ ê°„ì£¼ë˜ì–´ ë¬¸í•­ìœ¼ë¡œ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    # ì‹¤ì œë¡œ CSV íŒŒì¼ (ê°€ì¥ ì•ˆì •ì )
                    with log_box:
                        st.write("ğŸ“Š CSV ì™€ì´ë“œ í¬ë§· íŒŒì‹± ì¤‘...")
                        st.info("ğŸ’¡ íŒŒì¼ ì‹œê·¸ë‹ˆì²˜: CSV")
                    
                    wide_result = _parse_wide_csv(uploaded)
                    
                    # ğŸš¨ ë©”íƒ€ë°ì´í„° ì—´ ê±´ë„ˆë›°ê¸° ì•Œë¦¼
                    if wide_result.get("skipped_columns"):
                        with log_box:
                            st.info(f"ğŸ“‹ ë©”íƒ€ë°ì´í„°/PII ì—´ ê±´ë„ˆë›°ê¸°: {len(wide_result['skipped_columns'])}ê°œ")
                            with st.expander("ğŸ” ê±´ë„ˆë›´ ì—´ ëª©ë¡ ë³´ê¸°"):
                                for col in wide_result["skipped_columns"]:
                                    st.write(f"   - {col}")
                                st.caption("ğŸ’¡ ì´ ì—´ë“¤ì€ ì‘ë‹µì ê°œì¸ì •ë³´ë¡œ ê°„ì£¼ë˜ì–´ ë¬¸í•­ìœ¼ë¡œ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ğŸ’¡ ì™€ì´ë“œ í¬ë§· Questions ë“±ë¡ (Excel/CSV ê³µí†µ ì²˜ë¦¬)
            # ğŸš¨ í•µì‹¬ ìˆ˜ì •: íŒŒì¼ í—¤ë” í…ìŠ¤íŠ¸ë¥¼ registered_itemsì˜ item_textì™€ ë§¤í•‘í•˜ì—¬ ì‹¤ì œ item_id ì‚¬ìš©
            question_text_to_item_id = {}  # ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
            
            if use_wide_format and wide_result["questions"]:
                # 1. ì§ˆë¬¸ í…ìŠ¤íŠ¸ì™€ item_id ë§¤í•‘ ìƒì„±
                if registered_items:
                    with log_box:
                        st.write("ğŸ” íŒŒì¼ í—¤ë”ë¥¼ Survey_Itemsì˜ item_idì™€ ë§¤í•‘ ì¤‘...")
                    
                    for q in wide_result["questions"]:
                        q_text = q.get("text", "").strip()
                        # registered_itemsì—ì„œ ë§¤ì¹­ë˜ëŠ” item_text ì°¾ê¸°
                        matched_item = None
                        for item in registered_items:
                            item_text = item.get("item_text", "").strip()
                            # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¹„êµ (ì •ê·œí™”ëœ ë¹„êµ)
                            if q_text and item_text:
                                # ê°„ë‹¨í•œ ë§¤ì¹­: ì• 50ì ë¹„êµ ë˜ëŠ” ì „ì²´ í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€
                                if q_text[:50] in item_text or item_text[:50] in q_text:
                                    matched_item = item
                                    break
                        
                        if matched_item:
                            # ë§¤í•‘ ì„±ê³µ: ì‹¤ì œ item_id ì‚¬ìš©
                            item_id = matched_item.get("item_id")
                            question_text_to_item_id[q["questionId"]] = item_id
                            q["questionId"] = item_id  # ğŸš¨ ì„ì‹œ IDë¥¼ ì‹¤ì œ item_idë¡œ êµì²´
                            
                            with log_box:
                                st.write(f"   âœ“ '{q_text[:40]}...' â†’ {item_id}")
                        else:
                            # ë§¤ì¹­ ì‹¤íŒ¨: ê²½ê³  í‘œì‹œ
                            with log_box:
                                st.warning(f"   âš ï¸ '{q_text[:40]}...' - Survey_Itemsì—ì„œ ë§¤ì¹­ ì‹¤íŒ¨")
                
                # 2. Questions ì‹œíŠ¸ ë“±ë¡ (ë ˆê±°ì‹œ í˜¸í™˜ìš© - v2 ìŠ¤í‚¤ë§ˆì—ì„œëŠ” optional)
                # ğŸ’¡ v2 ìŠ¤í‚¤ë§ˆì—ì„œëŠ” Survey_Itemsë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ, Questions ì‹œíŠ¸ ì—†ì–´ë„ OK
                with log_box:
                    st.info("ğŸ’¡ v2 ìŠ¤í‚¤ë§ˆ: Survey_Itemsë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ Questions ì‹œíŠ¸ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.")
                
                # Questions ì¹´ìš´íŠ¸ëŠ” Survey_Items ê¸°ì¤€ìœ¼ë¡œ
                imported_questions = len(wide_result["questions"])
            elif has_questions:
                q_df = dfs["questions"].fillna("")
                for _, r in q_df.iterrows():
                    q = _normalize_question_row(r.to_dict())
                    if not q.get("courseId"):
                        q["courseId"] = course_saved_id
                    if not q.get("order"):
                        q["order"] = "0"
                    _with_backoff(upsert_question, spreadsheet, q)
                    imported_questions += 1
                    # Add delay every 10 questions to avoid quota limits
                    if imported_questions % 10 == 0:
                        time.sleep(1)
                    with log_box:
                        st.write(
    f"Questions ë“±ë¡: questionId={
        q['questionId']}, order={
            q['order']}, text='{
                q.get(
                    'text', '')[
                        :60]}'")

            # 3) Responses ì €ì¥ (í‘œì¤€ ë˜ëŠ” ì™€ì´ë“œ í¬ë§·) - v2 ìŠ¤í‚¤ë§ˆ ì‚¬ìš©
            imported_responses = 0
            if use_wide_format and wide_result["responses"]:
                # ê° ì‘ë‹µì ë¬¶ìŒë³„ë¡œ ë™ì¼ respondent_idë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ index ë‹¨ìœ„ë¡œ ê·¸ë£¹í•‘
                from collections import defaultdict
                idx_to_resps = defaultdict(list)
                for r in wide_result["responses"]:
                    idx_to_resps[r["respondentIndex"]].append(r)
                
                # ğŸ†• ì›ë³¸ ë°ì´í„°ì—ì„œ ì‘ë‹µì ë©”íƒ€ë°ì´í„°(íšŒì‚¬ëª… ë“±) ì¶”ì¶œì„ ìœ„í•œ ì¤€ë¹„
                respondent_metadata = {}  # {respondent_index: {"company": "...", ...}}
                
                try:
                    # ì›ë³¸ íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì—´ ì¶”ì¶œ
                    uploaded.seek(0)
                    file_magic_meta = uploaded.read(4)
                    uploaded.seek(0)
                    
                    is_zip_based_meta = file_magic_meta[:2] == b'PK'
                    
                    if is_zip_based_meta:
                        # ì‹¤ì œë¡œ XLSX íŒŒì¼
                        df_meta = pd.read_excel(uploaded, header=0, engine='openpyxl')
                    else:
                        # ì‹¤ì œë¡œ CSV íŒŒì¼ - ë‹¤ì¤‘ ì¸ì½”ë”© ì‹œë„
                        df_meta = None
                        for encoding in ['utf-8-sig', 'cp949', 'euc-kr', 'utf-8', 'latin-1']:
                            try:
                                uploaded.seek(0)
                                df_meta = pd.read_csv(uploaded, encoding=encoding)
                                break
                            except Exception:
                                continue
                        if df_meta is None:
                            raise ValueError("CSV ë©”íƒ€ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
                    # íšŒì‚¬ëª… ì—´ ì°¾ê¸°
                    company_col = None
                    for col in df_meta.columns:
                        if "íšŒì‚¬" in str(col) or "ì†Œì†" in str(col) or "company" in str(col).lower():
                            company_col = col
                            break
                    
                    # ê° ì‘ë‹µìì˜ íšŒì‚¬ëª… ì¶”ì¶œ ë° ì •ê·œí™”
                    if company_col:
                        for idx in range(len(df_meta)):
                            company_raw = df_meta.loc[idx, company_col] if company_col in df_meta.columns else ""
                            respondent_metadata[idx] = {
                                "company": normalize_company_name(str(company_raw)) if pd.notna(company_raw) else ""
                            }
                        with log_box:
                            st.write(f"âœ… íšŒì‚¬ëª… ì •ê·œí™” ì™„ë£Œ: {len(respondent_metadata)}ê°œ ì‘ë‹µì")
                except Exception as e:
                    with log_box:
                        st.warning(f"âš ï¸ ì‘ë‹µì ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
                
                op_count = 0
                for respondent_index, resp_list in sorted(idx_to_resps.items(), key=lambda x: x[0]):
                    # ğŸš¨ ìˆ˜ì •: respondentIndex ê¸°ë°˜ìœ¼ë¡œ ì¼ê´€ëœ respondent_idë¥¼ ìƒì„±
                    # íŒŒì¼ ì—…ë¡œë“œì—ì„œ ê³ ìœ í•œ ì‚¬ìš©ì í•´ì‹œë¥¼ ìƒì„±í•˜ì—¬ respondent_idë¡œ ì‚¬ìš©
                    respondent_hash_key = f"upload_{course_saved_id}_{respondent_index}"
                    respondent_id = f"U-{hashlib.md5(respondent_hash_key.encode()).hexdigest()[:10]}"
                    
                    # ğŸ†• ì‘ë‹µì ì •ë³´ ì €ì¥ (v2 ìŠ¤í‚¤ë§ˆ - Respondents ì‹œíŠ¸)
                    respondent_info = respondent_metadata.get(respondent_index, {})
                    try:
                        respondent_data = {
                            "respondent_id": respondent_id,
                            "course_id": course_saved_id,
                            "pii_consent": "",
                            "company": respondent_info.get("company", ""),
                            "department": "",
                            "job_role": "",
                            "tenure_years": "",
                            "name": "",
                            "phone": "",
                            "email": "",
                            "hashed_contact": "",
                            "extra_meta": "",
                            "created_at": datetime.now(timezone.utc).isoformat(),
                        }
                        _with_backoff(save_respondent, spreadsheet, respondent_data)
                        
                        if respondent_info.get("company"):
                            with log_box:
                                st.write(f"   Respondent {respondent_id}: {respondent_info['company']}")
                    except Exception as e:
                        with log_box:
                            st.warning(f"âš ï¸ ì‘ë‹µì ì •ë³´ ì €ì¥ ì‹¤íŒ¨ (ID: {respondent_id}): {str(e)}")
                    
                    for r in resp_list:
                        # ğŸš¨ v2 ìŠ¤í‚¤ë§ˆë¡œ ì‘ë‹µ ë°ì´í„° êµ¬ì„±
                        # ğŸ”‘ í•µì‹¬: ì„ì‹œ questionIdë¥¼ ë§¤í•‘ëœ ì‹¤ì œ item_idë¡œ ë³€í™˜
                        original_qid = r["questionId"]
                        actual_item_id = question_text_to_item_id.get(original_qid, original_qid)
                        
                        answer_str = str(r["answer"]) if r["answer"] else ""
                        
                        # ìˆ«ì ë³€í™˜ ì‹œë„
                        response_value_num = None
                        try:
                            if answer_str.strip():
                                response_value_num = float(answer_str)
                        except (ValueError, TypeError):
                            pass
                        
                        response_data = {
                            "response_id": generate_response_id(),
                            "course_id": course_saved_id,
                            "respondent_id": respondent_id,
                            "timestamp": datetime.now(timezone.utc).isoformat(),
                            "item_id": actual_item_id,  # ğŸš¨ ë§¤í•‘ëœ ì‹¤ì œ item_id ì‚¬ìš©
                            "response_value": answer_str,
                            "response_value_num": response_value_num,
                            "choice_value": "",
                            "comment_text": answer_str if r.get("type") == "subjective" else "",
                            "source_row_index": str(respondent_index + 2),  # í—¤ë” ì œì™¸í•œ í–‰ ë²ˆí˜¸
                            "ingest_batch_id": generate_batch_id(),
                        }
                        
                        # ğŸš¨ save_response_v2 í˜¸ì¶œë¡œ ë³€ê²½
                        _with_backoff(save_response_v2, spreadsheet, response_data)
                        imported_responses += 1
                        op_count += 1
                        
                        # More frequent delays to avoid quota limits
                        if op_count % 20 == 0:
                            time.sleep(1.5)
                            with log_box:
                                st.write(f"â¸ï¸ API ì¿¼í„° ë³´í˜¸: 20ê°œ ì‘ì—…ë§ˆë‹¤ 1.5ì´ˆ ëŒ€ê¸°")
                        
                        with log_box:
                            st.write(
                                f"Responses ë“±ë¡ (v2): item_id={actual_item_id}, "
                                f"answer='{answer_str[:60]}', respondent_id={respondent_id}"
                            )
            elif has_responses:
                r_df = dfs["responses"].fillna("")
                op_count = 0
                for row_idx, r in r_df.iterrows():
                    resp = _normalize_response_row(r.to_dict())
                    # courseId ë³´ì •
                    if not resp.get("courseId"):
                        resp["courseId"] = course_saved_id
                    
                    # ğŸš¨ v2 ìŠ¤í‚¤ë§ˆë¡œ ì‘ë‹µ ë°ì´í„° êµ¬ì„±
                    answer_str = str(resp.get("answer", ""))
                    
                    # ìˆ«ì ë³€í™˜ ì‹œë„
                    response_value_num = None
                    try:
                        if answer_str.strip():
                            response_value_num = float(answer_str)
                    except (ValueError, TypeError):
                        pass
                    
                    # respondentHashë¥¼ respondent_idë¡œ ë³€í™˜
                    respondent_id = f"U-{resp.get('respondentHash', 'unknown')[:10]}"
                    
                    response_data = {
                        "response_id": generate_response_id(),
                        "course_id": resp["courseId"],
                        "respondent_id": respondent_id,
                        "timestamp": datetime.now(timezone.utc).isoformat(),
                        "item_id": resp["questionId"],  # questionIdë¥¼ item_idë¡œ ì‚¬ìš©
                        "response_value": answer_str,
                        "response_value_num": response_value_num,
                        "choice_value": "",
                        "comment_text": answer_str,  # ëª¨ë“  ì‘ë‹µì„ commentë¡œ ì €ì¥
                        "source_row_index": str(row_idx + 2),  # í—¤ë” ì œì™¸í•œ í–‰ ë²ˆí˜¸
                        "ingest_batch_id": generate_batch_id(),
                    }
                    
                    # ğŸš¨ save_response_v2 í˜¸ì¶œë¡œ ë³€ê²½
                    _with_backoff(save_response_v2, spreadsheet, response_data)
                    imported_responses += 1
                    op_count += 1
                    
                    # More frequent delays to avoid quota limits
                    if op_count % 20 == 0:
                        time.sleep(1.5)
                        with log_box:
                            st.write(f"â¸ï¸ API ì¿¼í„° ë³´í˜¸: 20ê°œ ì‘ì—…ë§ˆë‹¤ 1.5ì´ˆ ëŒ€ê¸°")
                    
                    with log_box:
                        st.write(
                            f"Responses ë“±ë¡ (v2): item_id={resp['questionId']}, "
                            f"answer='{answer_str[:60]}', respondent_id={respondent_id}"
                        )

            # 4) í†µê³„ ê°±ì‹  (v2 ìŠ¤í‚¤ë§ˆì—ì„œëŠ” optional - Questions ì‹œíŠ¸ í•„ìš” ì—†ìŒ)
            if course_saved_id:
                try:
                    update_response_stats(spreadsheet, course_saved_id)
                    with log_box:
                        st.write("âœ… ResponseStats ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                except Exception as stats_err:
                    with log_box:
                        st.info(f"ğŸ’¡ ResponseStats ì—…ë°ì´íŠ¸ ê±´ë„ˆëœ€ (v2 ìŠ¤í‚¤ë§ˆì—ì„œëŠ” ë¶ˆí•„ìš”): {str(stats_err)[:100]}")

            st.success(
                f"âœ… ì—…ë¡œë“œ ì™„ë£Œ!\n\n"
                f"- ì½”ìŠ¤ID: **{course_saved_id}**\n"
                f"- í”„ë¡œê·¸ë¨: **{course_obj_v2.get('program_name')}**\n"
                f"- ì§ˆë¬¸: {imported_questions}ê°œ\n"
                f"- ì‘ë‹µ: {imported_responses}ê°œ"
            )

            # ìºì‹œ í´ë¦¬ì–´ (ë¦¬ìŠ¤íŠ¸ ì¦‰ì‹œ ê°±ì‹ )
            st.cache_data.clear()

            # ì„¸ì…˜ ìƒíƒœ í´ë¦¬ì–´ (ë‹¤ìŒ ì—…ë¡œë“œë¥¼ ìœ„í•´)
            st.session_state.upload_course_id = ""
            st.session_state.course_id_user_edited = False

            st.balloons()
            st.info("ğŸ’¡ 'ê³¼ì • ë¦¬ìŠ¤íŠ¸' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì—¬ ìƒˆë¡œ ì¶”ê°€ëœ ê³¼ì •ì„ í™•ì¸í•˜ì„¸ìš”!")

        except Exception as e:
            import traceback
            st.error(f"âŒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            with st.expander("ğŸ” ìƒì„¸ ì—ëŸ¬ ì •ë³´ (ë””ë²„ê¹…ìš©)"):
                st.code(traceback.format_exc())


def page_course_list(spreadsheet, is_admin: bool):
    st.markdown(
        """
        <div class="sk-page-header">
          <div class="title">mySUNI êµìœ¡ ê³¼ì • List</div>
          <div class="subtitle">ì¹´í…Œê³ ë¦¬ë³„ êµìœ¡ ê³¼ì •ì„ ì°¾ì•„ë³´ì„¸ìš”</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

    # v2 ìŠ¤í‚¤ë§ˆ ì‹œë„
    try:
        rows = list_courses_v2(spreadsheet, status=None)  # ëª¨ë“  ìƒíƒœ
        # v2 í•„ë“œ ì‚¬ìš©
        use_v2 = True
    except Exception:
        rows = get_all_courses_cached(spreadsheet)
        use_v2 = False

    # í•„í„°ë§: program_name/titleì´ ìˆëŠ” ê²ƒë§Œ
    if use_v2:
        valid_rows = [
    r for r in rows if str(
        r.get(
            "program_name",
             "")).strip()]
    else:
        valid_rows = [r for r in rows if str(r.get("title", "")).strip()]

    if not valid_rows:
        st.info("ë“±ë¡ëœ ê³¼ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
        if is_admin:
            with st.expander("ìƒˆ ê³¼ì • ë§Œë“¤ê¸°"):
                _course_create_form_v2(
                    spreadsheet) if use_v2 else _course_create_form(spreadsheet)
        return

    # Group by category/event_type
    categories = {}
    for r in valid_rows:
        if use_v2:
            cat = (r.get("event_type") or "ê¸°ë³¸").strip()
        else:
            cat = (r.get("category") or "ê¸°ë³¸").strip()
        categories.setdefault(cat, []).append(r)

    for cat, items in categories.items():
        st.markdown(f"### {cat}")
        cols = st.columns(3)
        for i, row in enumerate(items):
            with cols[i % 3]:
                # v2 vs ë ˆê±°ì‹œ í•„ë“œ
                if use_v2:
                    title = row.get('program_name', '(ì œëª©ì—†ìŒ)')
                    desc = f"{
    row.get(
        'theme',
        '')} | {
            row.get(
                'session_no',
                '')}íšŒì°¨ | {
                    row.get(
                        'event_date',
                         '')}"
                    course_id = row.get('course_id')
                else:
                    title = row.get('title', '(ì œëª©ì—†ìŒ)')
                    desc = row.get('description', '')
                    course_id = row.get('courseId')

                st.markdown(
                    f"""
                    <div class='sk-card'>
                      <h4>{title}</h4>
                      <div class='sk-desc'>{desc}</div>
                    </div>
                    """,
                    unsafe_allow_html=True,
                )
                if is_admin:
                    c1, c2 = st.columns(2)
                    with c1:
                        if st.button("ì„¤ë¬¸ í¸ì§‘", key=f"edit_{course_id}"):
                            st.session_state["editing_course_id"] = str(
                                course_id)
                            st.session_state["viewing_dashboard"] = None
                    with c2:
                        if st.button("ê²°ê³¼ ë³´ê¸°", key=f"result_{course_id}"):
                            st.session_state["viewing_dashboard"] = str(
                                course_id)
                            st.session_state["editing_course_id"] = None
                else:
                    st.button("ì„¤ë¬¸ ì°¸ì—¬", key=f"join_{course_id}")

    # Editor panel if a course is selected
    if is_admin and st.session_state.get("editing_course_id"):
        st.divider()
        _course_editor(spreadsheet, st.session_state["editing_course_id"])

    # Dashboard if viewing results
    if is_admin and st.session_state.get("viewing_dashboard"):
        st.divider()
        page_dashboard(spreadsheet, st.session_state["viewing_dashboard"])


def _course_create_form(spreadsheet):
    with st.form("create_course"):
        course: Dict[str, str] = {}
        course["courseId"] = st.text_input(
            "ê³¼ì •ID", value=str(int(datetime.utcnow().timestamp())))
        course["title"] = st.text_input("ì œëª©")
        course["description"] = st.text_area("ì„¤ëª…")
        course["category"] = st.text_input("ì¹´í…Œê³ ë¦¬", value="ê¸°ë³¸")
        course["createdAt"] = datetime.utcnow().isoformat()
        course["status"] = st.selectbox("ìƒíƒœ", ["active", "inactive"], index=0)
        course["ownerId"] = st.text_input("ê´€ë¦¬ìID", value="admin")
        submitted = st.form_submit_button("ì €ì¥")
        if submitted:
            upsert_course(spreadsheet, course)
            st.success("ê³¼ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨í•˜ì—¬ í™•ì¸í•˜ì„¸ìš”.")


def _course_create_form_v2(spreadsheet):
    """v2 ìŠ¤í‚¤ë§ˆ ê³¼ì • ìƒì„± í¼"""
    with st.form("create_course_v2"):
        st.markdown("### ìƒˆ ê³¼ì • ë§Œë“¤ê¸° (v2)")

        col1, col2 = st.columns(2)

        with col1:
            course_id = st.text_input(
    "ê³¼ì • ID*", value=generate_course_id(), help="ê³ ìœ  ì‹ë³„ì")
            program_name = st.text_input(
    "í”„ë¡œê·¸ë¨ëª…*", placeholder="Next Chip Talk")
            session_no = st.text_input("íšŒì°¨*", value="1")
            theme = st.text_input("ì£¼ì œ*", placeholder="AI ë°˜ë„ì²´ ì„¤ê³„")

        with col2:
            event_type = st.selectbox(
                "ì´ë²¤íŠ¸ ìœ í˜•*", ["NCT", "Forum", "Workshop", "Webinar", "Internal Talk"], index=0)
            event_date = st.date_input("í–‰ì‚¬ ë‚ ì§œ*")
            location = st.text_input("ì¥ì†Œ", value="ì˜¨ë¼ì¸")
            host_org = st.text_input("ì£¼ìµœ/ì£¼ê´€", value="SK hynix")

        speakers = st.text_input("ì—°ì‚¬ (ì„¸ë¯¸ì½œë¡  êµ¬ë¶„)", placeholder="ê¹€ë°•ì‚¬;ì´êµìˆ˜")
        status = st.selectbox(
            "ìƒíƒœ*", ["planned", "active", "completed", "archived"], index=0)

        submitted = st.form_submit_button("ê³¼ì • ì €ì¥")

        if submitted:
            if not all([course_id, program_name,
                       session_no, theme, event_type]):
                st.error("âŒ í•„ìˆ˜ í•­ëª©(*)ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return

            course = {
                "course_id": course_id,
                "program_name": program_name,
                "session_no": session_no,
                "theme": theme,
                "event_type": event_type,
                "event_date": event_date.isoformat() if event_date else "",
                "location": location,
                "host_org": host_org,
                "speakers": speakers,
                "survey_form_version": "v2.0",
                "response_source_file": "",
                "status": status,
                "created_at": datetime.now(timezone.utc).isoformat(),
                "updated_at": datetime.now(timezone.utc).isoformat(),
            }

            try:
                upsert_course_v2(spreadsheet, course)
                st.success("âœ… ê³¼ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.cache_data.clear()  # ìºì‹œ í´ë¦¬ì–´
                st.balloons()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {str(e)}")


def _course_editor(spreadsheet, course_id: str):
    st.markdown(f"#### ì„¤ë¬¸ í¸ì§‘ê¸° Â· Course ID: {course_id}")
    settings = get_survey_settings(spreadsheet, course_id)
    active_now = str(settings.get("isActive", "FALSE")).upper() == "TRUE"
    col1, col2 = st.columns([1, 3])
    with col1:
        new_state = st.toggle("ì„¤ë¬¸ í™œì„±í™”", value=active_now)
        if new_state != active_now:
            set_survey_active(spreadsheet, course_id, new_state)
            st.toast("ì„¤ë¬¸ í™œì„±í™” ìƒíƒœê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    with col2:
        st.write("ë¯¸ë¦¬ë³´ê¸°(ê°„ë‹¨)")
        _render_preview(spreadsheet, course_id)

    st.markdown("##### ë¬¸í•­ ëª©ë¡")

    # v2 ìŠ¤í‚¤ë§ˆ ì‹œë„ (Course_Item_Map + Survey_Items)
    try:
        questions = get_course_items(spreadsheet, course_id)
        is_v2 = True
    except Exception:
        # ë ˆê±°ì‹œ ìŠ¤í‚¤ë§ˆë¡œ í´ë°±
        questions = list_questions(spreadsheet, course_id)
        is_v2 = False

    if not questions:
        st.info("ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ì¶”ê°€í•˜ì„¸ìš”.")
    else:
        for q in questions:
            q_col1, q_col2 = st.columns([4, 1])
            with q_col1:
                # v2: metric_type, item_text ì‚¬ìš© / ë ˆê±°ì‹œ: type, text ì‚¬ìš©
                q_type = q.get('metric_type') if is_v2 else q.get('type')
                q_order = q.get('order_in_course') if is_v2 else q.get('order')
                q_text = q.get('item_text') if is_v2 else q.get('text')
                st.markdown(f"- ({q_type}) [{q_order}] {q_text}")
            with q_col2:
                q_id = q.get('item_id') if is_v2 else q.get('questionId')
                if st.button("ì‚­ì œ", key=f"del_{q_id}"):
                    if delete_question(spreadsheet, str(q_id)):
                        st.experimental_rerun()

    st.markdown("##### ë¬¸í•­ ì¶”ê°€")
    with st.form("add_question"):
        q = {}
        q["questionId"] = st.text_input("ë¬¸í•­ID", value=str(
            int(datetime.utcnow().timestamp() * 1000)))
        q["courseId"] = course_id
        q["order"] = st.number_input(
    "í‘œì‹œ ìˆœì„œ", min_value=1, value=(
        len(questions) + 1))
        q["text"] = st.text_input("ë¬¸í•­ ë‚´ìš©")
        q_type = st.selectbox(
    "ë¬¸í•­ ìœ í˜•", [
        "objective", "subjective", "rating"], index=0)
        q["type"] = q_type
        if q_type == "objective":
            choices = st.text_area("ì„ íƒì§€(ì‰¼í‘œë¡œ êµ¬ë¶„)")
            q["choicesJson"] = "[" + ",".join([f'\"{c.strip()}\"' for c in choices.split(
                ',') if c.strip()]) + "]" if choices else "[]"
        else:
            q["choicesJson"] = "[]"
        if q_type == "rating":
            q["ratingMax"] = str(
    st.number_input(
        "ìµœëŒ€ í‰ì ",
        min_value=3,
        max_value=10,
         value=5))
        else:
            q["ratingMax"] = ""
        q["isRequired"] = "TRUE" if st.checkbox("í•„ìˆ˜ ë¬¸í•­") else "FALSE"
        q["maxChars"] = str(
    st.number_input(
        "ìµœëŒ€ ê¸€ì ìˆ˜(ì£¼ê´€ì‹)",
        min_value=0,
         value=0))
        submitted = st.form_submit_button("ë¬¸í•­ ì¶”ê°€")
        if submitted:
            upsert_question(spreadsheet, q)
            st.success("ë¬¸í•­ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.experimental_rerun()


def _render_preview(spreadsheet, course_id: str):
    # v2 ìŠ¤í‚¤ë§ˆ ì‹œë„
    try:
        questions = get_course_items(spreadsheet, course_id)
        is_v2 = True
    except Exception:
        questions = list_questions(spreadsheet, course_id)
        is_v2 = False

    if not questions:
        st.caption("ë¯¸ë¦¬ë³´ê¸°í•  ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    for q in questions:
        if is_v2:
            # v2 ìŠ¤í‚¤ë§ˆ
            order = q.get('order_in_course', '0')
            text = q.get('item_text', '')
            q_type = q.get('metric_type', 'text')
            q_id = q.get('item_id', '')

            st.write(f"{order}. {text}")

            if q_type == "single_choice" or q_type == "multi_choice":
                options_str = q.get("options", "[]")
                try:
                    options = json.loads(options_str) if options_str else []
                except:
                    options = []
                if options:
                    st.radio(" ", options=options, key=f"prev_{q_id}")
            elif q_type == "likert" or q_type == "nps":
                scale_max = int(q.get("scale_max") or 5)
                st.slider(
    " ",
    min_value=1,
    max_value=scale_max,
    value=(
        scale_max + 1) // 2,
         key=f"prev_{q_id}")
            else:
                st.text_input(" ", key=f"prev_{q_id}")
        else:
            # ë ˆê±°ì‹œ ìŠ¤í‚¤ë§ˆ
            st.write(f"{q.get('order')}. {q.get('text')}")
        t = q.get("type")
        if t == "objective":
            choices_str = q.get("choicesJson", "[]")
            try:
                choices = json.loads(choices_str) if choices_str else []
            except:
                choices = []
            if choices:
                st.radio(
    " ", options=choices, key=f"prev_{
        q.get('questionId')}")
        elif t == "rating":
            st.slider(" ", min_value=1, max_value=int(q.get("ratingMax") or 5), value=int(
                (int(q.get("ratingMax") or 5) + 1) / 2), key=f"prev_{q.get('questionId')}")
        else:
            st.text_input(" ", key=f"prev_{q.get('questionId')}")


def generate_respondent_hash() -> str:
    """Generate a hash for respondent identification"""
    session_id = st.session_state.get("session_id", "default")
    timestamp = str(datetime.utcnow().timestamp())
    return hashlib.md5(f"{session_id}_{timestamp}".encode()).hexdigest()[:8]


def mask_ip_address(ip: str) -> str:
    """Mask IP address for privacy"""
    if not ip or ip == "unknown":
        return "***.***.***.***"
    parts = ip.split(".")
    if len(parts) == 4:
        return f"{parts[0]}.{parts[1]}.***.***"
    return "***.***.***.***"


def render_survey_form(spreadsheet, course_id: str):
    """Render the survey form for a specific course (v2 ìŠ¤í‚¤ë§ˆ í˜¸í™˜)"""

    # v2 ìŠ¤í‚¤ë§ˆ ì‹œë„
    try:
        course_v2 = get_course_by_id_v2(spreadsheet, course_id)
        if course_v2:
            use_v2 = True
        else:
            course = get_course_by_id(spreadsheet, course_id)
            use_v2 = False
    except Exception as e:
        st.error(f"âŒ ê³¼ì • ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        return

    if use_v2:
        if not course_v2:
            st.error(f"âŒ ê³¼ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {course_id}")
            return

        # v2 ìŠ¤í‚¤ë§ˆ: status í™•ì¸
        if str(course_v2.get("status", "")).strip().lower() != "active":
            st.warning("âš ï¸ ì´ ì„¤ë¬¸ì€ í˜„ì¬ ë¹„í™œì„±í™” ìƒíƒœì…ë‹ˆë‹¤.")
            st.caption("ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.")
            return

        course_title = f"{
    course_v2.get(
        'program_name',
        '')} - {
            course_v2.get(
                'theme',
                 '')}"
        course_desc = f"{
    course_v2.get(
        'event_type',
        '')} | {
            course_v2.get(
                'session_no',
                '')}íšŒì°¨ | {
                    course_v2.get(
                        'event_date',
                         '')}"
    else:
        if not course:
            st.error("âŒ ê³¼ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë ˆê±°ì‹œ ìŠ¤í‚¤ë§ˆ: settings í™•ì¸
        settings = get_survey_settings(spreadsheet, course_id)
        if str(settings.get("isActive", "FALSE")).upper() != "TRUE":
            st.warning("âš ï¸ ì´ ì„¤ë¬¸ì€ í˜„ì¬ ë¹„í™œì„±í™” ìƒíƒœì…ë‹ˆë‹¤.")
            return

        course_title = course.get('title', 'ì„¤ë¬¸')
        course_desc = course.get('description', '')

    st.markdown(
        f"""
        <div class="sk-page-header" style="margin-top:8px;">
          <div class="title">{course_title} ì„¤ë¬¸ì— ì°¸ì—¬í•´ì£¼ì„¸ìš”!</div>
          <div class="subtitle">{course_desc}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

    # v2 ìŠ¤í‚¤ë§ˆ ì‹œë„
    try:
        questions = get_course_items(spreadsheet, course_id)
        is_v2 = True
    except Exception:
        questions = list_questions(spreadsheet, course_id)
        is_v2 = False

    if not questions:
        st.info("ì„¤ë¬¸ ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # Initialize session
    if "session_id" not in st.session_state:
        st.session_state["session_id"] = f"session_{
    int(
        datetime.utcnow().timestamp())}"

    # Render questions
    responses = {}
    for i, q in enumerate(questions):
        # v2 vs ë ˆê±°ì‹œ í•„ë“œ ì¶”ì¶œ
        if is_v2:
            q_text = q.get('item_text', '')
            q_id = str(q.get('item_id'))
            is_required = str(q.get('is_required', 'FALSE')).upper() == 'TRUE'
            q_type = q.get('metric_type', 'text')
        else:
            q_text = q.get('text', '')
            q_id = str(q.get('questionId'))
            is_required = str(q.get('isRequired', 'FALSE')).upper() == 'TRUE'
            q_type = q.get('type', 'subjective')

        st.markdown(f"### {i + 1}. {q_text}")
        if is_required:
            st.markdown(
    "<span style='color:#D90B31;font-family: TheJamsil-4;'>*í•„ìˆ˜ ë¬¸í•­*</span>",
     unsafe_allow_html=True)

        # v2 íƒ€ì… ë§¤í•‘ (likert â†’ rating, single_choice â†’ objective)
        if is_v2:
            if q_type in ['likert', 'nps']:
                q_type = 'rating'
            elif q_type in ['single_choice', 'multi_choice']:
                q_type = 'objective'
            else:
                q_type = 'subjective'

        if q_type == 'objective':
            if is_v2:
                choices_str = q.get('options', '[]')
            else:
                choices_str = q.get('choicesJson', '[]')
            try:
                choices = json.loads(choices_str) if choices_str else []
            except:
                choices = []
            if choices:
                response = st.radio(
                    "ì„ íƒí•˜ì„¸ìš”:",
                    options=choices,
                    key=f"q_{q_id}",
                    index=None
                )
                responses[q_id] = response or ""
            else:
                st.warning("ì„ íƒì§€ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                responses[q_id] = ""

        elif q_type == 'rating':
            if is_v2:
                max_rating = int(q.get('scale_max', 5))
            else:
                max_rating = int(q.get('ratingMax', 5))
            response = st.slider(
                f"í‰ì ì„ ì„ íƒí•˜ì„¸ìš” (1-{max_rating}ì ):",
                min_value=1,
                max_value=max_rating,
                value=(max_rating + 1) // 2,
                key=f"q_{q_id}"
            )
            responses[q_id] = str(response)

        else:  # subjective
            max_chars = int(q.get('maxChars', 0)) if not is_v2 else 0
            char_limit = f" (ìµœëŒ€ {max_chars}ì)" if max_chars > 0 else ""
            response = st.text_area(
                f"ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”{char_limit}:",
                key=f"q_{q_id}",
                max_chars=max_chars if max_chars > 0 else None
            )
            responses[q_id] = response or ""

        st.divider()

    # Submit button
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        if st.button("ì„¤ë¬¸ ì œì¶œ", type="primary", use_container_width=True):
            # Validate required fields
            missing_required = []
            for q in questions:
                if is_v2:
                    is_required = str(
    q.get(
        'is_required',
         'FALSE')).upper() == 'TRUE'
                    q_id = str(q.get('item_id'))
                    q_text = q.get(
    'item_text', f"ë¬¸í•­ {
        q.get(
            'order_in_course', '')}")
                else:
                    is_required = str(
    q.get(
        'isRequired',
         'FALSE')).upper() == 'TRUE'
                    q_id = str(q.get('questionId'))
                    q_text = q.get('text', f"ë¬¸í•­ {q.get('order', '')}")

                if is_required:
                    if not responses.get(
                        q_id) or responses[q_id].strip() == "":
                        missing_required.append(q_text)

            if missing_required:
                st.error(f"âŒ ë‹¤ìŒ í•„ìˆ˜ ë¬¸í•­ì„ ë‹µí•´ì£¼ì„¸ìš”: {', '.join(missing_required)}")
            else:
                # Save responses
                try:
                    if is_v2:
                        # v2 ìŠ¤í‚¤ë§ˆ: Respondents + Responses ì €ì¥
                        import uuid
                        respondent_id = f"U-{uuid.uuid4().hex[:10]}"

                        # Respondent ì €ì¥ (PII ì—†ì´)
                        respondent_data = {
                            "respondent_id": respondent_id,
                            "course_id": course_id,
                            "pii_consent": False,
                            "company": None,
                            "job_role": None,
                            "tenure_years": None,
                            "name": None,
                            "phone": None,
                            "email": None,
                            "hashed_contact": generate_respondent_hash(),
                            "extra_meta": None,
                        }

                        with st.spinner("ì„¤ë¬¸ì„ ì œì¶œí•˜ëŠ” ì¤‘..."):
                            save_respondent(spreadsheet, respondent_data)

                            # Responses ì €ì¥
                            batch_id = f"B-{
    datetime.now(
        timezone.utc).isoformat()}"
                            for idx, (item_id, answer) in enumerate(
                                responses.items()):
                                response_data = {
                                    "response_id": f"R-{uuid.uuid4().hex[:12]}",
                                    "course_id": course_id,
                                    "respondent_id": respondent_id,
                                    "timestamp": datetime.now(timezone.utc).isoformat(),
                                    "item_id": item_id,
                                    "response_value": answer,
                                    "choice_value": None,
                                    "comment_text": None,
                                    "response_value_num": None,
                                    "source_row_index": None,
                                    "ingest_batch_id": batch_id,
                                }
                                save_response_v2(spreadsheet, response_data)

                                # Add small delay to avoid quota limits
                                if idx > 0 and idx % 5 == 0:
                                    time.sleep(0.5)
                    else:
                        # ë ˆê±°ì‹œ ìŠ¤í‚¤ë§ˆ
                        respondent_hash = generate_respondent_hash()
                        session_id = st.session_state["session_id"]
                        ip_masked = mask_ip_address("unknown")

                        with st.spinner("ì„¤ë¬¸ì„ ì œì¶œí•˜ëŠ” ì¤‘..."):
                            for idx, (q_id, answer) in enumerate(
                                responses.items()):
                                save_response(
                                    spreadsheet, course_id, q_id, answer,
                                    respondent_hash, session_id, ip_masked
                                )
                                if idx > 0 and idx % 5 == 0:
                                    time.sleep(0.5)

                        # Update stats
                        update_response_stats(spreadsheet, course_id)

                    st.success("âœ… ì„¤ë¬¸ì´ ì„±ê³µì ìœ¼ë¡œ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤! ì†Œì¤‘í•œ ì˜ê²¬ ê°ì‚¬í•©ë‹ˆë‹¤.")
                    st.balloons()

                    # Clear form
                    for q_id in responses.keys():
                        if f"q_{q_id}" in st.session_state:
                            del st.session_state[f"q_{q_id}"]

                    # Clear cache
                    st.cache_data.clear()

                except Exception as e:
                    st.error(f"âŒ ì„¤ë¬¸ ì œì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.exception(e)


def page_survey_participation(spreadsheet):
    """Page for survey participation (v2 ìŠ¤í‚¤ë§ˆ í˜¸í™˜)"""
    st.subheader("ì„¤ë¬¸ ì°¸ì—¬")

    # â›³ï¸ ë¡œì»¬ì—ì„œë§Œ ì“°ëŠ” ì´ë¦„ìœ¼ë¡œ ì´ˆê¸°í™” (courses ê¸ˆì§€)
    course_rows = []  # â† ìµœìƒë‹¨ì—ì„œ ì´ˆê¸°í™”(ëª¨ë“  ê²½ë¡œì—ì„œ ì¡´ì¬)
    use_v2 = False
    
    # v2 ìŠ¤í‚¤ë§ˆ ì‹œë„
    try:
        courses_v2 = list_courses_v2(spreadsheet)
        use_v2 = bool(courses_v2)
    except Exception:
        use_v2 = False
        courses_v2 = []

    active_courses = []

    if use_v2:
        # v2 ìŠ¤í‚¤ë§ˆ: statusê°€ 'active'ì¸ ê³¼ì •
        for course in courses_v2:
            if str(course.get('status', '')).strip().lower() == 'active':
                active_courses.append(course)
    else:
        # ë ˆê±°ì‹œ ìŠ¤í‚¤ë§ˆ - course_rowsë¡œ ë°›ê¸° (courses ê¸ˆì§€!)
        course_rows = get_all_courses_cached(spreadsheet)
        for course in course_rows:
            settings = get_survey_settings(
                spreadsheet, str(course.get('courseId')))
            if str(settings.get('isActive', 'FALSE')).upper() == 'TRUE':
                active_courses.append(course)

    if not active_courses:
        st.info("ğŸ“ í˜„ì¬ ì°¸ì—¬ ê°€ëŠ¥í•œ ì„¤ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.caption("ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ê±°ë‚˜ ë‚˜ì¤‘ì— ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    # Course selection (don't auto-select; wait for explicit user choice)
    if use_v2:
        course_options = {
            f"{c.get('program_name', '')} - {c.get('theme', '')} (ID: {c.get('course_id')})":
            c.get('course_id')
            for c in active_courses
        }
    else:
        course_options = {
            f"{c.get('title', '')} (ID: {c.get('courseId')})":
            c.get('courseId')
            for c in active_courses
        }

    select_placeholder = "-- ì„¤ë¬¸ì„ ì„ íƒí•˜ì„¸ìš” --"
    select_options = [select_placeholder] + list(course_options.keys())
    selected_course_name = st.selectbox(
        "ì°¸ì—¬í•  ì„¤ë¬¸ì„ ì„ íƒí•˜ì„¸ìš”:", select_options, index=0)

    if selected_course_name and selected_course_name != select_placeholder:
        selected_course_id = course_options[selected_course_name]
        st.divider()
        render_survey_form(spreadsheet, selected_course_id)


def configure_gemini():
    """Configure Gemini AI client"""
    try:
        from google import genai
        api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
        if not api_key and hasattr(
    st, "secrets") and "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
        if not api_key:
            return None
        os.environ["GOOGLE_API_KEY"] = api_key
        return genai.Client()
    except Exception as e:
        st.warning(f"Gemini AI ì„¤ì • ì‹¤íŒ¨: {str(e)}")
        return None


def analyze_rating_data(
    spreadsheet,
    course_id: str,
    question: Dict,
    all_responses: List[Dict] = None) -> Dict:
    """Analyze rating-type question responses (v2 í˜¸í™˜ ë¡œì§)"""
    # âš ï¸ ë ˆê±°ì‹œ get_responses_by_question í˜¸ì¶œì€ ìƒëµ (all_responses ì‚¬ìš© ê¶Œì¥)

    # v2 ìŠ¤í‚¤ë§ˆì—ì„œ item_idë¥¼ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ë ˆê±°ì‹œ questionIdë¥¼ ì‚¬ìš©
    q_id = str(question.get('item_id') or question.get('questionId'))
    
    if all_responses is None:
        return {"no_data": True, "error": "All responses not provided."}

    # ìºì‹œëœ ì‘ë‹µì—ì„œ í•´ë‹¹ ë¬¸í•­ë§Œ í•„í„°ë§ (v2ëŠ” item_id ì‚¬ìš©)
    responses = [r for r in all_responses if str(r.get("item_id") or r.get("questionId")) == q_id]

    if not responses:
        return {"no_data": True}

    # Count ratings (safely convert to int)
    rating_counts = Counter()
    valid_ratings = []
    for r in responses:
        try:
            # v2 ìŠ¤í‚¤ë§ˆëŠ” response_value_num ì‚¬ìš© (ìˆ«ì ì‘ë‹µ)
            answer_v2_key = r.get("response_value_num")
            
            # v2 í‚¤ë¥¼ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ë ˆê±°ì‹œ answer í‚¤ë¥¼ í´ë°±
            answer = answer_v2_key if answer_v2_key is not None else r.get("answer", "")
            
            if answer is not None and str(answer).strip():
                rating = int(float(str(answer).strip())) # ì•ˆì „í•˜ê²Œ float ë³€í™˜ í›„ int
                rating_counts[rating] += 1
                valid_ratings.append(rating)
        except (ValueError, TypeError):
            # ìˆ«ìë¡œ ë³€í™˜í•  ìˆ˜ ì—†ëŠ” ì‘ë‹µì€ ë¬´ì‹œ
            pass

    average = sum(valid_ratings) / len(valid_ratings) if valid_ratings else 0

    return {
        "no_data": False,
        "counts": dict(rating_counts),
        "total": len(valid_ratings), # ì‘ë‹µ ìˆ˜: ìœ íš¨í•œ ratingë§Œ ì¹´ìš´íŠ¸
        "average": average
    }


def analyze_objective_data(
    spreadsheet,
    course_id: str,
    question: Dict,
    all_responses: List[Dict] = None) -> Dict:
    """Analyze objective-type question responses (v2 í˜¸í™˜ ë¡œì§)"""
    # âš ï¸ ë ˆê±°ì‹œ get_responses_by_question í˜¸ì¶œì€ ìƒëµ

    # v2 ìŠ¤í‚¤ë§ˆì—ì„œ item_idë¥¼ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ë ˆê±°ì‹œ questionIdë¥¼ ì‚¬ìš©
    q_id = str(question.get('item_id') or question.get('questionId'))

    if all_responses is None:
        return {"no_data": True, "error": "All responses not provided."}

    # ìºì‹œëœ ì‘ë‹µì—ì„œ í•´ë‹¹ ë¬¸í•­ë§Œ í•„í„°ë§
    responses = [r for r in all_responses if str(r.get("item_id") or r.get("questionId")) == q_id]

    if not responses:
        return {"no_data": True}

    # Count choices (convert to string first)
    choice_counts = Counter()
    for r in responses:
        # v2 ìŠ¤í‚¤ë§ˆëŠ” response_value ë˜ëŠ” choice_value ì‚¬ìš© (ì„ íƒì§€ í…ìŠ¤íŠ¸)
        answer_v2_key = r.get("response_value") or r.get("choice_value")
        
        # v2 í‚¤ë¥¼ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ë ˆê±°ì‹œ answer í‚¤ë¥¼ í´ë°±
        answer = answer_v2_key if answer_v2_key is not None else r.get("answer", "")
        
        if answer is not None:
            answer_str = str(answer).strip()
            if answer_str:
                # multi_choiceì¸ ê²½ìš° ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ì—¬ ê° ì„ íƒì§€ë¥¼ ì¹´ìš´íŠ¸í•  ìˆ˜ ìˆì§€ë§Œ, 
                # ì—¬ê¸°ì„œëŠ” ë‹¨ì¼ ë¬¸ìì—´ë¡œ ì¹´ìš´íŠ¸í•˜ëŠ” ë ˆê±°ì‹œ ë°©ì‹ì„ ìœ ì§€í•©ë‹ˆë‹¤.
                choice_counts[answer_str] += 1

    return {
        "no_data": False,
        "counts": dict(choice_counts),
        "total": len(responses)
    }


def analyze_subjective_data(
    spreadsheet,
    course_id: str,
    question: Dict,
    all_responses: List[Dict] = None) -> Dict:
    """Analyze subjective-type question responses (v2 í˜¸í™˜ ë¡œì§)"""
    # âš ï¸ ë ˆê±°ì‹œ get_responses_by_question í˜¸ì¶œì€ ìƒëµ
    
    # v2 ìŠ¤í‚¤ë§ˆì—ì„œ item_idë¥¼ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ë ˆê±°ì‹œ questionIdë¥¼ ì‚¬ìš©
    q_id = str(question.get('item_id') or question.get('questionId'))

    if all_responses is None:
        return {"no_data": True, "error": "All responses not provided."}

    # ìºì‹œëœ ì‘ë‹µì—ì„œ í•´ë‹¹ ë¬¸í•­ë§Œ í•„í„°ë§
    responses = [r for r in all_responses if str(r.get("item_id") or r.get("questionId")) == q_id]

    if not responses:
        return {"no_data": True}

    # Collect text responses (convert to string first)
    texts = []
    for r in responses:
        # v2 ìŠ¤í‚¤ë§ˆëŠ” response_value ë˜ëŠ” comment_text ì‚¬ìš© (ì£¼ê´€ì‹ í…ìŠ¤íŠ¸)
        answer_v2_key = r.get("response_value") or r.get("comment_text")
        
        # v2 í‚¤ë¥¼ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ë ˆê±°ì‹œ answer í‚¤ë¥¼ í´ë°±
        answer = answer_v2_key if answer_v2_key is not None else r.get("answer", "")
        
        if answer is not None:
            answer_str = str(answer).strip()
            if answer_str:
                texts.append(answer_str)

    return {
        "no_data": False,
        "responses": texts,
        "total": len(texts)
    }


def generate_wordcloud(texts: List[str]) -> plt.Figure:
    """Generate wordcloud from text list"""
    if not texts:
        return None

    combined_text = " ".join(texts)

    # Create wordcloud
    wc = WordCloud(
        width=800,
        height=400,
        background_color='white',
        font_path=None,  # Use default font for Korean
        colormap='RdYlBu_r',
        relative_scaling=0.5,
        min_font_size=10
    ).generate(combined_text)

    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wc, interpolation='bilinear')
    ax.axis('off')
    return fig


def generate_ai_insights(
    spreadsheet,
    course_id: str,
    questions: List[Dict],
    all_analysis: Dict) -> str:
    """Generate AI insights using Gemini (v2 í˜¸í™˜ ë¡œì§)"""
    client = configure_gemini()
    if not client:
        return "Gemini AIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."

    try:
        # Prepare summary for Gemini
        summary = f"êµìœ¡ ê³¼ì • ì„¤ë¬¸ ë¶„ì„:\n\n"

        for q in questions:
            # v2 í•„ë“œë¥¼ ìš°ì„ í•˜ê³  ì—†ìœ¼ë©´ ë ˆê±°ì‹œ í•„ë“œ í´ë°±
            q_id = str(q.get('item_id') or q.get('questionId'))
            q_type = (q.get('metric_type') or q.get('type') or 'unknown').lower()
            q_text = q.get('item_text') or q.get('text') or '(ì œëª©ì—†ìŒ)'

            summary += f"ë¬¸í•­: {q_text}\n"
            summary += f"ìœ í˜•: {q_type}\n"

            # í†µí•© ë¶„ë¥˜: v2ì™€ ë ˆê±°ì‹œ íƒ€ì…ì„ ëª¨ë‘ ì§€ì›
            # likert, nps, rating â†’ rating ì¹´í…Œê³ ë¦¬
            if q_type in ['likert', 'nps', 'rating'] and q_id in all_analysis.get('rating', {}):
                data = all_analysis['rating'][q_id]
                if not data.get('no_data'):
                    summary += f"í‰ê·  ì ìˆ˜: {data.get('average', 0):.2f}\n"
                    summary += f"ì‘ë‹µ ìˆ˜: {data.get('total', 0)}\n"
                    summary += f"ì ìˆ˜ ë¶„í¬: {data.get('counts', {})}\n"

            # single_choice, multi_choice, objective â†’ objective ì¹´í…Œê³ ë¦¬
            elif q_type in ['single_choice', 'multi_choice', 'objective'] and q_id in all_analysis.get('objective', {}):
                data = all_analysis['objective'][q_id]
                if not data.get('no_data'):
                    summary += f"ì„ íƒ ë¶„í¬: {data.get('counts', {})}\n"
                    summary += f"ì‘ë‹µ ìˆ˜: {data.get('total', 0)}\n"

            # text, subjective â†’ subjective ì¹´í…Œê³ ë¦¬
            elif q_type in ['text', 'subjective'] and q_id in all_analysis.get('subjective', {}):
                data = all_analysis['subjective'][q_id]
                if not data.get('no_data'):
                    summary += f"ì£¼ê´€ì‹ ì‘ë‹µ ìˆ˜: {data.get('total', 0)}\n"
                    sample = data.get('responses', [])[:3]
                    if sample:
                        summary += f"ìƒ˜í”Œ ì‘ë‹µ: {', '.join(sample[:2])}\n"

            summary += "\n"

        prompt = f"""
{summary}

ìœ„ êµìœ¡ ì„¤ë¬¸ ê²°ê³¼ëŠ” SK ì„ì§ì›ì„ ëŒ€ìƒìœ¼ë¡œ í•œ êµìœ¡ í”„ë¡œê·¸ë¨ íš¨ê³¼ ì¸¡ì • ë° ë§Œì¡±ë„ ì¡°ì‚¬ ê²°ê³¼ì…ë‹ˆë‹¤.
ë¶„ì„ì˜ ëª©ì ì€ êµìœ¡ í”„ë¡œê·¸ë¨ì˜ ì„±ê³¼ë¥¼ í‰ê°€í•˜ê³ , **ë‹¤ìŒ ê³¼ì • ê°œì„  ì‚¬í•­**ì„ êµ¬ì²´ì ìœ¼ë¡œ ë„ì¶œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì´ êµìœ¡ ì„¤ë¬¸ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì˜ í•­ëª©ë“¤ì„ **ë‹´ë‹¹ì ê´€ì **ì—ì„œ ëª…í™•í•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”:

1. **êµìœ¡ í”„ë¡œê·¸ë¨ íš¨ê³¼ ìš”ì•½ (KPI)**: ì „ë°˜ì ì¸ ë§Œì¡±ë„ ë° ì´í•´ë„(likert/rating ë¬¸í•­)ì˜ ì£¼ìš” ê²°ê³¼ ìš”ì•½ ë° ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€ íŒë‹¨.
2. **ì£¼ìš” ê°œì„  í•„ìš” ì˜ì—­ (Deficiency Analysis)**: í‰ê·  ì ìˆ˜ê°€ ë‚®ê±°ë‚˜ ë¶€ì •ì ì¸ ì˜ê²¬(ì£¼ê´€ì‹)ì´ ì§‘ì¤‘ëœ **ìµœëŒ€ 2~3ê°œì˜ ì˜ì—­(ì½˜í…ì¸ , ìš´ì˜, ê°•ì‚¬ ë“±)**ì„ êµ¬ì²´ì ì¸ ê·¼ê±°ì™€ í•¨ê»˜ ì œì‹œ.
3. **ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ì œì•ˆ (Action Items)**: ë‹¤ìŒ íšŒì°¨ êµìœ¡ì„ ìœ„í•´ **ë‹´ë‹¹ìê°€ ì¦‰ì‹œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ 3ê°€ì§€ ì´ìƒ**ì„ ì‘ì„±.

í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """

        response = client.models.generate_content(
            model="gemini-2.0-flash-exp",
            contents=prompt
        )

        return response.text

    except Exception as e:
        return f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


@st.cache_data(ttl=120)  # Cache for 2 minutes
def get_all_responses_cached(_spreadsheet, course_id: str):
    """
    [í•µì‹¬ ìˆ˜ì •] ì‘ë‹µ ì‹œíŠ¸ ì´ë¦„ì„ ìœ ì—°í•˜ê²Œ ì°¾ì•„ v2 ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , ë””ë²„ê¹… ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    target_sheet_name = None
    
    try:
        # 1. ì‹œíŠ¸ ê²€ìƒ‰ (ìœ ì—°í•˜ê²Œ)
        worksheets = _spreadsheet.worksheets()
        for ws in worksheets:
            if "responses" in ws.title.lower() or "response" in ws.title.lower():
                target_sheet_name = ws.title
                break
        
        if not target_sheet_name:
            st.warning("ğŸ” Responses ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œíŠ¸ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”.")
            return []

        # 2. ë°ì´í„° ë¡œë“œ (API í˜¸ì¶œ ì§€ì )
        ws = _spreadsheet.worksheet(target_sheet_name)
        all_responses = ws.get_all_records()  # <-- í—¤ë”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ dict ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
        
        # 3. course_idë¡œ í•„í„°ë§
        filtered_responses = [
            r for r in all_responses 
            if str(r.get("course_id") or r.get("courseId")) == str(course_id)
        ]
        
        # 4. ğŸ”‘ ìµœì¢… ë””ë²„ê·¸ ë¡œì§ ì¶”ê°€: ë¡œë”© ìƒíƒœë¥¼ ëª…í™•íˆ í‘œì‹œ
        st.caption(f"**ğŸ” ë¡œë”© ë””ë²„ê·¸ (ì‹œíŠ¸: {target_sheet_name})**")
        st.write(f"- ì „ì²´ ì‘ë‹µ ë ˆì½”ë“œ ìˆ˜: {len(all_responses)}")
        st.write(f"- í•„í„°ë§ course_id: **{course_id}**")
        st.write(f"- ìµœì¢… í•„í„°ë§ í›„ ì‘ë‹µ ìˆ˜: **{len(filtered_responses)}**ê°œ")
        
        if len(all_responses) > 0 and len(filtered_responses) == 0:
            st.error("ğŸš¨ í•„í„°ë§ ì‹¤íŒ¨! ì‹œíŠ¸ì— course_idê°€ ë¶ˆì¼ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            # ì‹¤ì œ ì‹œíŠ¸ì— ì¡´ì¬í•˜ëŠ” course_idë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
            sheet_course_ids = set(str(r.get('course_id') or r.get('courseId')) for r in all_responses if r.get('course_id') or r.get('courseId'))
            st.code(f"ì‹œíŠ¸ ë‚´ course_id ëª©ë¡: {sheet_course_ids}")
        
        return filtered_responses
    
    except Exception as e:
        # API ì˜¤ë¥˜ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì˜ˆì™¸ ì²˜ë¦¬
        st.error(f"v2 ì‘ë‹µ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return []


@st.cache_data(ttl=120)  # Cache for 2 minutes
def get_all_questions_cached(_spreadsheet, course_id: str):
    """
    [ìµœì¢… ìˆ˜ì •] Questions ì‹œíŠ¸ ì´ë¦„ì„ ìœ ì—°í•˜ê²Œ ì°¾ì•„ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    target_sheet_name = None
    
    try:
        worksheets = _spreadsheet.worksheets()
        # 'questions' ë˜ëŠ” 'question' í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì‹œíŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        for ws in worksheets:
            if "questions" in ws.title.lower() or "question" in ws.title.lower():
                target_sheet_name = ws.title
                break
        
        if not target_sheet_name:
            raise ValueError("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ 'Questions' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        ws = _spreadsheet.worksheet(target_sheet_name)
        records = ws.get_all_records()
        filtered = [
            r for r in records if str(
                r.get("courseId")) == str(course_id)]
        # sort by order numeric if present
        try:
            filtered.sort(key=lambda r: int(str(r.get("order", "0") or 0)))
        except Exception:
            pass
        return filtered
    except Exception as e:
        st.error(f"ë¬¸í•­ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        if target_sheet_name:
            st.info(f"ğŸ’¡ ë§ˆì§€ë§‰ìœ¼ë¡œ ì‹œë„í•œ ì‹œíŠ¸ ì´ë¦„: {target_sheet_name}")
        else:
            st.info("ğŸ’¡ 'Questions' í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ì‹œíŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return []


@st.cache_data(ttl=180)  # Cache for 3 minutes
def get_all_courses_cached(_spreadsheet):
    """
    [ìµœì¢… ìˆ˜ì •] Courses ì‹œíŠ¸ ì´ë¦„ì„ ìœ ì—°í•˜ê²Œ ì°¾ì•„ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    target_sheet_name = None
    
    try:
        worksheets = _spreadsheet.worksheets()
        # 'courses' ë˜ëŠ” 'course' í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì‹œíŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        for ws in worksheets:
            if "courses" in ws.title.lower() or "course" in ws.title.lower():
                target_sheet_name = ws.title
                break
        
        if not target_sheet_name:
            raise ValueError("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ 'Courses' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        ws = _spreadsheet.worksheet(target_sheet_name)
        return ws.get_all_records()
    except Exception as e:
        st.error(f"ê³¼ì • ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        if target_sheet_name:
            st.info(f"ğŸ’¡ ë§ˆì§€ë§‰ìœ¼ë¡œ ì‹œë„í•œ ì‹œíŠ¸ ì´ë¦„: {target_sheet_name}")
        else:
            st.info("ğŸ’¡ 'Courses' í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ì‹œíŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return []


@st.cache_data(ttl=120)  # Cache for 2 minutes
def get_course_items_cached(_spreadsheet, course_id: str):
    """
    [API ì¿¼í„° í•´ê²°] gsheets_utils.get_course_items í˜¸ì¶œì„ ìºì‹œí•˜ì—¬ 
    API Read ìš”ì²­ì„ ì¤„ì´ê³  ì¿¼í„° ì´ˆê³¼ ì—ëŸ¬ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    try:
        # gsheets_utilsì˜ get_course_items í•¨ìˆ˜ í˜¸ì¶œ (ì´ í•¨ìˆ˜ëŠ” APIë¥¼ ì‚¬ìš©í•¨)
        return get_course_items(_spreadsheet, course_id)
    except Exception as e:
        # ë¬¸í•­ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë ˆê±°ì‹œ í•¨ìˆ˜ë¡œ í´ë°±í•˜ì—¬ ì•ˆì •ì„± í™•ë³´
        st.warning(f"get_course_items ì‹¤íŒ¨. ë ˆê±°ì‹œ list_questionsìœ¼ë¡œ í´ë°±: {str(e)}")
        return list_questions(_spreadsheet, course_id)


def page_dashboard(spreadsheet, course_id: str):
    """Dashboard page for analyzing survey results (v2 ìŠ¤í‚¤ë§ˆ í˜¸í™˜)"""

    # ì•ˆì „ ì¡°ì¹˜: ëª¨ë“  ê²½ë¡œì—ì„œ all_course_responses ë³€ìˆ˜ê°€ ì¡´ì¬í•˜ë„ë¡ ë³´ì¥
    all_course_responses = []

    # v2 ìŠ¤í‚¤ë§ˆ ì‹œë„
    try:
        course_v2 = get_course_by_id_v2(spreadsheet, course_id)
        if course_v2:
            use_v2 = True
        else:
            # ë ˆê±°ì‹œë¡œ fallback
            course = get_course_by_id(spreadsheet, course_id)
            use_v2 = False
    except Exception as e:
        st.error(f"âŒ ì‹œíŠ¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        st.info("ğŸ’¡ DB ì„¤ì • íƒ­ì—ì„œ ìŠ¤í‚¤ë§ˆë¥¼ í™•ì¸í•˜ê³  v2 ì´ˆê¸°í™”ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    # ê³¼ì • ì •ë³´ í™•ì¸
    if use_v2:
        if not course_v2:
            st.error(f"âŒ ê³¼ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {course_id}")
            st.info("ğŸ’¡ 'ê³¼ì • ë¦¬ìŠ¤íŠ¸' íƒ­ì—ì„œ course_idë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return
        course_title = f"{
    course_v2.get(
        'program_name',
        '')} - {
            course_v2.get(
                'theme',
                 '')}"
        course_desc = f"{
    course_v2.get(
        'event_type',
        '')} | {
            course_v2.get(
                'session_no',
                 '')}íšŒì°¨"
    else:
        if not course:
            st.error(f"âŒ ê³¼ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {course_id}")
        return
        course_title = course.get('title', '')
        course_desc = course.get('description', '')

    st.markdown(
        f"""
        <div class="sk-page-header">
          <div class="title">ë¯¸ë˜ë°˜ë„ì²´ êµìœ¡ ê³¼ì • Dashboard</div>
          <div class="subtitle">{course_title} Â· {course_desc}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

    # ë¬¸í•­ ì¡°íšŒ (v2 ìŠ¤í‚¤ë§ˆ ìš°ì„ )
    try:
        # âš ï¸ get_course_items ëŒ€ì‹  ìºì‹œëœ í—¬í¼ í•¨ìˆ˜ í˜¸ì¶œ
        questions = get_course_items_cached(spreadsheet, course_id)
        
        if not questions:
            st.info("ğŸ“ ì„¤ë¬¸ ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. 'ì„¤ë¬¸ í¸ì§‘'ì—ì„œ ë¬¸í•­ì„ ì¶”ê°€í•˜ì„¸ìš”.")
            return
        
        # use_v2 í”Œë˜ê·¸ ì„¤ì • (questionsì— item_id í•„ë“œê°€ ìˆìœ¼ë©´ v2ë¡œ ê°„ì£¼)
        use_v2 = any(q.get('item_id') for q in questions)
        
    except Exception as e:
        st.error(f"âŒ ë¬¸í•­ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        return
    
    # ì‘ë‹µ ì¡°íšŒ (v2 ìŠ¤í‚¤ë§ˆ ìš°ì„ )
    # âš ï¸ ì£¼ì˜: get_responses_v2ê°€ Responses_v2 ì‹œíŠ¸ê°€ ì—†ì–´ ì‹¤íŒ¨í•˜ëŠ” ë¬¸ì œë¥¼ ìš°íšŒí•©ë‹ˆë‹¤.
    try:
        # 1. ì‘ë‹µ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤ (ì‹œíŠ¸ ì´ë¦„ ë¬¸ì œ ìš°íšŒ ë¡œì§ í¬í•¨)
        all_course_responses = get_all_responses_cached(spreadsheet, course_id)
        
        # 2. ë¡œë“œëœ ë°ì´í„°ë¥¼ ë¶„ì„ì— ì‚¬ìš©í•  responses ë³€ìˆ˜ì— í• ë‹¹í•©ë‹ˆë‹¤.
        responses = all_course_responses
        
        # 3. ë¡œë“œëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ use_v2 í”Œë˜ê·¸ë¥¼ ì¬ì„¤ì •í•©ë‹ˆë‹¤.
        #    (Course ì •ë³´ ì¡°íšŒ ì„±ê³µ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ì‘ë‹µ ë°ì´í„°ì˜ ì¡´ì¬ ì—¬ë¶€ë¥¼ ìš°ì„  í™•ì¸)
        if not all_course_responses:
            st.warning("âš ï¸ ì•„ì§ ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ 'ì¼ë°˜ ì‚¬ìš©ì ëª¨ë“œ'ì—ì„œ ì„¤ë¬¸ì— ì‘ë‹µí•˜ê±°ë‚˜, 'íŒŒì¼ ì—…ë¡œë“œ' íƒ­ì—ì„œ ì‘ë‹µ ë°ì´í„°ë¥¼ ì ì¬í•˜ì„¸ìš”.")
            return

    except Exception as e:
        st.error(f"âŒ ì‘ë‹µ ë°ì´í„° ë¡œë”© ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return

    # use_v2 í”Œë˜ê·¸ëŠ” course_v2 ì¡°íšŒ ì‹œ ê²°ì •ëœ ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤ (ë¡œë”© ë¡œì§ê³¼ ë¶„ë¦¬)
    # all_course_responses ë³€ìˆ˜ëŠ” ì´ì œ ë¶„ì„ í•¨ìˆ˜ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    
    # KPI Summary - SVG ì•„ì´ì½˜ ì‚¬ìš©
    st.markdown('''
        <h3>
            <svg class="icon-svg icon-chip" viewBox="0 0 24 24">
                <rect x="3" y="3" width="18" height="18" rx="2"/>
                <line x1="7" y1="3" x2="7" y2="0"/>
                <line x1="12" y1="3" x2="12" y2="0"/>
                <line x1="17" y1="3" x2="17" y2="0"/>
                <line x1="7" y1="24" x2="7" y2="21"/>
                <line x1="12" y1="24" x2="12" y2="21"/>
                <line x1="17" y1="24" x2="17" y2="21"/>
                <line x1="0" y1="7" x2="3" y2="7"/>
                <line x1="0" y1="17" x2="3" y2="17"/>
                <line x1="21" y1="7" x2="24" y2="7"/>
                <line x1="21" y1="17" x2="24" y2="17"/>
                <circle cx="12" cy="12" r="3"/>
            </svg>
            ì£¼ìš” ì§€í‘œ
        </h3>
    ''', unsafe_allow_html=True)
    col1, col2, col3 = st.columns(3)
    
    try:
        # ì•ˆì „í•˜ê²Œ respondentHash ì¶”ì¶œ (v2ì™€ ë ˆê±°ì‹œ í˜¸í™˜)
        respondent_hashes = set()
        for r in responses:
            hash_val = r.get('respondentHash') or r.get('respondent_id')
            if hash_val:
                respondent_hashes.add(str(hash_val))
        
        unique_respondents = len(respondent_hashes)
        total_questions = len(questions)
        
        # ğŸ“ˆ í•µì‹¬ KPI: í‰ì í˜• ë¬¸í•­ì˜ ì „ì²´ í‰ê·  ê³„ì‚°
        rating_qs = [q for q in questions if (q.get('metric_type') or q.get('type') or '').lower() in ['rating', 'likert', 'nps']]
        overall_satisfaction = 0.0
        if rating_qs:
            total_avg = 0.0
            valid_count = 0
            for q in rating_qs:
                data = analyze_rating_data(spreadsheet, course_id, q, all_course_responses)
                if not data.get('no_data') and data.get('average', 0) > 0:
                    total_avg += data.get('average', 0)
                    valid_count += 1
            if valid_count > 0:
                overall_satisfaction = total_avg / valid_count
        
        with col1:
            st.metric("ì´ ì‘ë‹µì ìˆ˜", unique_respondents)
        with col2:
            st.metric("ì´ ë¬¸í•­ ìˆ˜", total_questions)
        with col3:
            # ğŸ’¡ êµìœ¡ ë‹´ë‹¹ìë¥¼ ìœ„í•œ í•µì‹¬ KPI
            if overall_satisfaction > 0:
                st.metric("í‰ê·  ë§Œì¡±ë„", f"{overall_satisfaction:.2f}ì ", 
                         delta="ìš°ìˆ˜" if overall_satisfaction >= 4.0 else "ê°œì„  í•„ìš”")
            else:
                st.metric("í‰ê·  ë§Œì¡±ë„", "N/A")
    except Exception as e:
        st.warning("âš ï¸ ì£¼ìš” ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        with st.expander("ğŸ” ìƒì„¸ ì •ë³´"):
            st.code(str(e))
    
    st.divider()
    
    # Tabs for different analyses
    tab1, tab2, tab3, tab4 = st.tabs([
        "ê°ê´€ì‹", 
        "í‰ì ", 
        "ì£¼ê´€ì‹", 
        "AI ì¸ì‚¬ì´íŠ¸"
    ])
    
    all_analysis = {
        'objective': {},
        'rating': {},
        'subjective': {}
    }
    
    # ğŸ’¡ í—¬í¼ í•¨ìˆ˜: v2ì˜ metric_typeì„ ìš°ì„ í•˜ê³  ì—†ìœ¼ë©´ ë ˆê±°ì‹œ typeì„ ë°˜í™˜
    def get_q_type(q):
        """v2ì˜ metric_typeì„ ìš°ì„ í•˜ê³  ì—†ìœ¼ë©´ ë ˆê±°ì‹œ typeì„ ë°˜í™˜"""
        return (q.get('metric_type') or q.get('type') or 'unknown').lower()
    
    def get_q_text(q):
        """v2ì˜ item_textë¥¼ ìš°ì„ í•˜ê³  ì—†ìœ¼ë©´ ë ˆê±°ì‹œ textë¥¼ ë°˜í™˜"""
        return q.get('item_text') or q.get('text') or '(ì œëª©ì—†ìŒ)'
    
    def get_q_id(q):
        """v2ì˜ item_idë¥¼ ìš°ì„ í•˜ê³  ì—†ìœ¼ë©´ ë ˆê±°ì‹œ questionIdë¥¼ ë°˜í™˜"""
        return str(q.get('item_id') or q.get('questionId'))
    
    def deduplicate_questions(question_list: List[Dict]) -> List[Dict]:
        seen_ids = set()
        unique_list = []
        for q in question_list:
            q_id = get_q_id(q)
            if q_id in seen_ids:
                continue
            seen_ids.add(q_id)
            unique_list.append(q)
        return unique_list

    # ì‘ë‹µì„ item_id ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”
    responses_by_item = defaultdict(list)
    for resp in all_course_responses:
        resp_key = str(resp.get("item_id") or resp.get("questionId"))
        if resp_key:
            responses_by_item[resp_key].append(resp)

    unique_question_ids = {get_q_id(q) for q in questions if get_q_id(q)}

    with st.expander("ë°ì´í„° ìƒíƒœ ìš”ì•½", expanded=False):
        st.write("- ì´ ë¬¸í•­ ìˆ˜ (Course_Item_Map):", len(questions))
        st.write("- ê³ ìœ  ë¬¸í•­ ìˆ˜:", len(unique_question_ids))
        st.write("- ì‘ë‹µ ë ˆì½”ë“œ ìˆ˜:", len(all_course_responses))
        st.write("- ì‘ë‹µì´ ìˆëŠ” ë¬¸í•­ ìˆ˜:", len({k for k, v in responses_by_item.items() if v}))

    with tab1:
        st.markdown('''
            <h3>
                <svg class="icon-svg icon-chart" viewBox="0 0 24 24">
                    <rect x="3" y="8" width="4" height="13"/>
                    <rect x="10" y="4" width="4" height="17"/>
                    <rect x="17" y="11" width="4" height="10"/>
                    <line x1="0" y1="23" x2="24" y2="23"/>
                </svg>
                ê°ê´€ì‹ ë¬¸í•­ ë¶„ì„
            </h3>
        ''', unsafe_allow_html=True)
        
        # v2 metric_typeì„ ìš°ì„  ì‚¬ìš©í•œ í†µí•© ë¶„ë¥˜
        objective_qs = [q for q in questions if get_q_type(q) in ['objective', 'single_choice', 'multi_choice']]
        objective_qs = deduplicate_questions(objective_qs)
        
        # ğŸ’¡ ê²½í’ˆ/ê°œì¸ì •ë³´ ê´€ë ¨ ë¬¸í•­ í•„í„°ë§
        exclude_keywords = ["ê²½í’ˆ", "ê°œì¸ì •ë³´", "ë™ì˜", "ìˆ˜ì§‘", "ì´ìš©", "ì œê³µ", "consent", "privacy", "prize"]
        objective_qs = [q for q in objective_qs 
                       if not any(keyword in get_q_text(q).lower() for keyword in exclude_keywords)]
        
        if not objective_qs:
            st.info("ê°ê´€ì‹ ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for q in objective_qs:
                q_text = get_q_text(q)
                q_id = get_q_id(q)
                related_responses = responses_by_item.get(q_id, [])

                st.markdown(f"#### {q_text}")

                if not related_responses:
                    st.info("ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (0ê±´)")
                    st.divider()
                    continue

                data = analyze_objective_data(spreadsheet, course_id, q, all_course_responses)
                all_analysis['objective'][q_id] = data

                if data.get('no_data'):
                    st.info("ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.caption(f"ì‘ë‹µ ìˆ˜: {len(related_responses)}")
                    df = pd.DataFrame(list(data['counts'].items()), columns=['ì„ íƒì§€', 'ì‘ë‹µ ìˆ˜'])
                    fig = px.bar(df, x='ì„ íƒì§€', y='ì‘ë‹µ ìˆ˜', title=f"ì´ ì‘ë‹µ: {data['total']}")
                    st.plotly_chart(fig, use_container_width=True, key=f"obj_chart_{q_id}")

                st.divider()
    
    with tab2:
        st.markdown('''
            <h3>
                <svg class="icon-svg icon-star" viewBox="0 0 24 24">
                    <polygon points="12,2 15,9 22,10 17,15 18,22 12,18 6,22 7,15 2,10 9,9"/>
                </svg>
                í‰ì í˜• ë¬¸í•­ ë¶„ì„
            </h3>
        ''', unsafe_allow_html=True)
        
        # v2 metric_typeì„ ìš°ì„  ì‚¬ìš©í•œ í†µí•© ë¶„ë¥˜
        rating_qs = [q for q in questions if get_q_type(q) in ['rating', 'likert', 'nps']]
        rating_qs = deduplicate_questions(rating_qs)
        
        if not rating_qs:
            st.info("í‰ì í˜• ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for q in rating_qs:
                q_text = get_q_text(q)
                q_id = get_q_id(q)

                related_responses = responses_by_item.get(q_id, [])

                st.markdown(f"#### {q_text}")

                if not related_responses:
                    st.info("ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (0ê±´)")
                    st.divider()
                    continue

                data = analyze_rating_data(spreadsheet, course_id, q, all_course_responses)
                all_analysis['rating'][q_id] = data
                
                if data.get('no_data'):
                    st.info("ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.caption(f"ì‘ë‹µ ìˆ˜: {len(related_responses)}")
                    col_a, col_b = st.columns([2, 1])
                    
                    with col_a:
                        df = pd.DataFrame(list(data['counts'].items()), columns=['í‰ì ', 'ì‘ë‹µ ìˆ˜'])
                        df['í‰ì '] = df['í‰ì '].astype(str) + 'ì '
                        fig = px.pie(df, names='í‰ì ', values='ì‘ë‹µ ìˆ˜', title=f"í‰ì  ë¶„í¬ (í‰ê· : {data['average']:.2f}ì )")
                        st.plotly_chart(fig, use_container_width=True, key=f"rating_chart_{q_id}")
                    
                    with col_b:
                        st.metric("í‰ê·  í‰ì ", f"{data['average']:.2f}ì ")
                        st.metric("ì´ ì‘ë‹µ ìˆ˜", data['total'])

                st.divider()
    
    with tab3:
        st.markdown('''
            <h3>
                <svg class="icon-svg icon-message" viewBox="0 0 24 24">
                    <path d="M21,3 L3,3 C1.9,3 1,3.9 1,5 L1,17 C1,18.1 1.9,19 3,19 L7,19 L12,23 L17,19 L21,19 C22.1,19 23,18.1 23,17 L23,5 C23,3.9 22.1,3 21,3 Z"/>
                    <line x1="6" y1="9" x2="18" y2="9"/>
                    <line x1="6" y1="13" x2="15" y2="13"/>
                </svg>
                ì£¼ê´€ì‹ ë¬¸í•­ ë¶„ì„
            </h3>
        ''', unsafe_allow_html=True)
        
        # v2 metric_typeì„ ìš°ì„  ì‚¬ìš©í•œ í†µí•© ë¶„ë¥˜
        subjective_qs = [q for q in questions if get_q_type(q) in ['subjective', 'text']]
        subjective_qs = deduplicate_questions(subjective_qs)
        
        if not subjective_qs:
            st.info("ì£¼ê´€ì‹ ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for q in subjective_qs:
                q_text = get_q_text(q)
                q_id = get_q_id(q)
                related_responses = responses_by_item.get(q_id, [])
                
                st.markdown(f"#### {q_text}")
                if not related_responses:
                    st.info("ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (0ê±´)")
                    st.divider()
                    continue

                data = analyze_subjective_data(spreadsheet, course_id, q, all_course_responses)
                all_analysis['subjective'][q_id] = data
                
                if data.get('no_data'):
                    st.info("ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    texts = data['responses']
                    st.caption(f"ì‘ë‹µ ìˆ˜: {len(texts)}")
                    
                    if len(texts) >= 5:
                        # Wordcloud
                        st.markdown("##### ì›Œë“œ í´ë¼ìš°ë“œ")
                        fig = generate_wordcloud(texts)
                        if fig:
                            st.pyplot(fig)
                    
                    # Show responses
                    st.markdown(f"##### ì „ì²´ ì‘ë‹µ ({len(texts)}ê°œ)")
                    with st.expander("ì‘ë‹µ ë³´ê¸°"):
                        for idx, text in enumerate(texts, 1):
                            st.markdown(f"{idx}. {text}")
                
                st.divider()
    
    with tab4:
        st.markdown('''
            <h3>
                <svg class="icon-svg icon-brain" viewBox="0 0 24 24">
                    <path d="M12,2 C8,2 5,5 5,9 L5,15 C5,19 8,22 12,22 C16,22 19,19 19,15 L19,9 C19,5 16,2 12,2 Z"/>
                    <circle cx="9" cy="10" r="1.5"/>
                    <circle cx="15" cy="10" r="1.5"/>
                    <path d="M9,14 Q12,16 15,14"/>
                    <path d="M7,9 L7,6 M17,9 L17,6 M12,2 L12,5"/>
                </svg>
                AI ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
            </h3>
        ''', unsafe_allow_html=True)
        
        if st.button("AI ë¶„ì„ ì‹¤í–‰", type="primary"):
            with st.spinner("Gemini AIë¡œ ë¶„ì„ ì¤‘..."):
                # v2ì™€ ë ˆê±°ì‹œ í†µí•© í˜¸í™˜
                insights = generate_ai_insights(spreadsheet, course_id, questions, all_analysis)
                
                st.markdown("#### ë¶„ì„ ê²°ê³¼")
                st.markdown(insights)
                
                # Save to Analysis sheet (v2ëŠ” Insights ì‹œíŠ¸ ì‚¬ìš© ê°€ëŠ¥)
                if use_v2:
                    # v2 ìŠ¤í‚¤ë§ˆ: Insights ì‹œíŠ¸ì— ì €ì¥
                    try:
                        insight_data = {
                            "insight_id": f"INS-{int(datetime.now(timezone.utc).timestamp())}",
                            "course_id": course_id,
                            "insight_type": "ai_generated",
                            "insight_text": insights,
                            "dimension": "overall",
                            "sentiment_score": None,
                            "created_at": datetime.now(timezone.utc).isoformat(),
                            "metadata": json.dumps({
                                "objective": all_analysis['objective'],
                                "rating": all_analysis['rating'],
                                "subjective_count": {k: v.get('total', 0) for k, v in all_analysis['subjective'].items()}
                            }, ensure_ascii=False)
                        }
                        save_insight(spreadsheet, insight_data)
                        st.success("âœ… ë¶„ì„ ê²°ê³¼ê°€ Insights ì‹œíŠ¸ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.warning(f"âš ï¸ Insights ì €ì¥ ì‹¤íŒ¨: {str(e)}")
                else:
                    # ë ˆê±°ì‹œ ìŠ¤í‚¤ë§ˆ: Analysis ì‹œíŠ¸ì— ì €ì¥
                    analysis_data = {
                        "objectiveJson": json.dumps(all_analysis['objective'], ensure_ascii=False),
                        "ratingJson": json.dumps(all_analysis['rating'], ensure_ascii=False),
                        "subjectiveJson": json.dumps(all_analysis['subjective'], ensure_ascii=False),
                        "insightsText": insights,
                        "actionItemsText": "",
                        "confidence": "0.85"
                    }
                    save_analysis(spreadsheet, course_id, analysis_data)
                    st.success("âœ… ë¶„ì„ ê²°ê³¼ê°€ Analysis ì‹œíŠ¸ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def main():
    set_page_config()
    apply_global_styles()
    
    # íŒŒìŠ¤í…” ë°°ê²½ ì¥ì‹ ì¶”ê°€
    st.markdown(
        """
        <div class="ai-bg-decoration"></div>
        <style>
          /* ì„ í˜• íŒ¨í„´ ì¥ì‹ */
          .stApp::before {
            content: '';
            position: fixed;
            top: 10%;
            right: 5%;
            width: 150px;
            height: 150px;
            background-image: 
              repeating-linear-gradient(45deg, transparent, transparent 15px, rgba(168, 216, 234, 0.1) 15px, rgba(168, 216, 234, 0.1) 30px),
              repeating-linear-gradient(-45deg, transparent, transparent 15px, rgba(212, 165, 216, 0.1) 15px, rgba(212, 165, 216, 0.1) 30px);
            border-radius: 50%;
            z-index: 0;
            pointer-events: none;
            animation: pattern-rotate 30s linear infinite;
          }
          
          .stApp::after {
            content: '';
            position: fixed;
            bottom: 15%;
            left: 8%;
            width: 100px;
            height: 100px;
            border: 3px solid var(--pastel-mint);
            border-radius: 50%;
            z-index: 0;
            pointer-events: none;
            animation: float 8s ease-in-out infinite;
            opacity: 0.3;
          }
          
          @keyframes pattern-rotate {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
          }
          
          @keyframes float {
            0%, 100% { transform: translateY(0px) scale(1); }
            50% { transform: translateY(-25px) scale(1.05); }
          }
        </style>
        """,
        unsafe_allow_html=True
    )
    
    spreadsheet = require_spreadsheet()
    
    # ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë“œ ì„ íƒ
    is_admin_mode = sidebar_mode_selector()
    authenticate_if_needed(is_admin_mode)

    is_admin = is_admin_mode and bool(st.session_state.get("admin_authenticated"))

    if is_admin:
        st.markdown(f"- **{ADMIN_BADGE}**: ì„¸ì…˜ ë§Œë£Œ 30ë¶„")
        
        # Cache control in sidebar
        with st.sidebar:
            st.divider()
            st.markdown("### ìºì‹œ ê´€ë¦¬")
            st.caption("ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì„ ë•Œ ìºì‹œë¥¼ í´ë¦¬ì–´í•˜ì„¸ìš”.")
            if st.button("ìºì‹œ í´ë¦¬ì–´", help="ëª¨ë“  ìºì‹œëœ ë°ì´í„°ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤"):
                st.cache_data.clear()
                st.success("ìºì‹œê°€ í´ë¦¬ì–´ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.info("í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ë©´ ìµœì‹  ë°ì´í„°ê°€ ë¡œë“œë©ë‹ˆë‹¤.")
        
        tab1, tab2, tab3 = st.tabs(["ê³¼ì • ë¦¬ìŠ¤íŠ¸", "DB ì„¤ì •", "íŒŒì¼ ì—…ë¡œë“œ"])
        with tab1:
            page_course_list(spreadsheet, is_admin=True)
        with tab2:
            page_setup_db(spreadsheet)
        with tab3:
            page_upload_files(spreadsheet)
    else:
        # ì¼ë°˜ ì‚¬ìš©ì ëª¨ë“œ: ì„¤ë¬¸ ì°¸ì—¬
        page_survey_participation(spreadsheet)


if __name__ == "__main__":
    main()


